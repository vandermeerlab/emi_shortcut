{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import random\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import vdmlab as vdm\n",
    "\n",
    "from load_data import get_pos, get_spikes, get_lfp\n",
    "# from tuning_curves_functions import get_tc_1d\n",
    "# from field_functions import unique_fields\n",
    "from maze_functions import trajectory_fields, find_zones\n",
    "from plotting_functions import plot_cooccur\n",
    "\n",
    "import info.R063d2_info as r063d2\n",
    "import info.R063d3_info as r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled\\\\'\n",
    "# output_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\plots\\\\'\n",
    "output_filepath = 'E:\\\\code\\\\emi_shortcut\\\\cache\\\\pickled\\\\'\n",
    "output_filepath = 'E:\\\\code\\\\emi_shortcut\\\\plots\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trajectory_fields(tuning_curves, spikes, zone, xedges, yedges, field_thresh):\n",
    "    \"\"\"Finds track tuning curves that have firing above field_thresh.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tuning_curves : list of np.arrays\n",
    "    spikes: list of vdmlab.SpikeTrain objects\n",
    "    zone : shapely.Polygon\n",
    "    xedges : np.array\n",
    "    yedges : np.array\n",
    "    field_thresh : float\n",
    "        Threshold (in Hz) that determines whether the neuron has a field.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fields_tc : dict\n",
    "        With u, shortcut, novel, pedestal as keys. Values are np.arrays.\n",
    "    \"\"\"\n",
    "    xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "    ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "\n",
    "    xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "    in_u = []\n",
    "    in_shortcut = []\n",
    "    in_novel = []\n",
    "    in_pedestal = []\n",
    "\n",
    "    fields_tc = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    fields_neuron = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    for i, neuron_tc in enumerate(tuning_curves):\n",
    "        field_idx = neuron_tc.flatten() > field_thresh\n",
    "        field = xy_centers[field_idx]\n",
    "        for pt in field:\n",
    "            point = Point([pt[0], pt[1]])\n",
    "            if zone['u'].contains(point) or zone['ushort'].contains(point) or zone['unovel'].contains(point):\n",
    "                if i not in in_u:\n",
    "                    in_u.append(i)\n",
    "                    fields_tc['u'].append(neuron_tc)\n",
    "                    fields_neuron['u'].append(spikes[i])\n",
    "            if zone['shortcut'].contains(point) or zone['shortped'].contains(point):\n",
    "                if i not in in_shortcut:\n",
    "                    in_shortcut.append(i)\n",
    "                    fields_tc['shortcut'].append(neuron_tc)\n",
    "                    fields_neuron['shortcut'].append(spikes[i])\n",
    "            if zone['novel'].contains(point) or zone['novelped'].contains(point):\n",
    "                if i not in in_novel:\n",
    "                    in_novel.append(i)\n",
    "                    fields_tc['novel'].append(neuron_tc)\n",
    "                    fields_neuron['novel'].append(spikes[i])\n",
    "            if zone['pedestal'].contains(point):\n",
    "                if i not in in_pedestal:\n",
    "                    in_pedestal.append(i)\n",
    "                    fields_tc['pedestal'].append(neuron_tc)\n",
    "                    fields_neuron['pedestal'].append(spikes[i])\n",
    "\n",
    "    return fields_tc, fields_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infos = [r063d3]\n",
    "experiment_times = ['pauseA']\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    for experiment_time in experiment_times:\n",
    "        print(experiment_time)\n",
    "        \n",
    "        lfp = get_lfp(info.good_swr[0])\n",
    "        position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "        spikes = get_spikes(info.spike_mat)\n",
    "\n",
    "        speed = position.speed(t_smooth=0.5)\n",
    "        run_idx = np.squeeze(speed.data) >= info.run_threshold\n",
    "        run_pos = position[run_idx]\n",
    "\n",
    "        t_start = info.task_times[experiment_time].start\n",
    "        t_stop = info.task_times[experiment_time].stop\n",
    "        \n",
    "        sliced_lfp = lfp.time_slice(t_start, t_stop)\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(t_start, t_stop) for spiketrain in spikes]\n",
    "        \n",
    "        t_start_tc = info.task_times['phase3'].start\n",
    "        t_stop_tc = info.task_times['phase3'].stop\n",
    "        \n",
    "        tc_pos = run_pos.time_slice(t_start_tc, t_stop_tc)\n",
    "\n",
    "        tc_spikes = [spiketrain.time_slice(t_start_tc, t_stop_tc) for spiketrain in spikes]\n",
    "\n",
    "        binsize = 3\n",
    "        xedges = np.arange(tc_pos.x.min(), tc_pos.x.max() + binsize, binsize)\n",
    "        yedges = np.arange(tc_pos.y.min(), tc_pos.y.max() + binsize, binsize)\n",
    "\n",
    "        tuning_curves = vdm.tuning_curve_2d(tc_pos, tc_spikes, xedges, yedges, gaussian_sigma=0.1)\n",
    "        \n",
    "        zones = find_zones(info)\n",
    "        \n",
    "        fields_tc, fields_spikes = trajectory_fields(tuning_curves, tc_spikes, zones, xedges, yedges, field_thresh=1.)\n",
    "        \n",
    "#         swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), power_thres=5)\n",
    "        \n",
    "#         swr_intervals = []\n",
    "#         for swr in swrs:\n",
    "#             swr_intervals.append([swr.time[0], swr.time[-1]])\n",
    "#         swr_intervals = np.array(swr_intervals).T\n",
    "        \n",
    "#         count_matrix = dict()\n",
    "#         for key in fields_spikes:\n",
    "#             count_matrix[key] = vdm.spike_counts(fields_spikes[key], swr_intervals, window=0.1)\n",
    "            \n",
    "#         tetrode_mask = dict()\n",
    "#         for key in fields_spikes:\n",
    "#             tetrode_mask[key] = vdm.get_tetrode_mask(fields_spikes[key])\n",
    "        \n",
    "#         probs = dict()\n",
    "#         for key in fields_spikes:\n",
    "#             probs[key] = vdm.compute_cooccur(count_matrix[key], tetrode_mask[key], num_shuffles=10000)\n",
    "            \n",
    "#         filename = 'testing_cooccur-' + experiment_time + '.png'\n",
    "#         savepath = os.path.join(output_filepath, filename)\n",
    "#         plot_cooccur(probs, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fields_spikes['u']), len(fields_spikes['shortcut']), len(fields_spikes['novel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_thresh = 1.\n",
    "zone = zones\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "in_u = []\n",
    "in_shortcut = []\n",
    "in_novel = []\n",
    "in_pedestal = []\n",
    "\n",
    "fields_tc = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "fields_neuron = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "for i, neuron_tc in enumerate(tuning_curves):\n",
    "    field_idx = np.ravel(neuron_tc) > field_thresh\n",
    "    field = xy_centers[field_idx]\n",
    "    for pt in field:\n",
    "        point = Point([pt[0], pt[1]])\n",
    "        if zone['novel'].contains(point) or zone['novelped'].contains(point):\n",
    "            if i not in in_novel:\n",
    "                in_novel.append(i)\n",
    "                fields_tc['novel'].append(neuron_tc)\n",
    "                fields_neuron['novel'].append(spikes[i])\n",
    "        elif zone['shortcut'].contains(point) or zone['shortped'].contains(point):\n",
    "            if i not in in_shortcut:\n",
    "                in_shortcut.append(i)\n",
    "                fields_tc['shortcut'].append(neuron_tc)\n",
    "                fields_neuron['shortcut'].append(spikes[i])\n",
    "        elif zone['u'].contains(point) or zone['ushort'].contains(point) or zone['unovel'].contains(point):\n",
    "            if i not in in_u:\n",
    "                in_u.append(i)\n",
    "                fields_tc['u'].append(neuron_tc)\n",
    "                fields_neuron['u'].append(spikes[i])\n",
    "        elif zone['pedestal'].contains(point):\n",
    "            if i not in in_pedestal:\n",
    "                in_pedestal.append(i)\n",
    "                fields_tc['pedestal'].append(neuron_tc)\n",
    "                fields_neuron['pedestal'].append(spikes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fields_neuron['u']), len(fields_neuron['shortcut']), len(fields_neuron['novel']), len(fields_neuron['pedestal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotting_functions import plot_intersects, plot_zone\n",
    "\n",
    "for zone in zones:\n",
    "    if zones[zone].geom_type == 'MultiPolygon':\n",
    "        plot_intersects(zones[zone])\n",
    "    elif zones[zone].geom_type == 'Polygon':\n",
    "        plot_zone(zones[zone])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "plt.plot(77.56975984316288, 66.92093904767174, '.', ms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import filters\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "def find_fields_2d(tuning_curves, neighborhood_size, threshold):\n",
    "    fields_mask = []\n",
    "    for tuning_curve in tuning_curves:\n",
    "        max_points = filters.maximum_filter(tuning_curve, neighborhood_size)\n",
    "        maxima = (tuning_curve == max_points)\n",
    "        min_points = filters.minimum_filter(tuning_curve, neighborhood_size)\n",
    "        diff = ((max_points - min_points) > threshold)\n",
    "        maxima[diff == 0] = 0\n",
    "        fields_mask.append(maxima)\n",
    "    return fields_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_size = 100\n",
    "threshold = 5\n",
    "fields_mask = find_fields_2d(tuning_curves, neighborhood_size, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields_mask[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
