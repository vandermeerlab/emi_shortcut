{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "import vdmlab as vdm\n",
    "\n",
    "from loading_data import get_data\n",
    "from utils_maze import get_xyedges, find_zones, speed_threshold\n",
    "from analyze_decode import get_edges, point_in_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_filepath = 'E:/code/emi_shortcut/plots/intermediate'\n",
    "pickle_filepath = 'E:/code/emi_shortcut/cache/pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons_filename = info.session_id + '_neurons.pkl'\n",
    "pickled_neurons = os.path.join(pickle_filepath, neurons_filename)\n",
    "with open(pickled_neurons, 'rb') as fileobj:\n",
    "    neurons = pickle.load(fileobj)\n",
    "    \n",
    "experiment_time = 'phase3'\n",
    "speed_limit = 0.4\n",
    "shuffle_id = False\n",
    "min_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('decoding:', info.session_id)\n",
    "\n",
    "track_times = ['phase1', 'phase2', 'phase3', 'tracks']\n",
    "pedestal_times = ['pauseA', 'pauseB', 'prerecord', 'postrecord']\n",
    "\n",
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "xedges, yedges = vdm.get_xyedges(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_start = info.task_times[experiment_time].start\n",
    "exp_stop = info.task_times[experiment_time].stop\n",
    "\n",
    "decode_spikes = neurons.time_slice(exp_start, exp_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "for i, tc in enumerate(neurons.tuning_curves[123:124]):\n",
    "    print(i)\n",
    "    pp = plt.pcolormesh(xx, yy, tc, cmap='pink_r')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tuning_curves = np.zeros(neurons.tuning_shape)\n",
    "for i in range(neurons.n_neurons):\n",
    "    all_tuning_curves += neurons.tuning_curves[i]\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, all_tuning_curves, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_start = info.task_times[experiment_time].start\n",
    "exp_stop = info.task_times[experiment_time].stop\n",
    "\n",
    "spikes = neurons.time_slice(exp_start, exp_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if experiment_time in track_times:\n",
    "    run_position = speed_threshold(position, speed_limit=speed_limit)\n",
    "else:\n",
    "    run_position = position\n",
    "    \n",
    "exp_position = run_position.time_slice(exp_start, exp_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "histogram, xs, ys = np.histogram2d(exp_position.x, exp_position.y, \n",
    "                                   bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if shuffle_id:\n",
    "    random.shuffle(tuning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if experiment_time in track_times:\n",
    "    epochs_interest = vdm.Epoch(np.hstack([exp_start, exp_stop]))\n",
    "elif experiment_time in pedestal_times:\n",
    "    sliced_lfp = lfp.time_slice(exp_start, exp_stop)\n",
    "\n",
    "    z_thresh = 3.0\n",
    "    power_thresh = 5.0\n",
    "    merge_thresh = 0.02\n",
    "    min_length = 0.01\n",
    "    swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "                                  power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "    epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=4)\n",
    "    if epochs_interest.n_epochs == 0:\n",
    "        epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)\n",
    "else:\n",
    "    raise ValueError(\"unrecognized experimental phase. Must be in ['prerecord', 'phase1', 'pauseA', 'phase2', \"\n",
    "                     \"'pauseB', phase3', 'postrecord'].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(exp_position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = plt.pcolormesh(counts, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tc_shape = neurons.tuning_curves.shape\n",
    "decoding_tc = neurons.tuning_curves.reshape(tc_shape[0], \n",
    "                                            tc_shape[1] * tc_shape[2])\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "histogram, xs, ys = np.histogram2d(decoded.x, decoded.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=min_length)\n",
    "    decoded_epochs = sequences.intersect(epochs_interest)\n",
    "    decoded = decoded[decoded_epochs]\n",
    "else:\n",
    "    raise ValueError(\"decoded cannot be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, remove_feeder=True, expand_by=8)\n",
    "decoded_zones = point_in_zones(decoded, zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time in ['phase1', 'phase2', 'phase3', 'tracks']:\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, exp_position.time, exp_position.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, exp_position.time, exp_position.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "\n",
    "        if actual_position[trajectory].n_samples > 0:\n",
    "            errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "histogram, xs, ys = np.histogram2d(output['decoded'].x, output['decoded'].y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('u error mean', np.mean(output['errors']['u']))\n",
    "print('shortcut error mean', np.mean(output['errors']['shortcut']))\n",
    "print('novel error mean', np.mean(output['errors']['novel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '_decode-' + experiment_time + '.pkl'\n",
    "decode_filename = info.session_id + filename\n",
    "pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "with open(pickled_decoded, 'rb') as fileobj:\n",
    "    decode = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "histogram, xs, ys = np.histogram2d(decode['decoded'].x, decode['decoded'].y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils_fields import categorize_fields\n",
    "from analyze_tuning_curves import get_odd_firing_idx\n",
    "from plot_sequence_raster import plot_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_thresh = 1.0\n",
    "fields_tunings = categorize_fields(neurons.tuning_curves, zones, xedges, yedges, field_thresh=field_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_line = LineString(info.u_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_dist = []\n",
    "for neuron in fields_tunings['u']:\n",
    "    yy = ycenters[np.where(fields_tunings['u'][neuron] == fields_tunings['u'][neuron].max())[0][0]]\n",
    "    xx = xcenters[np.where(fields_tunings['u'][neuron] == fields_tunings['u'][neuron].max())[1][0]]\n",
    "\n",
    "    pt = Point(xx, yy)\n",
    "    if zones['u'].contains(pt):\n",
    "        u_dist.append((u_line.project(pt), neuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordered_dist_u = sorted(u_dist, key=lambda x:x[0])\n",
    "sort_idx = []\n",
    "for neuron in ordered_dist_u:\n",
    "    sort_idx.append(neuron[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_spikes = []\n",
    "sort_tuning_curves = []\n",
    "for neuron in sort_idx:\n",
    "    sort_tuning_curves.append(fields_tunings['u'][neuron])\n",
    "    sort_spikes.append(neurons.spikes[neuron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_firing_idx = get_odd_firing_idx(sort_tuning_curves, max_mean_firing=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odd_firing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_spikes = []\n",
    "ordered_fields =[]\n",
    "for i, neuron in enumerate(sort_spikes):\n",
    "    if i not in odd_firing_idx:\n",
    "        ordered_spikes.append(neuron)\n",
    "        ordered_fields.append(sort_tuning_curves[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_sequence(ordered_spikes, lfp, info.sequence['u']['run'].starts[0], info.sequence['u']['run'].stops[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
