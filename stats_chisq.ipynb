{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:43.206229Z",
     "start_time": "2019-03-25T15:04:37.044341Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_sequenceless import Session, TaskTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:43.231767Z",
     "start_time": "2019-03-25T15:04:43.206229Z"
    }
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decoding\", \"sequenceless\", \"stats\")\n",
    "if not os.path.exists(output_filepath):\n",
    "    os.makedirs(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T19:16:16.657481Z",
     "start_time": "2019-03-25T19:16:16.653483Z"
    }
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as r066d1\n",
    "import info.r066d2 as r066d2\n",
    "infos = [r066d1, r066d2]\n",
    "info = r066d1\n",
    "# from run import analysis_infos\n",
    "# infos = analysis_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:44.531509Z",
     "start_time": "2019-03-25T15:04:43.655296Z"
    }
   },
   "outputs": [],
   "source": [
    "# for info in infos:\n",
    "print(info.session_id)\n",
    "events, position, spikes, lfp, _ = get_data(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:45.475250Z",
     "start_time": "2019-03-25T15:04:44.531509Z"
    }
   },
   "outputs": [],
   "source": [
    "passthresh_path = os.path.join(pickle_filepath, info.session_id + \"_likelihoods_true_passthresh.pkl\")\n",
    "\n",
    "if os.path.exists(passthresh_path):\n",
    "    print(\"Loading pickled passthresh likelihoods...\")\n",
    "    with open(passthresh_path, 'rb') as fileobj:\n",
    "        passthresh_session = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:45.491690Z",
     "start_time": "2019-03-25T15:04:45.475250Z"
    }
   },
   "outputs": [],
   "source": [
    "passthresh_session.pauseA.swrs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:45.520674Z",
     "start_time": "2019-03-25T15:04:45.495690Z"
    }
   },
   "outputs": [],
   "source": [
    "session = passthresh_session\n",
    "task_labels = [\"prerecord\", \"pauseA\"]\n",
    "zone_labels = [\"u\", \"shortcut\"]\n",
    "n_swrs = {task_label: 0 for task_label in task_labels}\n",
    "for zone_label in zone_labels:\n",
    "    for task_label in task_labels:\n",
    "        zone_sums = getattr(session, task_label).sums(zone_label)\n",
    "        n_swrs[task_label] += getattr(session, task_label).swrs.n_epochs\n",
    "    print(zone_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:45.531668Z",
     "start_time": "2019-03-25T15:04:45.522673Z"
    }
   },
   "outputs": [],
   "source": [
    "n_swrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:45.542661Z",
     "start_time": "2019-03-25T15:04:45.533666Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(passthresh_session.pauseA.sums(\"shortcut\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:40.332439Z",
     "start_time": "2019-03-25T16:38:40.327441Z"
    }
   },
   "outputs": [],
   "source": [
    "observed = np.array([[100, 150, 200], \n",
    "                     [50, 100, 150]])\n",
    "print(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:40.725240Z",
     "start_time": "2019-03-25T16:38:40.720243Z"
    }
   },
   "outputs": [],
   "source": [
    "expected_equal = np.ones(observed.shape) * np.mean(observed)\n",
    "expected_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:41.070619Z",
     "start_time": "2019-03-25T16:38:41.064605Z"
    }
   },
   "outputs": [],
   "source": [
    "expected_bypath = np.ones(observed.shape) * np.mean(observed, axis=0)\n",
    "expected_bypath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:41.276340Z",
     "start_time": "2019-03-25T16:38:41.272343Z"
    }
   },
   "outputs": [],
   "source": [
    "expected_byphase = np.repeat(np.mean(observed, axis=1), 3).reshape(observed.shape)\n",
    "expected_byphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:41.484946Z",
     "start_time": "2019-03-25T16:38:41.479950Z"
    }
   },
   "outputs": [],
   "source": [
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_equal, axis=None)\n",
    "print(chisq, p, p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:38:42.076896Z",
     "start_time": "2019-03-25T16:38:42.071899Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_squared_stat = (((observed-expected_equal)**2)/expected_equal).sum()\n",
    "chi_squared_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:49.103153Z",
     "start_time": "2019-03-25T15:04:49.097157Z"
    }
   },
   "outputs": [],
   "source": [
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_bypath, axis=None)\n",
    "print(chisq, p, p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:49.304023Z",
     "start_time": "2019-03-25T15:04:49.300026Z"
    }
   },
   "outputs": [],
   "source": [
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_byphase, axis=None)\n",
    "print(chisq, p, p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:12:27.280785Z",
     "start_time": "2019-03-25T15:12:27.273810Z"
    }
   },
   "outputs": [],
   "source": [
    "p_value = 1 - scipy.stats.chi2.cdf(x=chi_squared_stat, df=1)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:39:31.964835Z",
     "start_time": "2019-03-25T16:39:31.959858Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def limit_by_n_swr(session, task_labels, n_swr_thresh, zone_label=\"u\"):\n",
    "    session_copy = copy.deepcopy(session)\n",
    "\n",
    "    for task_label in task_labels:\n",
    "        if getattr(session_copy, task_label).swrs.n_epochs < n_swr_thresh:\n",
    "            zone_shape = getattr(session_copy, task_label).zones[zone_label].shape\n",
    "            getattr(session_copy, task_label).likelihoods = np.ones((1, 1, zone_shape[0], zone_shape[1])) * np.nan\n",
    "\n",
    "    return session_copy\n",
    "\n",
    "update_cache=False\n",
    "n_swr_thresh=10\n",
    "n_shuffles=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T19:16:24.321629Z",
     "start_time": "2019-03-25T19:16:19.958456Z"
    }
   },
   "outputs": [],
   "source": [
    "dont_save_pickle = False\n",
    "plot_individual = False\n",
    "plot_individual_passthresh = False\n",
    "plot_overspace = False\n",
    "plot_summary = True\n",
    "\n",
    "percentile_thresh = 95\n",
    "\n",
    "colours = dict()\n",
    "colours[\"u\"] = \"#2b8cbe\"\n",
    "colours[\"shortcut\"] = \"#31a354\"\n",
    "colours[\"novel\"] = \"#d95f0e\"\n",
    "colours[\"other\"] = \"#bdbdbd\"\n",
    "\n",
    "# swr params\n",
    "swr_params = dict()\n",
    "swr_params[\"merge_thresh\"] = 0.02\n",
    "swr_params[\"min_length\"] = 0.05\n",
    "swr_params[\"swr_thresh\"] = (140.0, 250.0)\n",
    "swr_params[\"min_involved\"] = 4\n",
    "\n",
    "task_labels = [\"prerecord\", \"pauseA\", \"pauseB\", \"postrecord\"]\n",
    "zone_labels = [\"u\", \"shortcut\", \"novel\", \"other\"]\n",
    "\n",
    "true_sessions = []\n",
    "shuffled_sessions = []\n",
    "passthresh_sessions = []\n",
    "passthresh_counts = []\n",
    "combined_passthresh_count = {task_label: {zone_label: 0 for zone_label in zone_labels} for task_label in task_labels}\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "\n",
    "    # Get true data\n",
    "    true_path = os.path.join(pickle_filepath, info.session_id + \"_likelihoods_true.pkl\")\n",
    "\n",
    "    # Remove previous pickle if update_cache\n",
    "    if update_cache:\n",
    "        if os.path.exists(true_path):\n",
    "            os.remove(true_path)\n",
    "\n",
    "    # Load pickle if it exists, otherwise compute and pickle\n",
    "    if os.path.exists(true_path):\n",
    "        print(\"Loading pickled true likelihoods...\")\n",
    "        compute_likelihoods = False\n",
    "        with open(true_path, 'rb') as fileobj:\n",
    "            true_session = pickle.load(fileobj)\n",
    "    else:\n",
    "        if dont_save_pickle:\n",
    "            true_path = None\n",
    "        true_session = get_likelihoods(info,\n",
    "                                       swr_params,\n",
    "                                       task_labels,\n",
    "                                       n_shuffles,\n",
    "                                       save_path=true_path)\n",
    "\n",
    "    true_sessions.append(true_session)\n",
    "\n",
    "    sessions_copy = []\n",
    "    for session in true_sessions:\n",
    "        session_copy = limit_by_n_swr(session, task_labels, n_swr_thresh)\n",
    "        sessions_copy.append(session_copy)\n",
    "    true_sessions = sessions_copy\n",
    "\n",
    "    # Get shuffled data\n",
    "    shuffled_path = os.path.join(pickle_filepath,\n",
    "                                 info.session_id + \"_likelihoods_shuffled-%03d.pkl\" % n_shuffles)\n",
    "\n",
    "    # Remove previous pickle if update_cache\n",
    "    if update_cache:\n",
    "        if os.path.exists(shuffled_path):\n",
    "            os.remove(shuffled_path)\n",
    "\n",
    "    # Load pickle if it exists, otherwise compute and pickle\n",
    "    if os.path.exists(shuffled_path):\n",
    "        print(\"Loading pickled shuffled likelihoods...\")\n",
    "        with open(shuffled_path, 'rb') as fileobj:\n",
    "            shuffled_session = pickle.load(fileobj)\n",
    "    else:\n",
    "        if dont_save_pickle:\n",
    "            shuffled_path = None\n",
    "        shuffled_session = get_likelihoods(info,\n",
    "                                           swr_params,\n",
    "                                           task_labels,\n",
    "                                           n_shuffles=n_shuffles,\n",
    "                                           save_path=shuffled_path)\n",
    "\n",
    "    shuffled_sessions.append(shuffled_session)\n",
    "    sessions_copy = []\n",
    "    for session in true_sessions:\n",
    "        session_copy = limit_by_n_swr(session, task_labels, n_swr_thresh)\n",
    "        sessions_copy.append(session_copy)\n",
    "    shuffled_sessions = sessions_copy\n",
    "\n",
    "    if plot_individual:\n",
    "        filepath = os.path.join(output_filepath, \"individual\")\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        plot_summary_individual(info, true_session, shuffled_session,\n",
    "                                zone_labels, task_labels, colours, filepath)\n",
    "\n",
    "    if plot_overspace:\n",
    "        filepath = os.path.join(output_filepath, \"overspace\")\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        plot_likelihood_overspace(info, true_session, task_labels, colours, filepath)\n",
    "\n",
    "    keep_idx = {task_label: [] for task_label in task_labels}\n",
    "    passthresh_count = {task_label: {zone_label: 0 for zone_label in zone_labels} for task_label in task_labels}\n",
    "\n",
    "    for task_label in task_labels:\n",
    "        for zone_label in zone_labels:\n",
    "            zones = getattr(true_session, task_label).zones\n",
    "            true_sums = np.array(getattr(true_session, task_label).sums(zone_label))\n",
    "            shuffled_sums = np.array(getattr(shuffled_session, task_label).sums(zone_label))\n",
    "            if true_sums.size <= 1 and np.isnan(true_sums).all():\n",
    "                continue\n",
    "            elif getattr(true_session, task_label).swrs.n_epochs == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for idx in range(true_sums.shape[1]):\n",
    "                    percentile = scipy.stats.percentileofscore(np.sort(shuffled_sums[:, idx]), true_sums[:, idx][0])\n",
    "                    if percentile >= percentile_thresh:\n",
    "                        keep_idx[task_label].append(idx)\n",
    "                        passthresh_count[task_label][zone_label] += 1\n",
    "                        combined_passthresh_count[task_label][zone_label] += 1\n",
    "\n",
    "    passthresh_counts.append(passthresh_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T19:16:25.849899Z",
     "start_time": "2019-03-25T19:16:25.844919Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_passthresh_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T19:16:32.714838Z",
     "start_time": "2019-03-25T19:16:32.708842Z"
    }
   },
   "outputs": [],
   "source": [
    "passthresh_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:39:36.700589Z",
     "start_time": "2019-03-25T16:39:36.695591Z"
    }
   },
   "outputs": [],
   "source": [
    "shortcut_n = []\n",
    "u_n = []\n",
    "novel_n = []\n",
    "other_n = []\n",
    "\n",
    "for task_label in task_labels:\n",
    "    shortcut_n.append(passthresh_counts[0][task_label][\"shortcut\"])\n",
    "    u_n.append(passthresh_counts[0][task_label][\"u\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:39:37.036922Z",
     "start_time": "2019-03-25T16:39:37.031924Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array([shortcut_n, u_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:39:37.833337Z",
     "start_time": "2019-03-25T16:39:37.824341Z"
    }
   },
   "outputs": [],
   "source": [
    "observed = np.array([shortcut_n, u_n])\n",
    "print(observed)\n",
    "\n",
    "expected_equal = np.ones(observed.shape) * np.mean(observed)\n",
    "print(expected_equal)\n",
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_equal, axis=None)\n",
    "print(chisq, p, p<0.05)\n",
    "\n",
    "expected_bypath = np.ones(observed.shape) * np.mean(observed, axis=0)\n",
    "print(expected_bypath)\n",
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_bypath, axis=None)\n",
    "print(chisq, p, p<0.05)\n",
    "\n",
    "expected_byphase = np.repeat(np.mean(observed, axis=1), len(task_labels)).reshape(observed.shape)\n",
    "print(expected_byphase)\n",
    "chisq, p = scipy.stats.chisquare(observed, f_exp=expected_byphase, axis=None)\n",
    "print(chisq, p, p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:41:40.062590Z",
     "start_time": "2019-03-25T16:41:40.056614Z"
    }
   },
   "outputs": [],
   "source": [
    "print(observed)\n",
    "expected = np.ones(observed.shape) * np.mean(observed, axis=0)\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:42:46.197451Z",
     "start_time": "2019-03-25T16:42:46.192453Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_squared_stat = np.nansum((((observed-expected)**2)/expected))\n",
    "chi_squared_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:42:18.886811Z",
     "start_time": "2019-03-25T16:42:18.879813Z"
    }
   },
   "outputs": [],
   "source": [
    "(observed-expected)**2 / expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T16:42:14.876642Z",
     "start_time": "2019-03-25T16:42:14.871644Z"
    }
   },
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
