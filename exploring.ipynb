{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import vdmlab as vdm\n",
    "\n",
    "from loading_data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from run import test_infos\n",
    "infos = test_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle_filepath = 'E:/code/emi_shortcut/cache/pickled'\n",
    "pickle_filepath = 'C:/Users/Emily/code/emi_shortcut/cache/pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import info.r063d3 as info\n",
    "\n",
    "tuning_curve_filename = info.session_id + '_tuning-curve.pkl'\n",
    "pickled_tuning_curve = os.path.join(pickle_filepath, tuning_curve_filename)\n",
    "with open(pickled_tuning_curve, 'rb') as fileobj:\n",
    "    tuning_curve = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_time = 'pauseA'\n",
    "decode_filename = info.session_id + '_decode-' + experiment_time + '.pkl'\n",
    "pickled_decode = os.path.join(pickle_filepath, decode_filename)\n",
    "with open(pickled_decode, 'rb') as fileobj:\n",
    "    decode = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode['zones']['u'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analyze_decode import analyze\n",
    "experiment_time = 'phase1'\n",
    "pausea = analyze(info, tuning_curve, experiment_time=experiment_time, shuffle_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pausea['zones']['u'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = pausea['decoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pausea['zones']['shortcut'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pausea['zones']['novel'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pausea['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "11 / 358152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pausea['decoded'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = pausea['zones']['u']\n",
    "shortcut = pausea['zones']['shortcut']\n",
    "novel = pausea['zones']['novel']\n",
    "other = pausea['zones']['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position.n_samples, shortcut.n_samples, novel.n_samples, other.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(u.x, u.y, 'b.', ms=2)\n",
    "plt.plot(shortcut.x, shortcut.y, 'g.', ms=2)\n",
    "plt.plot(novel.x, novel.y, 'k.', ms=2)\n",
    "plt.plot(other.x, other.y, 'r.', ms=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(position.x, position.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_id = False\n",
    "from analyze_decode import get_edges, point_in_zones\n",
    "from utils_maze import find_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= 0.1\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "track_starts = [info.task_times['phase1'].start,\n",
    "                info.task_times['phase2'].start,\n",
    "                info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase1'].stop,\n",
    "               info.task_times['phase2'].stop,\n",
    "               info.task_times['phase3'].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "if shuffle_id:\n",
    "    random.shuffle(tuning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = track_pos\n",
    "\n",
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(position.x, position.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if experiment_time == 'tracks':\n",
    "    decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "    epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "\n",
    "else:\n",
    "    decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                           info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "#     sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "#     z_thresh = 3.0\n",
    "#     power_thresh = 5.0\n",
    "#     merge_thresh = 0.02\n",
    "#     min_length = 0.01\n",
    "#     swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "#                                   power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "#     epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "#     if epochs_interest.n_epochs == 0:\n",
    "#         epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(decode_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy_centers.shape, time_centers.shape, likelihood.shape, decoding_tc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)\n",
    "\n",
    "decoding_tc = []\n",
    "for tuning in tuning_curve:\n",
    "    decoding_tc.append(np.ravel(tuning))\n",
    "decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n",
    "\n",
    "# if not decoded.isempty:\n",
    "#     sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=3)\n",
    "# #     decoded_epochs = sequences.intersect(epochs_interest, boundaries=False)\n",
    "#     decoded_epochs = sequences.intersect(vdm.Epoch(info.task_times[experiment_time].start, \n",
    "#                                                    info.task_times[experiment_time].stop), boundaries=False)\n",
    "#     decoded = vdm.epoch_position(decoded, decoded_epochs)\n",
    "# else:\n",
    "#     raise ValueError(\"decoded cannot be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, expand_by=7)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time in ['phase1', 'phase2', 'phase3', 'tracks']:\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(output['errors']['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = decoded\n",
    "\n",
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(position.x, position.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.n_samples, output['decoded'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(time_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_id = False\n",
    "experiment_time='pauseA'\n",
    "from analyze_decode import get_edges, point_in_zones\n",
    "from utils_maze import find_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= 0.1\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "# track_starts = [info.task_times['phase1'].start,\n",
    "#                 info.task_times['phase2'].start,\n",
    "#                 info.task_times['phase3'].start]\n",
    "# track_stops = [info.task_times['phase1'].stop,\n",
    "#                info.task_times['phase2'].stop,\n",
    "#                info.task_times['phase3'].stop]\n",
    "\n",
    "# track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "if shuffle_id:\n",
    "    random.shuffle(tuning_curve)\n",
    "\n",
    "if experiment_time == 'tracks':\n",
    "    decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "    epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "\n",
    "else:\n",
    "    decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                           info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "    sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "    z_thresh = 3.0\n",
    "    power_thresh = 5.0\n",
    "    merge_thresh = 0.02\n",
    "    min_length = 0.01\n",
    "    swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "                                  power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "    epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "    if epochs_interest.n_epochs == 0:\n",
    "        epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)\n",
    "\n",
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(run_pos, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)\n",
    "\n",
    "decoding_tc = []\n",
    "for tuning in tuning_curve:\n",
    "    decoding_tc.append(np.ravel(tuning))\n",
    "decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n",
    "\n",
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=3)\n",
    "    decoded_epochs = sequences.intersect(epochs_interest, boundaries=False)\n",
    "    decoded = vdm.epoch_position(decoded, decoded_epochs)\n",
    "else:\n",
    "    raise ValueError(\"decoded cannot be empty.\")\n",
    "\n",
    "zones = find_zones(info, expand_by=7)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time == 'tracks':\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['zones']['shortcut'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils_plotting import plot_intersects, plot_zone\n",
    "plt.plot(position.x, position.y, 'k.', ms=1)\n",
    "for zone in zones:\n",
    "    if zones[zone].geom_type == 'MultiPolygon':\n",
    "        plot_intersects(zones[zone])\n",
    "    elif zones[zone].geom_type == 'Polygon':\n",
    "        plot_zone(zones[zone])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= 0.1\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "track_starts = [info.task_times['phase1'].start,\n",
    "                info.task_times['phase2'].start,\n",
    "                info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase1'].stop,\n",
    "               info.task_times['phase2'].stop,\n",
    "               info.task_times['phase3'].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pos = position.time_slice(info.task_times['pauseA'].start, info.task_times['pauseA'].stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max() + binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max() + binsize, binsize)\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_starts, track_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle_id = False\n",
    "experiment_time = 'pauseA'\n",
    "\n",
    "\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "if shuffle_id:\n",
    "    random.shuffle(tuning_curve)\n",
    "\n",
    "if experiment_time == 'tracks':\n",
    "    decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "    epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "\n",
    "else:\n",
    "    decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                           info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "    sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "    z_thresh = 3.0\n",
    "    power_thresh = 5.0\n",
    "    merge_thresh = 0.02\n",
    "    min_length = 0.01\n",
    "    swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "                                  power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "    epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "    print(epochs_interest.n_epochs)\n",
    "    if epochs_interest.n_epochs == 0:\n",
    "        epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swrs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs_interest.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analyze_decode import get_edges\n",
    "\n",
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(run_pos, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)\n",
    "\n",
    "decoding_tc = []\n",
    "for tuning in tuning_curve:\n",
    "    decoding_tc.append(np.ravel(tuning))\n",
    "decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(likelihood)), likelihood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pos.time[0], run_pos.time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n",
    "\n",
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=3)\n",
    "    decoded_epochs = sequences.intersect(epochs_interest, boundaries=False)\n",
    "    decoded = vdm.epoch_position(decoded, decoded_epochs)\n",
    "else:\n",
    "    raise ValueError(\"decoded cannot be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils_maze import find_zones\n",
    "from analyze_decode import point_in_zones\n",
    "\n",
    "zones = find_zones(info, expand_by=7)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time == 'tracks':\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "51 / 358152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['decoded'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['zones']['u'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec = output['decoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(output['errors']['u']), np.mean(output['errors']['shortcut']), np.mean(output['errors']['novel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dec.x, dec.y, 'b.', ms=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output['zones']['u'].n_samples + output['zones']['shortcut'].n_samples + output['zones']['novel'].n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving many tuning curves on the same plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "rows = 8\n",
    "cols = 14\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "grids = gridspec.GridSpec(cols, rows)\n",
    "grids.update(wspace=0.02, hspace=0.05)\n",
    "\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for i in range(rows*cols):\n",
    "    ax = plt.subplot(grids[i])\n",
    "    pp = ax.pcolormesh(xx, yy, tuning_curves[i], cmap='pink_r')\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# savepath = 'E:/code/emi_shortcut/plots/tuning/' + info.session_id + 'many_tuning-curves.png'\n",
    "# plt.savefig(savepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Neuralynx events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloc = 'C:/Users/EmilyWork/Desktop/20170104'\n",
    "session = '2017-01-05_test1'\n",
    "event_filename = 'Events.nev'\n",
    "# event_labels = dict(on='on',\n",
    "#                     off='off')\n",
    "event_labels = dict(on='TTL Output on AcqSystem1_0 board 0 port 3 value (0x0002).',\n",
    "                    off='TTL Output on AcqSystem1_0 board 0 port 3 value (0x0000).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(dataloc, session, event_filename)\n",
    "events = vdm.load_events(filepath, event_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(events['off']), len(events['on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
