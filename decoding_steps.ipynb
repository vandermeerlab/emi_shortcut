{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import vdmlab as vdm\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "from loading_data import get_data\n",
    "from utils_plotting import plot_decoded_compare\n",
    "from plot_decode import get_decoded, get_zone_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "emi_shortcut = os.path.join(home, \"code\", \"emi_shortcut\")\n",
    "pickle_filepath = os.path.join(emi_shortcut, \"cache\", \"pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import info\n",
    "\n",
    "# spike_sorted_infos = [\n",
    "#     info.r063d2, info.r063d3, info.r063d4, info.r063d5, info.r063d6, info.r063d7,\n",
    "#     info.r066d1, info.r066d2, info.r066d3, info.r066d4, info.r066d5, info.r066d6, info.r066d7,\n",
    "#     info.r067d1, info.r067d2, info.r067d3, info.r067d4, info.r067d5, info.r067d6, info.r067d7,\n",
    "#     info.r068d1, info.r068d2, info.r068d3, info.r068d4, info.r068d5, info.r068d6, info.r068d7]\n",
    "\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import info.r063d2 as r063d2\n",
    "import info.r066d2 as r066d2\n",
    "import info.r067d2 as r067d2\n",
    "import info.r068d2 as r068d2\n",
    "import info.r063d3 as r063d3\n",
    "infos = [r063d2, r063d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_times = ['pauseA', 'pauseB']\n",
    "\n",
    "decodes = []\n",
    "\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded(info, experiment_times, pickle_filepath, get_zone_proportion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['phase1', 'phase2']\n",
    "\n",
    "sessions = []\n",
    "\n",
    "for info in infos:\n",
    "    combined = OrderedDict()\n",
    "    for experiment_time in experiment_times: \n",
    "        \n",
    "        combined[experiment_time] = dict()\n",
    "\n",
    "        filename = '_decode-' + experiment_time + '.pkl'\n",
    "        decode_filename = info.session_id + filename\n",
    "        pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "        with open(pickled_decoded, 'rb') as fileobj:\n",
    "            decoded = pickle.load(fileobj)\n",
    "\n",
    "        for key in ['u', 'shortcut', 'novel']:\n",
    "            combined[experiment_time][key] = decoded['zones'][key]\n",
    "            \n",
    "    sessions.append(combined)\n",
    "    \n",
    "norm = compare_rates(sessions)\n",
    "plot_decoded_compare(norm, ylabel='Total firing rate')\n",
    "\n",
    "#     combined_lengths = dict(u=[], shortcut=[], novel=[])\n",
    "\n",
    "#         combined_lengths['u'].append(LineString(info.u_trajectory).length)\n",
    "#         combined_lengths['shortcut'].append(LineString(info.shortcut_trajectory).length)\n",
    "#         combined_lengths['novel'].append(LineString(info.novel_trajectory).length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_rates(combined_zones, jump=0.1):\n",
    "    \"\"\"Compare position normalized by time spent in zone\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    combined_zones: list of OrderedDict of dict of lists\n",
    "        With experiment_time as keys and inner dict \n",
    "        has u, shortcut, novel as keys.\n",
    "    jump: float\n",
    "        Any duration above this amount will not be included.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normalized : dict\n",
    "        With u, shortcut, novel as keys.\n",
    "\n",
    "    \"\"\"\n",
    "    rates = []\n",
    "\n",
    "    for session in combined_zones:\n",
    "        normalized = OrderedDict()\n",
    "        for experiment_time in combined_zones[0].keys():\n",
    "            normalized[experiment_time] = dict()\n",
    "            \n",
    "        for experiment_time in session.keys():\n",
    "            for trajectory in session[experiment_time].keys():\n",
    "                linger = np.diff(session[experiment_time][trajectory].time)\n",
    "                linger = np.sum(linger[linger < jump])\n",
    "                normalized[experiment_time][trajectory] = session[experiment_time][trajectory].n_samples / linger\n",
    "       \n",
    "        rates.append(normalized)\n",
    "\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = compare_rates(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decoded_compare(norm, ylabel='Total firing rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_decode(infos, filename, experiment_time, shuffle_id, tuning_curves=None):\n",
    "    total_times = []\n",
    "    combined_errors = []\n",
    "    combined_lengths = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "    combined_decoded = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "    for i, info in enumerate(infos):\n",
    "        decode_filename = info.session_id + filename\n",
    "        pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "        if os.path.isfile(pickled_decoded):\n",
    "            with open(pickled_decoded, 'rb') as fileobj:\n",
    "                decoded = pickle.load(fileobj)\n",
    "        else:\n",
    "            if tuning_curves is None:\n",
    "                raise ValueError(\"tuning curves required when generating decoded\")\n",
    "            decoded = analyze(info, tuning_curves[i], experiment_time=experiment_time, shuffle_id=shuffle_id)\n",
    "\n",
    "        total_times.append(decoded['times'])\n",
    "\n",
    "        combined_lengths['u'].append(LineString(info.u_trajectory).length)\n",
    "        combined_lengths['shortcut'].append(LineString(info.shortcut_trajectory).length)\n",
    "        combined_lengths['novel'].append(LineString(info.novel_trajectory).length)\n",
    "\n",
    "        combined_decoded['u'].append(decoded['zones']['u'])\n",
    "        combined_decoded['shortcut'].append(decoded['zones']['shortcut'])\n",
    "        combined_decoded['novel'].append(decoded['zones']['novel'])\n",
    "        combined_decoded['other'].append(decoded['zones']['other'])\n",
    "        combined_decoded['together'].append(len(decoded['zones']['u'].time) +\n",
    "                                            len(decoded['zones']['shortcut'].time) +\n",
    "                                            len(decoded['zones']['novel'].time) +\n",
    "                                            len(decoded['zones']['other'].time))\n",
    "\n",
    "        keys = ['u', 'shortcut', 'novel']\n",
    "        combined_errors = dict(u=[], shortcut=[], novel=[], together=[])\n",
    "        for trajectory in keys:\n",
    "            combined_errors[trajectory].extend(decoded['errors'][trajectory])\n",
    "            combined_errors['together'].extend(decoded['errors'][trajectory])\n",
    "\n",
    "    output = dict()\n",
    "    output['combined_decoded'] = combined_decoded\n",
    "    output['combined_errors'] = combined_errors\n",
    "    output['total_times'] = total_times\n",
    "    output['combined_lengths'] = combined_lengths\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized_time_spent(combined_decoded, n_sessions, lengths, filenames):\n",
    "    decoded_linger = dict(u=[], shortcut=[], novel=[])\n",
    "    decoded_length = dict(u=[], shortcut=[], novel=[])\n",
    "    for val in range(n_sessions):\n",
    "        decode = dict()\n",
    "        length = dict()\n",
    "        for key in decoded_linger:\n",
    "            decode[key] = combined_decoded[key][val]\n",
    "            length[key] = lengths[key][val]\n",
    "        norm_decoded = compare_rates(decode)\n",
    "        len_decoded = compare_lengths(decode, length)\n",
    "        for key in decoded_linger:\n",
    "            decoded_linger[key].append(norm_decoded[key])\n",
    "            decoded_length[key].append(len_decoded[key])\n",
    "\n",
    "    savepath = os.path.join(output_filepath, filenames[0])\n",
    "    y_label = 'Points normalized by time spent'\n",
    "    plot_decoded(decoded_linger, y_label=y_label, savepath=savepath)\n",
    "\n",
    "    savepath = os.path.join(output_filepath, filenames[1])\n",
    "    y_label = 'Points normalized by track length'\n",
    "    plot_decoded(decoded_length, y_label=y_label, savepath=savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_normalized(infos, tuning_curves, all_tracks_tc=False):\n",
    "    # Plot decoding normalized by time spent\n",
    "    experiment_time = 'phase3'\n",
    "    print('getting decoded', experiment_time)\n",
    "    decoded_phase3 = combine_decode(infos, '_decode-' + experiment_time + '.pkl', experiment_time=experiment_time,\n",
    "                                    shuffle_id=False, tuning_curves=tuning_curves)\n",
    "    print('normalizing ...')\n",
    "    n_sessions = len(infos)\n",
    "    if all_tracks_tc:\n",
    "        filenames = ['combined-time-norm_tracks_decoded_all-tracks.png',\n",
    "                     'combined-length-norm_tracks_decoded_all-tracks.png']\n",
    "    else:\n",
    "        filenames = ['combined-time-norm_tracks_decoded.png', 'combined-length-norm_tracks_decoded.png']\n",
    "    normalized_time_spent(decoded_phase3['combined_decoded'], n_sessions, decoded_phase3['combined_lengths'], filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compare_lengths(zones, lengths):\n",
    "    \"\"\"Compare position normalized by time spent in zone.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zones: dict\n",
    "        With u, shortcut, novel, other as keys.\n",
    "    lengths: dict\n",
    "        With u, shortcut, novel as keys.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normalized : dict\n",
    "        With u, shortcut, novel as keys.\n",
    "\n",
    "    \"\"\"\n",
    "    normalized = dict()\n",
    "    normalized['u'] = len(zones['u'].time) / lengths['u']\n",
    "    normalized['shortcut'] = len(zones['shortcut'].time) / lengths['shortcut']\n",
    "    normalized['novel'] = len(zones['novel'].time) / lengths['novel']\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['phase1', 'phase2', 'phase3']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['prerecord', 'phase1', 'pauseA', 'phase2', 'pauseB', 'phase3', 'postrecord']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['prerecord', 'postrecord']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "emi_shortcut = os.path.join(home, \"code\", \"emi_shortcut\")\n",
    "pickle_filepath = os.path.join(emi_shortcut, \"cache\", \"pickled\")\n",
    "# pickle_filepath = 'E:/code/emi_shortcut/cache/pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_all_tracks = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils_maze import get_xyedges, speed_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "xedges, yedges = get_xyedges(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pos = speed_threshold(position)\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]\n",
    "\n",
    "position_tc = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "track_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "\n",
    "tuning_curve = vdm.tuning_curve_2d(position_tc, track_spikes, xedges, yedges, gaussian_sigma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuning curves with high firing rates\n",
    "tc_sums = np.sum(np.sum(tuning_curve, axis=2), axis=1)\n",
    "np.where(tc_sums > 3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuning curves with low firing rates\n",
    "low_thresh = 1\n",
    "high_thresh = 3000\n",
    "tc_sums = np.sum(np.sum(tuning_curve, axis=2), axis=1)\n",
    "keep_neurons = (tc_sums > low_thresh) & (tc_sums < high_thresh)\n",
    "tuning_curve = tuning_curve[keep_neurons]\n",
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "for ii in range(10):\n",
    "    print(ii)\n",
    "    pp = plt.pcolormesh(yy, xx, tuning_curve[ii], cmap='pink_r')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decoding for phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_id = False\n",
    "from analyze_decode import get_edges, point_in_zones\n",
    "from utils_maze import find_zones\n",
    "\n",
    "experiment_time = 'phase1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_times = ['phase1', 'phase2', 'phase3', 'tracks']\n",
    "pedestal_times = ['pauseA', 'pauseB', 'prerecord', 'postrecord']\n",
    "\n",
    "spikes = spikes[keep_neurons]\n",
    "\n",
    "if experiment_time in track_times:\n",
    "    run_pos = speed_threshold(position, speed_limit=0.4)\n",
    "else:\n",
    "    run_pos = position\n",
    "\n",
    "track_starts = [info.task_times[experiment_time].start]\n",
    "track_stops = [info.task_times[experiment_time].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "# if shuffle_id:\n",
    "#     random.shuffle(tuning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(position.x, position.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(track_pos.x, track_pos.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_pos.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info.task_times[experiment_time].start, info.task_times[experiment_time].stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if experiment_time == 'tracks':\n",
    "#     decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "#     epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "\n",
    "# else:\n",
    "decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                       info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "#     sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "#     z_thresh = 3.0\n",
    "#     power_thresh = 5.0\n",
    "#     merge_thresh = 0.02\n",
    "#     min_length = 0.01\n",
    "#     swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "#                                   power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "#     epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "#     if epochs_interest.n_epochs == 0:\n",
    "#         epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(decode_spikes[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(track_pos, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = plt.pcolormesh(counts, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tc_shape = tuning_curve.shape\n",
    "print(counts.shape)\n",
    "decoding_tc = tuning_curve.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "print(decoded.x.shape)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n",
    "print(decoded.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(decoded.x, decoded.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=3)\n",
    "    decoded_epochs = sequences.intersect(vdm.Epoch(info.task_times[experiment_time].start, \n",
    "                                                   info.task_times[experiment_time].stop))\n",
    "    decoded = decoded[decoded_epochs]\n",
    "else:\n",
    "    raise ValueError(\"decoded cannot be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, expand_by=8)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time in ['phase1', 'phase2', 'phase3', 'tracks']:\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output['decoded'].n_samples / output['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(output['zones']['u'].x, output['zones']['u'].y, 'b.', ms=2)\n",
    "# plt.plot(output['zones']['other'].x, output['zones']['other'].y, 'r.', ms=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(output['errors']['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = output['zones']['u']\n",
    "\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(pos.x, pos.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve_filename = info.session_id + '_tuning-curve.pkl'\n",
    "pickled_tuning_curve = os.path.join(pickle_filepath, tuning_curve_filename)\n",
    "with open(pickled_tuning_curve, 'rb') as fileobj:\n",
    "    tuning_curve = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analyze_decode import analyze\n",
    "experiment_time = 'postrecord'\n",
    "dec = analyze(info, tuning_curve, experiment_time=experiment_time, shuffle_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec['decoded'].n_samples, dec['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading decode from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_time = 'postrecord'\n",
    "decode_filename = info.session_id + '_decode-' + experiment_time + '.pkl'\n",
    "pickled_decode = os.path.join(pickle_filepath, decode_filename)\n",
    "with open(pickled_decode, 'rb') as fileobj:\n",
    "    decode = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode['decoded'].n_samples / decode['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
