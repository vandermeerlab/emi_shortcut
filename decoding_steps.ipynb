{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import vdmlab as vdm\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict\n",
    "\n",
    "from loading_data import get_data\n",
    "from utils_plotting import plot_decoded_compare\n",
    "from analyze_decode import get_decoded_proportions, get_zone_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "emi_shortcut = os.path.join(home, \"code\", \"emi_shortcut\")\n",
    "pickle_filepath = os.path.join(emi_shortcut, \"cache\", \"pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import info\n",
    "\n",
    "# spike_sorted_infos = [\n",
    "#     info.r063d2, info.r063d3, info.r063d4, info.r063d5, info.r063d6, info.r063d7,\n",
    "#     info.r066d1, info.r066d2, info.r066d3, info.r066d4, info.r066d5, info.r066d6, info.r066d7,\n",
    "#     info.r067d1, info.r067d2, info.r067d3, info.r067d4, info.r067d5, info.r067d6, info.r067d7,\n",
    "#     info.r068d1, info.r068d2, info.r068d3, info.r068d4, info.r068d5, info.r068d6, info.r068d7]\n",
    "\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import info.r063d2 as r063d2\n",
    "import info.r063d3 as r063d3\n",
    "infos = [r063d2, r063d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decoded(info, experiment_times, pickle_filepath, f_combine):\n",
    "    \"\"\"Combines decoded outputs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info: module\n",
    "    experiment_times: list of str\n",
    "    pickle_filepath: str\n",
    "    f_combine: function\n",
    "        Either get_zone_proportion or get_errors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    decode_together: OrderedDict\n",
    "        With experiment_time as keys, each a dict\n",
    "        with u, shortcut, novel, other as keys.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    decode_together = OrderedDict()\n",
    "\n",
    "    for experiment_time in experiment_times:\n",
    "        filename = '_decode-' + experiment_time + '.pkl'\n",
    "        decode_filename = info.session_id + filename\n",
    "        pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "        if os.path.isfile(pickled_decoded):\n",
    "            with open(pickled_decoded, 'rb') as fileobj:\n",
    "                decoded = pickle.load(fileobj)\n",
    "        else:\n",
    "            raise ValueError(\"pickled decoded not found for \" + info.session_id)\n",
    "\n",
    "        decode_together[experiment_time] = f_combine(decoded, experiment_time)\n",
    "\n",
    "    return decode_together\n",
    "\n",
    "\n",
    "def get_errors(decoded, experiment_time):\n",
    "    \"\"\"Computes the error of decoded position compared to actual position\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    decoded: vdmlab.Position\n",
    "\n",
    "    Returns: dict\n",
    "\n",
    "    \"\"\"\n",
    "    decoded_error = dict()\n",
    "    for key in decoded['actual'].keys():\n",
    "        if experiment_time in ['phase1', 'phase2', 'phase3']:\n",
    "            decoded_error[key] = decoded['zones'][key].distance(decoded['actual'][key])\n",
    "        else:\n",
    "            decoded_error[key] = 0\n",
    "\n",
    "    return decoded_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# experiment_times = ['prerecord', 'phase1', 'pauseA', 'phase2', 'pauseB', 'phase3', 'postrecord']\n",
    "experiment_times = ['phase1', 'phase2', 'phase3']\n",
    "# experiment_times = ['pauseA', 'pauseB']\n",
    "\n",
    "decodes = []\n",
    "errors = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded(info, experiment_times, pickle_filepath, get_zone_proportion))\n",
    "    errors.append(get_decoded(info, experiment_times, pickle_filepath, get_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_errors(errors):\n",
    "    \n",
    "    combine_errors = OrderedDict()\n",
    "\n",
    "    for key in errors[0].keys():\n",
    "        combine_errors[key] = dict(u=[], shortcut=[], novel=[], together=[])\n",
    "        for error in errors:\n",
    "            for trajectory in error[key].keys():\n",
    "                combine_errors[key][trajectory].extend(error[key][trajectory])\n",
    "                combine_errors[key]['together'].extend(error[key][trajectory])\n",
    "                \n",
    "    return combine_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combine_errors = combine_errors(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(combine_errors['phase1']['together'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_time = 'phase1'\n",
    "filename = '_decode-' + experiment_time + '.pkl'\n",
    "decode_filename = info.session_id + filename\n",
    "pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "if os.path.isfile(pickled_decoded):\n",
    "    with open(pickled_decoded, 'rb') as fileobj:\n",
    "        decoded = pickle.load(fileobj)\n",
    "else:\n",
    "    raise ValueError(\"pickled decoded not found for \" + info.session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_decode(infos, filename, experiment_time, shuffle_id, tuning_curves=None):\n",
    "    total_times = []\n",
    "    combined_errors = []\n",
    "    combined_lengths = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "    combined_decoded = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "    for i, info in enumerate(infos):\n",
    "        decode_filename = info.session_id + filename\n",
    "        pickled_decoded = os.path.join(pickle_filepath, decode_filename)\n",
    "\n",
    "        if os.path.isfile(pickled_decoded):\n",
    "            with open(pickled_decoded, 'rb') as fileobj:\n",
    "                decoded = pickle.load(fileobj)\n",
    "        else:\n",
    "            if tuning_curves is None:\n",
    "                raise ValueError(\"tuning curves required when generating decoded\")\n",
    "            decoded = analyze(info, tuning_curves[i], experiment_time=experiment_time, shuffle_id=shuffle_id)\n",
    "\n",
    "        total_times.append(decoded['times'])\n",
    "\n",
    "        combined_lengths['u'].append(LineString(info.u_trajectory).length)\n",
    "        combined_lengths['shortcut'].append(LineString(info.shortcut_trajectory).length)\n",
    "        combined_lengths['novel'].append(LineString(info.novel_trajectory).length)\n",
    "\n",
    "        combined_decoded['u'].append(decoded['zones']['u'])\n",
    "        combined_decoded['shortcut'].append(decoded['zones']['shortcut'])\n",
    "        combined_decoded['novel'].append(decoded['zones']['novel'])\n",
    "        combined_decoded['other'].append(decoded['zones']['other'])\n",
    "        combined_decoded['together'].append(len(decoded['zones']['u'].time) +\n",
    "                                            len(decoded['zones']['shortcut'].time) +\n",
    "                                            len(decoded['zones']['novel'].time) +\n",
    "                                            len(decoded['zones']['other'].time))\n",
    "\n",
    "        keys = ['u', 'shortcut', 'novel']\n",
    "        combined_errors = dict(u=[], shortcut=[], novel=[], together=[])\n",
    "        for trajectory in keys:\n",
    "            combined_errors[trajectory].extend(decoded['errors'][trajectory])\n",
    "            combined_errors['together'].extend(decoded['errors'][trajectory])\n",
    "\n",
    "    output = dict()\n",
    "    output['combined_decoded'] = combined_decoded\n",
    "    output['combined_errors'] = combined_errors\n",
    "    output['total_times'] = total_times\n",
    "    output['combined_lengths'] = combined_lengths\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(infos, tuning_curves, by_trajectory, all_tracks_tc=False):\n",
    "    experiment_time = 'phase3'\n",
    "    print('getting decoded', experiment_time)\n",
    "    decoded = combine_decode(infos, '_decode-tracks.pkl', experiment_time=experiment_time,\n",
    "                             shuffle_id=False, tuning_curves=tuning_curves)\n",
    "\n",
    "    print('getting decoded', experiment_time, 'shuffled')\n",
    "    decoded_shuffle = combine_decode(infos, '_decode-tracks-shuffled.pkl', experiment_time=experiment_time,\n",
    "                                     shuffle_id=True, tuning_curves=tuning_curves)\n",
    "\n",
    "    if all_tracks_tc and by_trajectory:\n",
    "        filename = 'combined-errors_decoded_all-tracks_by-trajectory.png'\n",
    "    elif all_tracks_tc and not by_trajectory:\n",
    "        filename = 'combined-errors_decoded_all-tracks.png'\n",
    "    elif not all_tracks_tc and by_trajectory:\n",
    "        filename = 'combined-errors_decoded_by-trajectory.png'\n",
    "    else:\n",
    "        filename = 'combined-errors_decoded.pdf'\n",
    "    savepath = os.path.join(output_filepath, filename)\n",
    "    plot_decoded_errors(decoded['combined_errors'], decoded_shuffle['combined_errors'], by_trajectory, fliersize=2,\n",
    "                        savepath=savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decoded_errors(decode_errors, shuffled_errors, experiment_time, by_trajectory=False, fliersize=1, savepath=None):\n",
    "    \"\"\"Plots boxplot distance between decoded and actual position for decoded and shuffled_id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    decode_errors: dict of lists\n",
    "        With u, shortcut, novel, other, and together as keys.\n",
    "    shuffled_errors: dict of lists\n",
    "        With u, shortcut, novel, other, and together as keys.\n",
    "    by_trajectory: boolean\n",
    "    fliersize: int\n",
    "    savepath : str or None\n",
    "        Location and filename for the saved plot.\n",
    "\n",
    "    \"\"\"\n",
    "    if by_trajectory:\n",
    "        decoded_u = pd.DataFrame(dict(error=decode_errors[experiment_time]['u'], shuffled='Decoded_u'))\n",
    "        decoded_shortcut = pd.DataFrame(dict(error=decode_errors[experiment_time]['shortcut'], shuffled='Decoded_shortcut'))\n",
    "        decoded_novel = pd.DataFrame(dict(error=decode_errors[experiment_time]['novel'], shuffled='Decoded_novel'))\n",
    "        \n",
    "        shuffled_u = pd.DataFrame(dict(error=shuffled_errors[experiment_time]['u'], shuffled='ID-shuffle decoded_u'))\n",
    "        shuffled_shortcut = pd.DataFrame(dict(error=shuffled_errors[experiment_time]['shortcut'], shuffled='ID-shuffle decoded_shortcut'))\n",
    "        shuffled_novel = pd.DataFrame(dict(error=shuffled_errors[experiment_time]['novel'], shuffled='ID-shuffle decoded_novel'))\n",
    "\n",
    "        data = pd.concat([shuffled_u, decoded_u, shuffled_shortcut, decoded_shortcut, shuffled_novel, decoded_novel])\n",
    "        colours = 'colorblind'\n",
    "    else:\n",
    "        decoded_dict = dict(error=decode_errors[experiment_time]['together'], shuffled='Decoded')\n",
    "        shuffled_dict = dict(error=shuffled_errors[experiment_time]['together'], shuffled='ID-shuffle decoded')\n",
    "        decoded = pd.DataFrame(decoded_dict)\n",
    "        shuffled = pd.DataFrame(shuffled_dict)\n",
    "        data = pd.concat([shuffled, decoded])\n",
    "        colours = ['#ffffff', '#bdbdbd']\n",
    "\n",
    "        print('actual:', np.mean(decode_errors[experiment_time]['together']), \n",
    "              stats.sem(decode_errors[experiment_time]['together']))\n",
    "        print('shuffle:', np.mean(shuffled_errors[experiment_time]['together']), \n",
    "              stats.sem(shuffled_errors[experiment_time]['together']))\n",
    "\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    flierprops = dict(marker='o', markersize=fliersize, linestyle='none')\n",
    "    # ax = sns.boxplot(x='shuffled', y='error', data=data, palette=colours, flierprops=flierprops)\n",
    "    ax = sns.boxplot(x='shuffled', y='error', data=data, flierprops=flierprops)\n",
    "\n",
    "    edge_colour = '#252525'\n",
    "    for i, artist in enumerate(ax.artists):\n",
    "        artist.set_edgecolor(edge_colour)\n",
    "        artist.set_facecolor(colours[i])\n",
    "\n",
    "        for j in range(i*6, i*6+6):\n",
    "            line = ax.lines[j]\n",
    "            line.set_color(edge_colour)\n",
    "            line.set_mfc(edge_colour)\n",
    "            line.set_mec(edge_colour)\n",
    "\n",
    "    ax.set(xlabel=' ', ylabel=\"Error (cm)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    sns.despine()\n",
    "\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath, transparent=True)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decoded_errors(combine_errors, combine_errors, experiment_time='phase1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decoded_compare(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decoded_compare(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['phase1', 'phase2', 'phase3']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['prerecord', 'phase1', 'pauseA', 'phase2', 'pauseB', 'phase3', 'postrecord']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_times = ['prerecord', 'postrecord']\n",
    "\n",
    "decodes = []\n",
    "for info in infos:\n",
    "    decodes.append(get_decoded_proportions(info, experiment_times, pickle_filepath))\n",
    "    \n",
    "plot_compare_decoded(decodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "emi_shortcut = os.path.join(home, \"code\", \"emi_shortcut\")\n",
    "pickle_filepath = os.path.join(emi_shortcut, \"cache\", \"pickled\")\n",
    "# pickle_filepath = 'E:/code/emi_shortcut/cache/pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_all_tracks = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils_maze import get_xyedges, speed_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, lfp_theta = get_data(info)\n",
    "xedges, yedges = get_xyedges(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_pos = speed_threshold(position)\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]\n",
    "\n",
    "position_tc = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "track_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "\n",
    "tuning_curve = vdm.tuning_curve_2d(position_tc, track_spikes, xedges, yedges, gaussian_sigma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuning curves with high firing rates\n",
    "tc_sums = np.sum(np.sum(tuning_curve, axis=2), axis=1)\n",
    "np.where(tc_sums > 3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuning curves with low firing rates\n",
    "low_thresh = 1\n",
    "high_thresh = 3000\n",
    "tc_sums = np.sum(np.sum(tuning_curve, axis=2), axis=1)\n",
    "keep_neurons = (tc_sums > low_thresh) & (tc_sums < high_thresh)\n",
    "tuning_curve = tuning_curve[keep_neurons]\n",
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "for ii in range(10):\n",
    "    print(ii)\n",
    "    pp = plt.pcolormesh(yy, xx, tuning_curve[ii], cmap='pink_r')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decoding for phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_id = False\n",
    "from analyze_decode import get_edges, point_in_zones\n",
    "from utils_maze import find_zones\n",
    "\n",
    "experiment_time = 'phase1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_times = ['phase1', 'phase2', 'phase3', 'tracks']\n",
    "pedestal_times = ['pauseA', 'pauseB', 'prerecord', 'postrecord']\n",
    "\n",
    "spikes = spikes[keep_neurons]\n",
    "\n",
    "if experiment_time in track_times:\n",
    "    run_pos = speed_threshold(position, speed_limit=0.4)\n",
    "else:\n",
    "    run_pos = position\n",
    "\n",
    "track_starts = [info.task_times[experiment_time].start]\n",
    "track_stops = [info.task_times[experiment_time].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "# if shuffle_id:\n",
    "#     random.shuffle(tuning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(position.x, position.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(track_pos.x, track_pos.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track_pos.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info.task_times[experiment_time].start, info.task_times[experiment_time].stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if experiment_time == 'tracks':\n",
    "#     decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "#     epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "\n",
    "# else:\n",
    "decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                       info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "#     sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "#     z_thresh = 3.0\n",
    "#     power_thresh = 5.0\n",
    "#     merge_thresh = 0.02\n",
    "#     min_length = 0.01\n",
    "#     swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "#                                   power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "#     epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "#     if epochs_interest.n_epochs == 0:\n",
    "#         epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(decode_spikes[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(track_pos, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = plt.pcolormesh(counts, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tc_shape = tuning_curve.shape\n",
    "print(counts.shape)\n",
    "decoding_tc = tuning_curve.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "print(decoded.x.shape)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n",
    "print(decoded.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(decoded.x, decoded.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=40, min_length=3)\n",
    "    decoded_epochs = sequences.intersect(vdm.Epoch(info.task_times[experiment_time].start, \n",
    "                                                   info.task_times[experiment_time].stop))\n",
    "    decoded = decoded[decoded_epochs]\n",
    "else:\n",
    "    raise ValueError(\"decoded cannot be empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, expand_by=8)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time in ['phase1', 'phase2', 'phase3', 'tracks']:\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output['decoded'].n_samples / output['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(output['zones']['u'].x, output['zones']['u'].y, 'b.', ms=2)\n",
    "# plt.plot(output['zones']['other'].x, output['zones']['other'].y, 'r.', ms=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(output['errors']['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = output['zones']['u']\n",
    "\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "histogram, xs, ys = np.histogram2d(pos.x, pos.y, bins=xx.shape)\n",
    "\n",
    "pp = plt.pcolormesh(yy, xx, histogram, cmap='pink_r')\n",
    "plt.colorbar(pp)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve_filename = info.session_id + '_tuning-curve.pkl'\n",
    "pickled_tuning_curve = os.path.join(pickle_filepath, tuning_curve_filename)\n",
    "with open(pickled_tuning_curve, 'rb') as fileobj:\n",
    "    tuning_curve = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analyze_decode import analyze\n",
    "experiment_time = 'postrecord'\n",
    "dec = analyze(info, tuning_curve, experiment_time=experiment_time, shuffle_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec['decoded'].n_samples, dec['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading decode from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import info.r066d1 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_time = 'postrecord'\n",
    "decode_filename = info.session_id + '_decode-' + experiment_time + '.pkl'\n",
    "pickled_decode = os.path.join(pickle_filepath, decode_filename)\n",
    "with open(pickled_decode, 'rb') as fileobj:\n",
    "    decode = pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode['decoded'].n_samples / decode['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
