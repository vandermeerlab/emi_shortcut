{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "# import itertools\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "\n",
    "from load_data import get_pos, get_spikes\n",
    "from maze_functions import find_zones, trajectory_fields\n",
    "from plotting_functions import plot_intersects, plot_zone\n",
    "from decode_functions import get_edges\n",
    "\n",
    "import vdmlab as vdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.array([[2, 7],\n",
    "               [4, 5],\n",
    "               [6, 3],\n",
    "               [8, 1],\n",
    "               [2, 4]])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(xy, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'b.', ms=10)\n",
    "plt.xlim(0.5, 8.5)\n",
    "plt.ylim(0.5, 7.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), \n",
    "          vdm.SpikeTrain(np.array([0., 0., 2.])),\n",
    "          vdm.SpikeTrain(np.array([2., 2.4]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 2\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(position, spikes, xedges, yedges, sampling_rate=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in tuning_curves:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges, apply_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(time_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc = []\n",
    "for tuning_curve in tuning_curves:\n",
    "    decoding_tc.append(np.ravel(tuning_curve))\n",
    "decoding_tc = np.array(decoding_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = tuning_curves[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.y, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.y, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_spline = InterpolatedUnivariateSpline(position.time, position.x)\n",
    "y_spline = InterpolatedUnivariateSpline(position.time, position.y)\n",
    "actual_position = vdm.Position(np.hstack((x_spline(time_centers)[..., np.newaxis],\n",
    "                                         (y_spline(time_centers)[..., np.newaxis]))), time_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_position.x, actual_position.y, actual_position.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = np.abs(decoded.data - actual_position.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_error = np.nanmean(error)\n",
    "avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the 1D decoding work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 3])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(x, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), vdm.SpikeTrain(np.array([2.2, 2.43]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_binsize = 1\n",
    "tuning_curves = vdm.tuning_curve(position, spikes, binsize=pos_binsize, sampling_rate=1., gaussian_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tuning_curves[0], 'b')\n",
    "plt.plot(tuning_curves[1], 'm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, tuning_curves, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_edges = vdm.binned_position(position, pos_binsize)\n",
    "x_centers = (pos_edges[1:] + pos_edges[:-1]) / 2.\n",
    "x_centers = x_centers[..., np.newaxis]\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, x_centers, time_centers)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nan_idx = np.isnan(decoded.x)\n",
    "decoded = decoded[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spline = InterpolatedUnivariateSpline(position.time, position.x)\n",
    "actual_position = vdm.Position(spline(decoded.time), decoded.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_position.x, actual_position.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = np.abs(decoded.x - actual_position.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, actual_position.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_error = np.mean(error)\n",
    "avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# check velocity 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 3])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(x, time)\n",
    "\n",
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), \n",
    "          vdm.SpikeTrain(np.array([2.2, 2.4])),\n",
    "          vdm.SpikeTrain(np.array([0.6, 0.9])),\n",
    "          vdm.SpikeTrain(np.array([1., 1.1])), \n",
    "          vdm.SpikeTrain(np.array([1.7, 1.9]))]\n",
    "\n",
    "pos_binsize = 1\n",
    "tuning_curves = vdm.tuning_curve(position, spikes, binsize=pos_binsize, sampling_rate=1., gaussian_std=None)\n",
    "\n",
    "counts_binsize = 0.5\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, tuning_curves, counts_binsize)\n",
    "\n",
    "pos_edges = vdm.binned_position(position, pos_binsize)\n",
    "x_centers = (pos_edges[1:] + pos_edges[:-1]) / 2.\n",
    "x_centers = x_centers[..., np.newaxis]\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, x_centers, time_centers)\n",
    "\n",
    "nan_idx = np.isnan(decoded.x)\n",
    "decoded = decoded[~nan_idx]\n",
    "\n",
    "print(decoded.x, decoded.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode_jumps = vdm.remove_teleports(decoded, speed_thresh=0, min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode_jumps.time, decode_jumps.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts filtering parameter check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = [0.1, 0.025, 0.01, 0.002, None, 0.5, 1.0]\n",
    "error = [29.9113296726, 29.3032199091, 45.8427697608, 45.8427697608, 45.8427697608, 28.623598705, 29.0339763118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(std, error, '.', ms=15)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(25, 48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from load_data import get_pos, get_spikes, get_lfp\n",
    "\n",
    "import info.R063d2_info as r063d2\n",
    "import info.R063d3_info as r063d3\n",
    "info = r063d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import vdmlab as vdm\n",
    "\n",
    "from load_data import get_pos, get_spikes\n",
    "from maze_functions import find_zones\n",
    "from tuning_curves_functions import get_tc_1d, find_ideal\n",
    "from decode_functions import get_edges, point_in_zones, compare_rates\n",
    "from plotting_functions import plot_compare_decoded_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled\\\\'\n",
    "output_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\plots\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R063d2\n",
      "R063d3\n"
     ]
    }
   ],
   "source": [
    "infos = [r063d2, r063d3]\n",
    "# infos = [r063d2, r063d3, r063d4, r063d5, r063d6, r066d1, r066d2, r066d3, r066d4, r067d1]\n",
    "\n",
    "shuffle_id = False\n",
    "\n",
    "combined_errors = []\n",
    "combined_actual = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "combined_decoded = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "    spikes = get_spikes(info.spike_mat)\n",
    "\n",
    "    speed = position.speed(t_smooth=0.5)\n",
    "    run_idx = np.squeeze(speed.data) >= info.run_threshold\n",
    "    run_pos = position[run_idx]\n",
    "\n",
    "    # track_starts = [info.task_times['phase1'].start, info.task_times['phase2'].start, info.task_times['phase3'].start]\n",
    "    # track_stops = [info.task_times['phase1'].stop, info.task_times['phase2'].stop, info.task_times['phase3'].stop]\n",
    "\n",
    "    track_start = info.task_times['phase3'].start\n",
    "    track_stop = info.task_times['phase3'].stop\n",
    "\n",
    "    track_pos = run_pos.time_slice(track_start, track_stop)\n",
    "\n",
    "    track_spikes = [spiketrain.time_slice(track_start, track_stop) for spiketrain in spikes]\n",
    "\n",
    "    binsize = 3\n",
    "    xedges = np.arange(track_pos.x.min(), track_pos.x.max() + binsize, binsize)\n",
    "    yedges = np.arange(track_pos.y.min(), track_pos.y.max() + binsize, binsize)\n",
    "\n",
    "    tuning_curves = vdm.tuning_curve_2d(track_pos, track_spikes, xedges, yedges, gaussian_sigma=0.1)\n",
    "    if shuffle_id:\n",
    "        random.shuffle(tuning_curves)\n",
    "\n",
    "    counts_binsize = 0.025\n",
    "    time_edges = get_edges(run_pos, counts_binsize, lastbin=True)\n",
    "    counts = vdm.get_counts(track_spikes, time_edges, gaussian_std=0.025)\n",
    "\n",
    "    decoding_tc = []\n",
    "    for tuning_curve in tuning_curves:\n",
    "        decoding_tc.append(np.ravel(tuning_curve))\n",
    "    decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "    likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "    xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "    ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "    xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "    time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "    decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "    nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "    decoded = decoded[~nan_idx]\n",
    "\n",
    "    if not decoded.isempty:\n",
    "        decoded = vdm.remove_teleports(decoded, speed_thresh=10, min_length=3)\n",
    "\n",
    "    actual_x = np.interp(decoded.time, track_pos.time, track_pos.x)\n",
    "    actual_y = np.interp(decoded.time, track_pos.time, track_pos.y)\n",
    "\n",
    "    actual_position = vdm.Position(np.hstack((actual_x[..., np.newaxis], actual_y[..., np.newaxis])), decoded.time)\n",
    "\n",
    "    errors = actual_position.distance(decoded)\n",
    "\n",
    "    zones = find_zones(info, expand_by=7)\n",
    "    actual_zones = point_in_zones(actual_position, zones)\n",
    "    decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "    combined_errors.append(np.mean(errors))\n",
    "\n",
    "    combined_actual['u'].append(actual_zones['u'])\n",
    "    combined_actual['shortcut'].append(actual_zones['shortcut'])\n",
    "    combined_actual['novel'].append(actual_zones['novel'])\n",
    "    combined_actual['other'].append(actual_zones['other'])\n",
    "    combined_actual['together'].append(len(actual_zones['u'].time) + len(actual_zones['shortcut'].time) + \n",
    "                                       len(actual_zones['novel'].time) + len(actual_zones['other'].time))\n",
    "\n",
    "    combined_decoded['u'].append(decoded_zones['u'])\n",
    "    combined_decoded['shortcut'].append(decoded_zones['shortcut'])\n",
    "    combined_decoded['novel'].append(decoded_zones['novel'])\n",
    "    combined_decoded['other'].append(decoded_zones['other'])\n",
    "    combined_decoded['together'].append(len(decoded_zones['u'].time) + len(decoded_zones['shortcut'].time) +\n",
    "                                        len(decoded_zones['novel'].time) + len(decoded_zones['other'].time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Position' and 'Position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-61a6498b240f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2885\u001b[0;31m                           out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Position' and 'Position'"
     ]
    }
   ],
   "source": [
    "np.mean(combined_actual['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = ['u', 'shortcut', 'novel', 'other']\n",
    "\n",
    "actual = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "decode = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "for key in keys:\n",
    "    if len(combined_actual[key]) != len(combined_decoded[key]):\n",
    "        raise ValueError(\"must have same number of decoded and actual samples\")\n",
    "    for val in range(len(combined_actual[key])):\n",
    "        actual[key].append(len(combined_actual[key][val].time)/combined_actual['together'][val])\n",
    "        decode[key].append(len(combined_decoded[key][val].time)/combined_decoded['together'][val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_actual = dict(u=[], shortcut=[], novel=[], other=[])\n",
    "normalized_decoded = dict(u=[], shortcut=[], novel=[], other=[])\n",
    "\n",
    "if len(combined_actual[key]) != len(combined_decoded[key]):\n",
    "    raise ValueError(\"must have same number of decoded and actual samples\")\n",
    "\n",
    "n_sessions = len(combined_actual['together'])\n",
    "\n",
    "for val in range(n_sessions):\n",
    "    actual = dict()\n",
    "    decode = dict()\n",
    "    for key in keys:\n",
    "        actual[key] = combined_actual[key][val]\n",
    "        decode[key] = combined_decoded[key][val]\n",
    "    norm_actual = compare_rates(actual)\n",
    "    norm_decoded = compare_rates(decode)\n",
    "    for key in keys:\n",
    "        normalized_actual[key].append(norm_actual[key])\n",
    "        normalized_decoded[key].append(norm_decoded[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_compare_decoded_track(normalized_actual, normalized_decoded, str(round(np.mean(combined_errors), 2)), max_y=60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_compare_decoded_track(actual, decode, distance, max_y=1., savepath=None, savefig=False):\n",
    "    \"\"\"Plots barplot comparing decoded vs. actual position during track times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual_zones: dict\n",
    "        With u, shortcut, novel, other as keys, each a vdmlab.Position object.\n",
    "    decoded_zones: dict\n",
    "        With u, shortcut, novel, other as keys, each a vdmlab.Position object.\n",
    "    distance: str\n",
    "        Total distance between actual and decoded positions\n",
    "    savepath : str or None\n",
    "        Location and filename for the saved plot.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    actual_mean = dict()\n",
    "    actual_mean['u'] = np.mean(actual['u'])\n",
    "    actual_mean['shortcut'] = np.mean(actual['shortcut'])\n",
    "    actual_mean['novel'] = np.mean(actual['novel'])\n",
    "    actual_mean['other'] = np.mean(actual['other'])\n",
    "\n",
    "    actual_sem = dict()\n",
    "    actual_sem['u'] = stats.sem(actual['u'])\n",
    "    actual_sem['shortcut'] = stats.sem(actual['shortcut'])\n",
    "    actual_sem['novel'] = stats.sem(actual['novel'])\n",
    "    actual_sem['other'] = stats.sem(actual['other'])\n",
    "\n",
    "    decoded_mean = dict()\n",
    "    decoded_mean['u'] = np.mean(decode['u'])\n",
    "    decoded_mean['shortcut'] = np.mean(decode['shortcut'])\n",
    "    decoded_mean['novel'] = np.mean(decode['novel'])\n",
    "    decoded_mean['other'] = np.mean(decode['other'])\n",
    "\n",
    "    decoded_sem = dict()\n",
    "    decoded_sem['u'] = stats.sem(decode['u'])\n",
    "    decoded_sem['shortcut'] = stats.sem(decode['shortcut'])\n",
    "    decoded_sem['novel'] = stats.sem(decode['novel'])\n",
    "    decoded_sem['other'] = stats.sem(decode['other'])\n",
    "\n",
    "    actual_means = [actual_mean['u'], actual_mean['shortcut'], actual_mean['novel'], actual_mean['other']]\n",
    "    actual_sems = [actual_sem['u'], actual_sem['shortcut'], actual_sem['novel'], actual_sem['other']]\n",
    "\n",
    "    decoded_means = [decoded_mean['u'], decoded_mean['shortcut'], decoded_mean['novel'], decoded_mean['other']]\n",
    "    decoded_sems = [decoded_sem['u'], decoded_sem['shortcut'], decoded_sem['novel'], decoded_sem['other']]\n",
    "\n",
    "    n_groups = np.arange(4)\n",
    "    width = 0.45\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.bar(n_groups, actual_means, width, color=['#5975a4', '#5f9e6e', '#b55d5f', '#c51b8A'],\n",
    "           label='Actual', yerr=actual_sems, ecolor='k')\n",
    "    ax.bar(n_groups+width, decoded_means, width, color=['b', 'g', 'r', 'm'],\n",
    "           label='Decoded', yerr=decoded_sems, ecolor='k')\n",
    "    plt.ylabel('Proportion of points')\n",
    "    sns.despine()\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(n_groups + width)\n",
    "    ax.set_xticklabels(['U', 'Shortcut', 'Novel', 'Other'])\n",
    "    ax.set_ylim(0., max_y)\n",
    "    ax.text(width*6, max_y*-0.15, 'total distance: ' + distance, fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        plt.savefig(savepath, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1 * -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decode_functions import point_in_zones\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def point_in_zones(position, zones):\n",
    "    \"\"\"Assigns points if contained in shortcut zones\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    position : vdmlab.Position\n",
    "    zones : dict\n",
    "        With u, ushort, unovel, shortcut, shortped, novel, novelped, pedestal as keys\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_zones : dict\n",
    "        With u, shortcut, novel, other as keys, each a vdmlab.Position object\n",
    "\n",
    "    \"\"\"\n",
    "    u_data = []\n",
    "    u_times = []\n",
    "    shortcut_data = []\n",
    "    shortcut_times = []\n",
    "    novel_data = []\n",
    "    novel_times = []\n",
    "    other_data = []\n",
    "    other_times = []\n",
    "\n",
    "    for x, y, time in zip(position.x, position.y, position.time):\n",
    "        point = Point([x, y])\n",
    "        if zones['u'].contains(point) or zones['ushort'].contains(point) or zones['unovel'].contains(point):\n",
    "            u_data.append([x, y])\n",
    "            u_times.append(time)\n",
    "            continue\n",
    "        elif zones['shortcut'].contains(point) or zones['shortped'].contains(point):\n",
    "            shortcut_data.append([x, y])\n",
    "            shortcut_times.append(time)\n",
    "            continue\n",
    "        elif zones['novel'].contains(point) or zones['novelped'].contains(point):\n",
    "            novel_data.append([x, y])\n",
    "            novel_times.append(time)\n",
    "            continue\n",
    "        else:\n",
    "            other_data.append([x, y])\n",
    "            other_times.append(time)\n",
    "\n",
    "    sorted_zones = dict()\n",
    "    sorted_zones['u'] = vdm.Position(u_data, u_times)\n",
    "    sorted_zones['shortcut'] = vdm.Position(shortcut_data, shortcut_times)\n",
    "    sorted_zones['novel'] = vdm.Position(novel_data, novel_times)\n",
    "    sorted_zones['other'] = vdm.Position(other_data, other_times)\n",
    "\n",
    "    return sorted_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, expand_by=7)\n",
    "actual_zones = point_in_zones(actual_position, zones)\n",
    "decoded_zones = point_in_zones(decoded, zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(actual_zones['other'].time), len(decoded_zones['other'].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(decoded.time), len(actual_position.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_compare_decoded_track(actual, decode, distance, savepath=None, savefig=True):\n",
    "    \"\"\"Plots barplot comparing decoded vs. actual position during track times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual_zones: dict\n",
    "        With u, shortcut, novel, other as keys, each a vdmlab.Position object.\n",
    "    decoded_zones: dict\n",
    "        With u, shortcut, novel, other as keys, each a vdmlab.Position object.\n",
    "    distance: str\n",
    "        Total distance between actual and decoded positions\n",
    "    savepath : str or None\n",
    "        Location and filename for the saved plot.\n",
    "\n",
    "    \"\"\"\n",
    "    actual = [actual['u'], actual['shortcut'], actual['novel'], actual['other']]\n",
    "    decode = [decode['u'], decode['shortcut'], decode['novel'], decode['other']]\n",
    "\n",
    "    n_groups = np.arange(4)\n",
    "    width = 0.45\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.bar(n_groups, actual, width, color=['#5975a4', '#5f9e6e', '#b55d5f', '#c51b8A'], label='Actual')\n",
    "    ax.bar(n_groups+width, decode, width, color=['b', 'g', 'r', 'm'], label='Decoded')\n",
    "    plt.ylabel('Proportion of points')\n",
    "    sns.despine()\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(n_groups + width)\n",
    "    ax.set_xticklabels(['U', 'Shortcut', 'Novel', 'Other'])\n",
    "#     ax.set_ylim(0., 1.)\n",
    "    ax.text(width*5, 0.8, 'total distance: ' + distance, fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        plt.savefig(savepath, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_actual = (len(actual_zones['novel'].time) +\n",
    "                    len(actual_zones['shortcut'].time) +\n",
    "                    len(actual_zones['u'].time) +\n",
    "                    len(actual_zones['other'].time))\n",
    "\n",
    "total_decoded = (len(decoded_zones['u'].time) +\n",
    "                 len(decoded_zones['shortcut'].time) +\n",
    "                 len(decoded_zones['novel'].time) +\n",
    "                 len(decoded_zones['other'].time))\n",
    "actual = dict()\n",
    "actual['u'] = len(actual_zones['u'].time)/total_actual\n",
    "actual['shortcut'] = len(actual_zones['shortcut'].time)/total_actual\n",
    "actual['novel'] = len(actual_zones['novel'].time)/total_actual\n",
    "actual['other'] = len(actual_zones['other'].time)/total_actual\n",
    "\n",
    "decode = dict()\n",
    "decode['u'] = len(decoded_zones['u'].time)/total_decoded\n",
    "decode['shortcut'] = len(decoded_zones['shortcut'].time)/total_decoded\n",
    "decode['novel'] = len(decoded_zones['novel'].time)/total_decoded\n",
    "decode['other'] = len(decoded_zones['other'].time)/total_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_rates(zones, jump=0.1):\n",
    "    \"\"\"Compare position normalized by time spent in zone.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    zones: dict\n",
    "        With u, shortcut, novel, other as keys.\n",
    "    jump: float\n",
    "        Any duration above this amount will not be included.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    normalized : dict\n",
    "        With u, shortcut, novel, other as keys.\n",
    "    \n",
    "    \"\"\"\n",
    "    u_linger = np.diff(zones['u'].time)\n",
    "    shortcut_linger = np.diff(zones['shortcut'].time)\n",
    "    novel_linger = np.diff(zones['novel'].time)\n",
    "    other_linger = np.diff(zones['other'].time)\n",
    "    \n",
    "    u_linger = np.sum(u_linger[u_linger < jump])\n",
    "    shortcut_linger = np.sum(shortcut_linger[shortcut_linger < jump])\n",
    "    novel_linger = np.sum(novel_linger[novel_linger < jump])\n",
    "    other_linger = np.sum(other_linger[other_linger < jump])\n",
    "\n",
    "    normalized = dict()\n",
    "    normalized['u'] = len(zones['u'].time) / u_linger\n",
    "    normalized['shortcut'] = len(zones['shortcut'].time) / shortcut_linger\n",
    "    normalized['novel'] = len(zones['novel'].time) / novel_linger\n",
    "    if len(zones['other'].time) > 20:\n",
    "        normalized['other'] = len(zones['other'].time) / other_linger\n",
    "    else:\n",
    "        normalized['other'] = np.nan\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode = compare_rates(decoded_zones)\n",
    "\n",
    "print('u:', decode['u'])\n",
    "print('shortcut:', decode['shortcut'])\n",
    "print('novel:', decode['novel'])\n",
    "print('other:', decode['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = compare_rates(actual_zones)\n",
    "\n",
    "print('u:', actual['u'])\n",
    "print('shortcut:', actual['shortcut'])\n",
    "print('novel:', actual['novel'])\n",
    "print('other:', actual['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_compare_decoded_track(actual, decode, str(round(np.mean(errors), 2)), savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(actual_zones['u'].x, actual_zones['u'].y, 'b.')\n",
    "plt.plot(actual_zones['shortcut'].x, actual_zones['shortcut'].y, 'g.')\n",
    "plt.plot(actual_zones['novel'].x, actual_zones['novel'].y, 'r.')\n",
    "plt.plot(actual_zones['other'].x, actual_zones['other'].y, 'c.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(decoded_zones['u'].x, decoded_zones['u'].y, '.', color='b')\n",
    "plt.plot(decoded_zones['shortcut'].x, decoded_zones['shortcut'].y, '.', color='g')\n",
    "plt.plot(decoded_zones['novel'].x, decoded_zones['novel'].y, '.', color='r')\n",
    "plt.plot(decoded_zones['other'].x, decoded_zones['other'].y, '.', color='c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = [11.84, 16.73, 14.19, 5.20, 7.10, 8.79, 8.23, 10.16, 9.22, 13.20, 21.13, 11.32, 20.54, 17.58, 17.63, 7.79, 7.66, 22.53, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = 24\n",
    "test_xy = actual_position.data + np.random.normal(0, std, actual_position.data.shape)\n",
    "test_pos = vdm.Position(test_xy, actual_position.time)\n",
    "test_errors = actual_position.distance(test_pos)\n",
    "print('Test distance:', np.mean(test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference = 32\n",
    "test_xy = actual_position.data + difference\n",
    "test_pos = vdm.Position(test_xy, actual_position.time)\n",
    "test_errors = actual_position.distance(test_pos)\n",
    "print('Test distance:', np.mean(test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(test_pos.x, test_pos.y, 'm.', ms=1)\n",
    "plt.plot(actual_position.x, actual_position.y, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import InterpolatedUnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-np.pi, np.pi, 10)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spline = InterpolatedUnivariateSpline(x, y)\n",
    "xs = np.linspace(-np.pi, np.pi, 100)\n",
    "plt.plot(xs, spline(xs), 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spline.get_residual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing parameter check r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [45.848643426859908, 29.302109714304461, 29.865521819738152, 29.913643399713909, \n",
    "           29.31095963377842, 28.624072044945866, 29.030549355726453, 30.077038030159233, \n",
    "           35.687684936555392, 45.848643426859908, 29.302109714304461, 29.865521819738152, \n",
    "           29.913643399713909, 29.31095963377842, 28.624072044945866, 29.030549355726453, \n",
    "           30.077038030159233, 35.687684936555392, 45.837111423306133, 29.298067119359189, \n",
    "           29.865976461880123, 29.906030473851345, 29.315789159414265, 28.624741085514444, \n",
    "           29.038110154705642, 30.079648033878346, 35.671749554313877, 31.61798486482013, \n",
    "           28.246634578841597, 29.647769711117515, 29.759165760476954, 29.411293543594194, \n",
    "           29.032704072802389, 29.042793425889936, 30.065880405200712, 35.645934498839758, \n",
    "           35.53800513968023, 28.658373941308831, 29.9207542421798, 29.708641610463751, \n",
    "           29.15494984997331, 28.578793132568546, 27.936605145242357, 29.258432270602221, \n",
    "           36.575977104419799, 36.941733764866761, 28.565957749459606, 31.102959353810512, \n",
    "           31.652782412930737, 31.239089639161165, 30.370535330601069, 30.036002190935022, \n",
    "           30.47971725975156, 34.304025317596022, 42.40508424723307, 36.370085788326456, \n",
    "           35.665673178845203, 35.775161545441925, 35.072970980897509, 33.78477541516596, \n",
    "           32.971823463940467, 32.494082917186063, 36.476158353888927, 45.262874125229665, \n",
    "           39.137571198808182, 38.514080294292121, 38.145109980432188, 37.304017745509341, \n",
    "           36.004485787827981, 34.679346348606181, 34.496813560336243, 39.817394108676588, \n",
    "           46.179512100491614, 43.733904525349814, 43.343444851581296, 42.579898778998576, \n",
    "           41.358252936093763, 39.791099877994974, 37.98070494210117, 36.890839324932948, \n",
    "           40.813685068781943, 49.4741802086211, 48.591570003593411, 47.833202625053076, \n",
    "           46.995084807712587, 46.078177190708551, 44.893523028409724, 43.235332282122172, \n",
    "           41.63670146397692, 42.87855295235785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [position, time]\n",
    "inputs = [[None, None], [None, 0.025], [None, 0.05], [None, 0.1], [None, 0.2], [None, 0.5], \n",
    "          [None, 1.0], [None, 2.0], [None, 5.0], [0.1, None], [0.1, 0.025], [0.1, 0.05], \n",
    "          [0.1, 0.1], [0.1, 0.2], [0.1, 0.5], [0.1, 1.0], [0.1, 2.0], [0.1, 5.0], [0.25, None], \n",
    "          [0.25, 0.025], [0.25, 0.05], [0.25, 0.1], [0.25, 0.2], [0.25, 0.5], [0.25, 1.0], \n",
    "          [0.25, 2.0], [0.25, 5.0], [0.5, None], [0.5, 0.025], [0.5, 0.05], [0.5, 0.1], [0.5, 0.2], \n",
    "          [0.5, 0.5], [0.5, 1.0], [0.5, 2.0], [0.5, 5.0], [1.0, None], [1.0, 0.025], [1.0, 0.05], \n",
    "          [1.0, 0.1], [1.0, 0.2], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 5.0], [3.0, None], \n",
    "          [3.0, 0.025], [3.0, 0.05], [3.0, 0.1], [3.0, 0.2], [3.0, 0.5], [3.0, 1.0], [3.0, 2.0], \n",
    "          [3.0, 5.0], [5.0, None], [5.0, 0.025], [5.0, 0.05], [5.0, 0.1], [5.0, 0.2], [5.0, 0.5], \n",
    "          [5.0, 1.0], [5.0, 2.0], [5.0, 5.0], [7.5, None], [7.5, 0.025], [7.5, 0.05], [7.5, 0.1], \n",
    "          [7.5, 0.2], [7.5, 0.5], [7.5, 1.0], [7.5, 2.0], [7.5, 5.0], [10.0, None], [10.0, 0.025], \n",
    "          [10.0, 0.05], [10.0, 0.1], [10.0, 0.2], [10.0, 0.5], [10.0, 1.0], [10.0, 2.0], [10.0, 5.0], \n",
    "          [15.0, None], [15.0, 0.025], [15.0, 0.05], [15.0, 0.1], [15.0, 0.2], [15.0, 0.5], \n",
    "          [15.0, 1.0], [15.0, 2.0], [15.0, 5.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "inputs = np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(results == min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 10\n",
    "inputs[val], results[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 19\n",
    "inputs[val], results[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 28\n",
    "inputs[val], results[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing parameter check r063d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [time, position]\n",
    "inputs = [[None, None], [None, 0.1], [None, 0.25], [None, 0.5], [None, 1.0], [None, 3.0], [None, 5.0], [None, 7.5], \n",
    "          [None, 10.0], [None, 15.0], [0.025, None], [0.025, 0.1], [0.025, 0.25], [0.025, 0.5], [0.025, 1.0], [0.025, 3.0], \n",
    "          [0.025, 5.0], [0.025, 7.5], [0.025, 10.0], [0.025, 15.0], [0.05, None], [0.05, 0.1], [0.05, 0.25], [0.05, 0.5], \n",
    "          [0.05, 1.0], [0.05, 3.0], [0.05, 5.0], [0.05, 7.5], [0.05, 10.0], [0.05, 15.0], [0.1, None], [0.1, 0.1], [0.1, 0.25], \n",
    "          [0.1, 0.5], [0.1, 1.0], [0.1, 3.0], [0.1, 5.0], [0.1, 7.5], [0.1, 10.0], [0.1, 15.0], [0.2, None], [0.2, 0.1], \n",
    "          [0.2, 0.25], [0.2, 0.5], [0.2, 1.0], [0.2, 3.0], [0.2, 5.0], [0.2, 7.5], [0.2, 10.0], [0.2, 15.0], [0.5, None], \n",
    "          [0.5, 0.1], [0.5, 0.25], [0.5, 0.5], [0.5, 1.0], [0.5, 3.0], [0.5, 5.0], [0.5, 7.5], [0.5, 10.0], [0.5, 15.0], \n",
    "          [1.0, None], [1.0, 0.1], [1.0, 0.25], [1.0, 0.5], [1.0, 1.0], [1.0, 3.0], [1.0, 5.0], [1.0, 7.5], [1.0, 10.0], \n",
    "          [1.0, 15.0], [2.0, None], [2.0, 0.1], [2.0, 0.25], [2.0, 0.5], [2.0, 1.0], [2.0, 3.0], [2.0, 5.0], [2.0, 7.5], \n",
    "          [2.0, 10.0], [2.0, 15.0], [5.0, None], [5.0, 0.1], [5.0, 0.25], [5.0, 0.5], [5.0, 1.0], [5.0, 3.0], [5.0, 5.0], \n",
    "          [5.0, 7.5], [5.0, 10.0], [5.0, 15.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "results = [35.231131061040671, 23.993012240227859, 24.958608788951562, 31.614563956638591, 30.060249486997485, nan, nan, \n",
    "          nan, nan, nan, 35.231131061040671, 23.993012240227859, 24.958608788951562, 31.614563956638591, 30.060249486997485, \n",
    "          nan, nan, nan, nan, nan, 35.231131061040671, 23.993012240227859, 24.958608788951562, 31.614563956638591, \n",
    "          30.060249486997485, nan, nan, nan, nan, nan, 35.231131061040671, 23.993012240227859, 24.958608788951562, \n",
    "          31.614563956638591, 30.060249486997485, nan, nan, nan, nan, nan, 35.243167496690631, 23.986385402892175, \n",
    "          24.958608788951562, 31.614563956638591, 30.060249486997485, nan, nan, nan, nan, nan, 36.687684162561489, \n",
    "          24.21184241467045, 25.081955729791964, 31.578593802111705, 29.904358245378063, nan, nan, nan, nan, nan, \n",
    "          36.465090354168112, 25.046352066083077, 26.493514951760506, 35.573266532195376, 43.974389805212944, nan, nan, \n",
    "          nan, nan, nan, 40.526575334651049, 27.200979868403344, 27.630098744507702, 40.861532245914212, 42.532905903890416, \n",
    "          nan, nan, nan, nan, nan, 39.691876087341186, 32.640087276459617, 32.217219984902279, 44.092366863934338, \n",
    "          52.264811100872024, nan, nan, nan, nan, nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = np.random.rand(20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_idx = np.array([4, 6, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_idx = [idx for idx in np.split(np.arange(pos.shape[0]), split_idx) if idx.size > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos[np.hstack(all_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time = np.linspace(0, np.pi*2, 201)\n",
    "data = np.hstack((np.sin(time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(time, data, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = vdm.Position(data, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speed = position.speed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(speed.time, speed.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_idx = np.squeeze(speed.data) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = vdm.Position(data, time)\n",
    "speed = position.speed()\n",
    "run_idx = np.squeeze(speed.data) >= 0.7\n",
    "run_position = position[run_idx]\n",
    "\n",
    "len(run_position.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert np.allclose(len(run_position.x), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "velocity = self[1:].distance(self[:-1])\n",
    "velocity /= np.diff(self.time)\n",
    "velocity = np.hstack(([0], velocity))\n",
    "\n",
    "if t_smooth is not None:\n",
    "    dt = np.median(np.diff(self.time))\n",
    "    filter_length = np.ceil(t_smooth / dt)\n",
    "    velocity = np.convolve(velocity, np.ones(int(filter_length))/filter_length, 'same')\n",
    "\n",
    "return AnalogSignal(velocity, self.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_smooth=0.5\n",
    "velocity = np.diff(np.squeeze(position.data))\n",
    "velocity /= np.diff(position.time)\n",
    "velocity = np.hstack(([0], velocity))\n",
    "\n",
    "dt = np.median(np.diff(position.time))\n",
    "filter_length = np.ceil(t_smooth / dt)\n",
    "velocity = np.convolve(velocity, np.ones(int(filter_length))/filter_length, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.hstack((a[0:2], a[6:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for t_start, t_stop in zip(np.array([0, 6]), np.array([2, 8])):\n",
    "    indices.append((a >= t_start) & (a <= t_stop))\n",
    "indices = np.any(np.column_stack((indices)),axis=1)\n",
    "a[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.any(np.column_stack((indices)),axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([0., 0., 1.])), vdm.SpikeTrain(np.array([3.6, 3.9]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_line = LineString([[2, 0], [2, 2], [2, 4], [2, 6], [2, 8], [2, 10]])\n",
    "\n",
    "one_start = Point([2, 2])\n",
    "one_stop = Point([2, 8])\n",
    "\n",
    "expand_by = 1\n",
    "\n",
    "one_zone = vdm.expand_line(one_start, one_stop, one_line, expand_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_idx = []\n",
    "for pos_idx in range(len(position.time)):\n",
    "    point = Point([position.x[pos_idx], position.y[pos_idx]])\n",
    "    if one_zone.contains(point):\n",
    "        this_idx.append(pos_idx)\n",
    "        \n",
    "this_pos = position[this_idx]\n",
    "linear = this_pos.linearize(one_line, one_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'g.', ms=10)\n",
    "# plt.plot([2, 4, 2], [7, 5, 4], 'm.', ms=20)\n",
    "plt.plot([2, 6], [4, 3], 'm.', ms=20)\n",
    "plt.plot(one_zone.exterior.xy[0], one_zone.exterior.xy[1], 'b', lw=1)\n",
    "plt.xlim(-1, 10)\n",
    "plt.ylim(-1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_line(start_pt, stop_pt, line, expand_by):\n",
    "    line_expanded = line.buffer(expand_by)\n",
    "    zone = start_pt.union(line_expanded).union(stop_pt)\n",
    "    \n",
    "    return zone\n",
    "\n",
    "def find_zones(info, expand_by=6):\n",
    "    u_line = LineString(info.u_trajectory)\n",
    "    shortcut_line = LineString(info.shortcut_trajectory)\n",
    "    novel_line = LineString(info.novel_trajectory)\n",
    "\n",
    "    u_start = Point(info.u_trajectory[0])\n",
    "    u_stop = Point(info.u_trajectory[-1])\n",
    "    shortcut_start = Point(info.shortcut_trajectory[0])\n",
    "    shortcut_stop = Point(info.shortcut_trajectory[-1])\n",
    "    novel_start = Point(info.novel_trajectory[0])\n",
    "    novel_stop = Point(info.novel_trajectory[-1])\n",
    "    pedestal_center = Point(info.path_pts['pedestal'][0], info.path_pts['pedestal'][1])\n",
    "    pedestal = pedestal_center.buffer(expand_by*2.2)\n",
    "\n",
    "    zone = dict()\n",
    "    zone['u'] = expand_line(u_start, u_stop, u_line, expand_by)\n",
    "    zone['shortcut'] = expand_line(shortcut_start, shortcut_stop, shortcut_line, expand_by)\n",
    "    zone['novel'] = expand_line(novel_start, novel_stop, novel_line, expand_by)\n",
    "    zone['ushort'] = zone['u'].intersection(zone['shortcut'])\n",
    "    zone['unovel'] = zone['u'].intersection(zone['novel'])\n",
    "    zone['uped'] = zone['u'].intersection(pedestal)\n",
    "    zone['shortped'] = zone['shortcut'].intersection(pedestal)\n",
    "    zone['novelped'] = zone['novel'].intersection(pedestal)\n",
    "    zone['pedestal'] = pedestal\n",
    "    \n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trajectory_fields(tuning_curves, zone, xedges, yedges, field_thresh):\n",
    "    \n",
    "    xcenters = np.array((xedges[1:] + xedges[:-1]) / 2.)\n",
    "    ycenters = np.array((yedges[1:] + yedges[:-1]) / 2.)\n",
    "    \n",
    "    tuning_points = []\n",
    "    for i in itertools.product(ycenters, xcenters):\n",
    "        tuning_points.append(i)\n",
    "    tuning_points = np.array(tuning_points)\n",
    "\n",
    "    this_neuron = 0\n",
    "    fields_tc = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    fields_neuron = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    for neuron_tc in tuning_curves:\n",
    "        this_neuron += 1\n",
    "        field_idx = neuron_tc.flatten() > field_thresh\n",
    "        field = tuning_points[field_idx]\n",
    "        for pt in field:\n",
    "            point = Point([pt[0], pt[1]])\n",
    "            if zone['u'].contains(point) or zone['ushort'].contains(point) or zone['unovel'].contains(point):\n",
    "                if this_neuron not in fields_neuron['u']:\n",
    "                    fields_tc['u'].append(neuron_tc)\n",
    "                    fields_neuron['u'].append(this_neuron)\n",
    "            if zone['shortcut'].contains(point) or zone['shortped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['shortcut']:\n",
    "                    fields_tc['shortcut'].append(neuron_tc)\n",
    "                    fields_neuron['shortcut'].append(this_neuron)\n",
    "            if zone['novel'].contains(point) or zone['novelped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['novel']:\n",
    "                    fields_tc['novel'].append(neuron_tc)\n",
    "                    fields_neuron['novel'].append(this_neuron)\n",
    "            if zone['pedestal'].contains(point):\n",
    "                if this_neuron not in fields_neuron['pedestal']:\n",
    "                    fields_tc['pedestal'].append(neuron_tc)\n",
    "                    fields_neuron['pedestal'].append(this_neuron)\n",
    "                \n",
    "    return fields_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\info')\n",
    "sys.path.append('E:\\\\code\\\\emi_shortcut\\\\info')\n",
    "import info.R063d3_info as r063d3\n",
    "info = r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filepath = 'E:\\\\code\\\\emi_shortcut\\\\cache\\\\pickled'\n",
    "# pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "spikes = get_spikes(info.spike_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= info.run_threshold\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "t_start = info.task_times['phase3'].start\n",
    "t_stop = info.task_times['phase3'].stop\n",
    "\n",
    "sliced_pos = run_pos.time_slice(t_start, t_stop)\n",
    "\n",
    "sliced_spikes = [spiketrain.time_slice(t_start, t_stop) for spiketrain in spikes]\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(sliced_pos, sliced_spikes, xedges, yedges, gaussian_sigma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(zones['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields_tc = trajectory_fields(tuning_curves, zones, xedges, yedges, field_thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(fields_tc['novel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in fields_tc['novel']:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
