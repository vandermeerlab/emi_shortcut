{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "# import itertools\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "\n",
    "from load_data import get_pos, get_spikes\n",
    "from maze_functions import find_zones, trajectory_fields\n",
    "from plotting_functions import plot_intersects, plot_zone\n",
    "from decode_functions import get_edges\n",
    "\n",
    "import vdmlab as vdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.array([[2, 7],\n",
    "               [4, 5],\n",
    "               [6, 3],\n",
    "               [8, 1],\n",
    "               [2, 4]])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(xy, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'b.', ms=10)\n",
    "plt.xlim(0.5, 8.5)\n",
    "plt.ylim(0.5, 7.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), \n",
    "          vdm.SpikeTrain(np.array([0., 0., 2.])),\n",
    "          vdm.SpikeTrain(np.array([2., 2.4]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 2\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(position, spikes, xedges, yedges, sampling_rate=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in tuning_curves:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges, apply_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(time_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc = []\n",
    "for tuning_curve in tuning_curves:\n",
    "    decoding_tc.append(np.ravel(tuning_curve))\n",
    "decoding_tc = np.array(decoding_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = tuning_curves[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.y, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.y, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_spline = InterpolatedUnivariateSpline(position.time, position.x)\n",
    "y_spline = InterpolatedUnivariateSpline(position.time, position.y)\n",
    "actual_position = vdm.Position(np.hstack((x_spline(time_centers)[..., np.newaxis],\n",
    "                                         (y_spline(time_centers)[..., np.newaxis]))), time_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_position.x, actual_position.y, actual_position.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = np.abs(decoded.data - actual_position.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_error = np.nanmean(error)\n",
    "avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the 1D decoding work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 3])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(x, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), vdm.SpikeTrain(np.array([2.2, 2.43]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_binsize = 1\n",
    "tuning_curves = vdm.tuning_curve(position, spikes, binsize=pos_binsize, sampling_rate=1., gaussian_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tuning_curves[0], 'b')\n",
    "plt.plot(tuning_curves[1], 'm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, tuning_curves, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_edges = vdm.binned_position(position, pos_binsize)\n",
    "x_centers = (pos_edges[1:] + pos_edges[:-1]) / 2.\n",
    "x_centers = x_centers[..., np.newaxis]\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, x_centers, time_centers)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nan_idx = np.isnan(decoded.x)\n",
    "decoded = decoded[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, decoded.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spline = InterpolatedUnivariateSpline(position.time, position.x)\n",
    "actual_position = vdm.Position(spline(decoded.time), decoded.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_position.x, actual_position.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = np.abs(decoded.x - actual_position.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded.x, actual_position.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_error = np.mean(error)\n",
    "avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# check velocity 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 3])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(x, time)\n",
    "\n",
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), \n",
    "          vdm.SpikeTrain(np.array([2.2, 2.4])),\n",
    "          vdm.SpikeTrain(np.array([0.6, 0.9])),\n",
    "          vdm.SpikeTrain(np.array([1., 1.1])), \n",
    "          vdm.SpikeTrain(np.array([1.7, 1.9]))]\n",
    "\n",
    "pos_binsize = 1\n",
    "tuning_curves = vdm.tuning_curve(position, spikes, binsize=pos_binsize, sampling_rate=1., gaussian_std=None)\n",
    "\n",
    "counts_binsize = 0.5\n",
    "time_edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, time_edges)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, tuning_curves, counts_binsize)\n",
    "\n",
    "pos_edges = vdm.binned_position(position, pos_binsize)\n",
    "x_centers = (pos_edges[1:] + pos_edges[:-1]) / 2.\n",
    "x_centers = x_centers[..., np.newaxis]\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, x_centers, time_centers)\n",
    "\n",
    "nan_idx = np.isnan(decoded.x)\n",
    "decoded = decoded[~nan_idx]\n",
    "\n",
    "print(decoded.x, decoded.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode_jumps = vdm.remove_teleports(decoded, speed_thresh=0, min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode_jumps.time, decode_jumps.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts filtering parameter check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = [0.1, 0.025, 0.01, 0.002, None, 0.5, 1.0]\n",
    "error = [29.9113296726, 29.3032199091, 45.8427697608, 45.8427697608, 45.8427697608, 28.623598705, 29.0339763118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(std, error, '.', ms=15)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(25, 48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_data import get_pos, get_spikes, get_lfp\n",
    "\n",
    "import info.R063d2_info as r063d2\n",
    "import info.R063d3_info as r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import vdmlab as vdm\n",
    "\n",
    "from load_data import get_pos, get_spikes\n",
    "from maze_functions import find_zones\n",
    "from tuning_curves_functions import get_tc_1d, find_ideal\n",
    "from decode_functions import get_edges, point_in_zones, compare_rates\n",
    "from plotting_functions import plot_compare_decoded_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled\\\\'\n",
    "# output_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\plots\\\\'\n",
    "pickle_filepath = 'E:\\\\code\\\\emi_shortcut\\\\cache\\\\pickled\\\\'\n",
    "output_filepath = 'E:\\\\code\\\\emi_shortcut\\\\plots\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infos = [r063d2, r063d3]\n",
    "# infos = [r063d2, r063d3, r063d4, r063d5, r063d6,\n",
    "#          r066d1, r066d2, r066d3, r066d4, r066d5,\n",
    "#          r067d1, r067d2, r067d3, r067d4, r067d5,\n",
    "#          r068d1, r068d2, r068d3, r068d4, r068d5]\n",
    "\n",
    "shuffle_id = False\n",
    "pauseB = False\n",
    "\n",
    "combined_errors = []\n",
    "combined_actual = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "combined_decoded = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "    spikes = get_spikes(info.spike_mat)\n",
    "\n",
    "    speed = position.speed(t_smooth=0.5)\n",
    "    run_idx = np.squeeze(speed.data) >= 0.5\n",
    "    run_pos = position[run_idx]\n",
    "\n",
    "    # track_starts = [info.task_times['phase1'].start, info.task_times['phase2'].start, info.task_times['phase3'].start]\n",
    "    # track_stops = [info.task_times['phase1'].stop, info.task_times['phase2'].stop, info.task_times['phase3'].stop]\n",
    "\n",
    "    track_start = info.task_times['phase3'].start\n",
    "    track_stop = info.task_times['phase3'].stop\n",
    "\n",
    "    track_pos = run_pos.time_slice(track_start, track_stop)\n",
    "\n",
    "    track_spikes = [spiketrain.time_slice(track_start, track_stop) for spiketrain in spikes]\n",
    "\n",
    "    binsize = 3\n",
    "    xedges = np.arange(track_pos.x.min(), track_pos.x.max() + binsize, binsize)\n",
    "    yedges = np.arange(track_pos.y.min(), track_pos.y.max() + binsize, binsize)\n",
    "\n",
    "    tuning_curves = vdm.tuning_curve_2d(track_pos, track_spikes, xedges, yedges, gaussian_sigma=0.1)\n",
    "    if shuffle_id:\n",
    "        random.shuffle(tuning_curves)\n",
    "\n",
    "    if pauseB:\n",
    "        decode_spikes = [spiketrain.time_slice(info.task_times['pauseB'].start, info.task_times['pauseB'].stop)\n",
    "                         for spiketrain in spikes]\n",
    "    else:\n",
    "        decode_spikes = track_spikes\n",
    "\n",
    "    counts_binsize = 0.025\n",
    "    time_edges = get_edges(run_pos, counts_binsize, lastbin=True)\n",
    "    counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.025)\n",
    "\n",
    "    decoding_tc = []\n",
    "    for tuning_curve in tuning_curves:\n",
    "        decoding_tc.append(np.ravel(tuning_curve))\n",
    "    decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "    likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "    xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "    ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "    xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "    time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "    decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "    nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "    decoded = decoded[~nan_idx]\n",
    "\n",
    "    if not decoded.isempty:\n",
    "        decoded = vdm.remove_teleports(decoded, speed_thresh=10, min_length=3)\n",
    "\n",
    "    actual_x = np.interp(decoded.time, track_pos.time, track_pos.x)\n",
    "    actual_y = np.interp(decoded.time, track_pos.time, track_pos.y)\n",
    "\n",
    "    actual_position = vdm.Position(np.hstack((actual_x[..., np.newaxis], actual_y[..., np.newaxis])), decoded.time)\n",
    "\n",
    "    errors = actual_position.distance(decoded)\n",
    "\n",
    "    zones = find_zones(info, expand_by=7)\n",
    "    actual_zones = point_in_zones(actual_position, zones)\n",
    "    decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "\n",
    "    combined_errors.append(np.mean(errors))\n",
    "\n",
    "    combined_actual['u'].append(actual_zones['u'])\n",
    "    combined_actual['shortcut'].append(actual_zones['shortcut'])\n",
    "    combined_actual['novel'].append(actual_zones['novel'])\n",
    "    combined_actual['other'].append(actual_zones['other'])\n",
    "    combined_actual['together'].append(len(actual_zones['u'].time) + len(actual_zones['shortcut'].time) +\n",
    "                                       len(actual_zones['novel'].time) + len(actual_zones['other'].time))\n",
    "\n",
    "    combined_decoded['u'].append(decoded_zones['u'])\n",
    "    combined_decoded['shortcut'].append(decoded_zones['shortcut'])\n",
    "    combined_decoded['novel'].append(decoded_zones['novel'])\n",
    "    combined_decoded['other'].append(decoded_zones['other'])\n",
    "    combined_decoded['together'].append(len(decoded_zones['u'].time) + len(decoded_zones['shortcut'].time) +\n",
    "                                        len(decoded_zones['novel'].time) + len(decoded_zones['other'].time))\n",
    "\n",
    "\n",
    "def compare_decoded_actual(combined_actual, combined_decoded, shuffle_id, pauseB, output_filepath):\n",
    "    keys = ['u', 'shortcut', 'novel', 'other']\n",
    "\n",
    "    actual = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "    decode = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "    n_sessions = len(combined_actual['together'])\n",
    "\n",
    "    for key in keys:\n",
    "        if len(combined_actual['together']) != len(combined_decoded['together']):\n",
    "            raise ValueError(\"must have same number of decoded and actual samples\")\n",
    "\n",
    "        for val in range(n_sessions):\n",
    "            actual[key].append(len(combined_actual[key][val].time)/combined_actual['together'][val])\n",
    "            decode[key].append(len(combined_decoded[key][val].time)/combined_decoded['together'][val])\n",
    "\n",
    "    if shuffle_id and not pauseB:\n",
    "        filename = 'combined-phase3-id_shuffle_decoded.png'\n",
    "    elif shuffle_id and pauseB:\n",
    "        filename = 'combined-pauseB-id_shuffle_decoded.png'\n",
    "    elif pauseB and not shuffle_id:\n",
    "        filename = 'combined-pauseB-id_decoded.png'\n",
    "    else:\n",
    "        filename = 'combined-phase3_decoded.png'\n",
    "    savepath = os.path.join(output_filepath, filename)\n",
    "\n",
    "    if pauseB:\n",
    "        plot_compare_decoded_track(decode, max_y=1.0, savepath=savepath)\n",
    "    else:\n",
    "        plot_compare_decoded_track(decode, actual, distance=str(round(np.mean(combined_errors), 2)),\n",
    "                                   max_y=1.0, savepath=savepath)\n",
    "\n",
    "    return combined_errors\n",
    "\n",
    "\n",
    "def normalized_time_spent(combined_actual, combined_decoded, shuffle_id, output_filepath):\n",
    "\n",
    "    keys = ['u', 'shortcut', 'novel', 'other']\n",
    "\n",
    "    normalized_actual = dict(u=[], shortcut=[], novel=[], other=[])\n",
    "    normalized_decoded = dict(u=[], shortcut=[], novel=[], other=[])\n",
    "\n",
    "    n_sessions = len(combined_actual['together'])\n",
    "\n",
    "    for val in range(n_sessions):\n",
    "        actual = dict()\n",
    "        decode = dict()\n",
    "        for key in keys:\n",
    "            actual[key] = combined_actual[key][val]\n",
    "            decode[key] = combined_decoded[key][val]\n",
    "        norm_actual = compare_rates(actual)\n",
    "        norm_decoded = compare_rates(decode)\n",
    "        for key in keys:\n",
    "            normalized_actual[key].append(norm_actual[key])\n",
    "            normalized_decoded[key].append(norm_decoded[key])\n",
    "\n",
    "    if shuffle_id:\n",
    "        filename = 'combined-norm_phase3-id_shuffle_decoded.png'\n",
    "    else:\n",
    "        filename = 'combined-norm_phase3_decoded.png'\n",
    "    savepath = os.path.join(output_filepath, filename)\n",
    "\n",
    "    y_label = 'Points normalized by time spent'\n",
    "    plot_compare_decoded_track(normalized_actual, normalized_decoded, y_label=y_label, max_y=60., savepath=savepath)\n",
    "\n",
    "\n",
    "compare_decoded_actual(combined_actual, combined_decoded, shuffle_id, pauseB, output_filepath)\n",
    "# plot_normalized = normalized_time_spent(combined_actual, combined_decoded, n_sessions, shuffle_id, output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_decoded_actual(combined_actual, combined_decoded, shuffle_id, pauseB, output_filepath):\n",
    "    keys = ['u', 'shortcut', 'novel', 'other']\n",
    "\n",
    "    actual = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "    decode = dict(u=[], shortcut=[], novel=[], other=[], together=[])\n",
    "\n",
    "    n_sessions = len(combined_actual['together'])\n",
    "\n",
    "    for key in keys:\n",
    "        if len(combined_actual['together']) != len(combined_decoded['together']):\n",
    "            raise ValueError(\"must have same number of decoded and actual samples\")\n",
    "\n",
    "        for val in range(n_sessions):\n",
    "            actual[key].append(len(combined_actual[key][val].time)/combined_actual['together'][val])\n",
    "            decode[key].append(len(combined_decoded[key][val].time)/combined_decoded['together'][val])\n",
    "\n",
    "    if shuffle_id and not pauseB:\n",
    "        filename = 'combined-phase3-id_shuffle_decoded.png'\n",
    "    elif shuffle_id and pauseB:\n",
    "        filename = 'combined-pauseB-id_shuffle_decoded.png'\n",
    "    elif pauseB and not shuffle_id:\n",
    "        filename = 'combined-pauseB-id_decoded.png'\n",
    "    else:\n",
    "        filename = 'combined-phase3_decoded.png'\n",
    "    savepath = os.path.join(output_filepath, filename)\n",
    "\n",
    "    if pauseB:\n",
    "        plot_compare_decoded_track(decode, max_y=1.0, savepath=savepath)\n",
    "    else:\n",
    "        plot_compare_decoded_track(decode, actual, distance=str(round(np.mean(combined_errors), 2)),\n",
    "                                   max_y=1.0, savepath=savepath)\n",
    "\n",
    "    return combined_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_decoded_actual(combined_actual, combined_decoded, shuffle_id, pauseB, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 0\n",
    "key = 'novel'\n",
    "((len(combined_actual[key][val].time)/combined_actual['together'][val]) + info.track_length[key]/total_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((len(combined_actual[key][val].time)/combined_actual['together'][val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(combined_actual[key][val].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info.track_length[key]/total_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_tracks = info.track_length['u'] + info.track_length['shortcut'] + info.track_length['novel'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(1*2)/(4+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/3 + 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_proportion = info.track_length['u']/total_tracks\n",
    "shortcut_proportion = info.track_length['shortcut']/total_tracks\n",
    "novel_proportion = info.track_length['novel']/total_tracks\n",
    "u_proportion + shortcut_proportion + novel_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(0.4 + 0.6)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(374-272)/info.pxl_to_cm[1] + (663-448)/info.pxl_to_cm[0] + (274-76)/info.pxl_to_cm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(220-118)/info.pxl_to_cm[0] + (286-45)/info.pxl_to_cm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(480-364)/info.pxl_to_cm[1] + (551-367)/info.pxl_to_cm[0] + (382-51)/info.pxl_to_cm[1] + (691-228)/info.pxl_to_cm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = np.random.rand(20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_idx = np.array([4, 6, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_idx = [idx for idx in np.split(np.arange(pos.shape[0]), split_idx) if idx.size > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos[np.hstack(all_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time = np.linspace(0, np.pi*2, 201)\n",
    "data = np.hstack((np.sin(time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(time, data, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = vdm.Position(data, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speed = position.speed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(speed.time, speed.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_idx = np.squeeze(speed.data) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = vdm.Position(data, time)\n",
    "speed = position.speed()\n",
    "run_idx = np.squeeze(speed.data) >= 0.7\n",
    "run_position = position[run_idx]\n",
    "\n",
    "len(run_position.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert np.allclose(len(run_position.x), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "velocity = self[1:].distance(self[:-1])\n",
    "velocity /= np.diff(self.time)\n",
    "velocity = np.hstack(([0], velocity))\n",
    "\n",
    "if t_smooth is not None:\n",
    "    dt = np.median(np.diff(self.time))\n",
    "    filter_length = np.ceil(t_smooth / dt)\n",
    "    velocity = np.convolve(velocity, np.ones(int(filter_length))/filter_length, 'same')\n",
    "\n",
    "return AnalogSignal(velocity, self.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_smooth=0.5\n",
    "velocity = np.diff(np.squeeze(position.data))\n",
    "velocity /= np.diff(position.time)\n",
    "velocity = np.hstack(([0], velocity))\n",
    "\n",
    "dt = np.median(np.diff(position.time))\n",
    "filter_length = np.ceil(t_smooth / dt)\n",
    "velocity = np.convolve(velocity, np.ones(int(filter_length))/filter_length, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.hstack((a[0:2], a[6:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for t_start, t_stop in zip(np.array([0, 6]), np.array([2, 8])):\n",
    "    indices.append((a >= t_start) & (a <= t_stop))\n",
    "indices = np.any(np.column_stack((indices)),axis=1)\n",
    "a[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.any(np.column_stack((indices)),axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([0., 0., 1.])), vdm.SpikeTrain(np.array([3.6, 3.9]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_line = LineString([[2, 0], [2, 2], [2, 4], [2, 6], [2, 8], [2, 10]])\n",
    "\n",
    "one_start = Point([2, 2])\n",
    "one_stop = Point([2, 8])\n",
    "\n",
    "expand_by = 1\n",
    "\n",
    "one_zone = vdm.expand_line(one_start, one_stop, one_line, expand_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_idx = []\n",
    "for pos_idx in range(len(position.time)):\n",
    "    point = Point([position.x[pos_idx], position.y[pos_idx]])\n",
    "    if one_zone.contains(point):\n",
    "        this_idx.append(pos_idx)\n",
    "        \n",
    "this_pos = position[this_idx]\n",
    "linear = this_pos.linearize(one_line, one_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'g.', ms=10)\n",
    "# plt.plot([2, 4, 2], [7, 5, 4], 'm.', ms=20)\n",
    "plt.plot([2, 6], [4, 3], 'm.', ms=20)\n",
    "plt.plot(one_zone.exterior.xy[0], one_zone.exterior.xy[1], 'b', lw=1)\n",
    "plt.xlim(-1, 10)\n",
    "plt.ylim(-1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_line(start_pt, stop_pt, line, expand_by):\n",
    "    line_expanded = line.buffer(expand_by)\n",
    "    zone = start_pt.union(line_expanded).union(stop_pt)\n",
    "    \n",
    "    return zone\n",
    "\n",
    "def find_zones(info, expand_by=6):\n",
    "    u_line = LineString(info.u_trajectory)\n",
    "    shortcut_line = LineString(info.shortcut_trajectory)\n",
    "    novel_line = LineString(info.novel_trajectory)\n",
    "\n",
    "    u_start = Point(info.u_trajectory[0])\n",
    "    u_stop = Point(info.u_trajectory[-1])\n",
    "    shortcut_start = Point(info.shortcut_trajectory[0])\n",
    "    shortcut_stop = Point(info.shortcut_trajectory[-1])\n",
    "    novel_start = Point(info.novel_trajectory[0])\n",
    "    novel_stop = Point(info.novel_trajectory[-1])\n",
    "    pedestal_center = Point(info.path_pts['pedestal'][0], info.path_pts['pedestal'][1])\n",
    "    pedestal = pedestal_center.buffer(expand_by*2.2)\n",
    "\n",
    "    zone = dict()\n",
    "    zone['u'] = expand_line(u_start, u_stop, u_line, expand_by)\n",
    "    zone['shortcut'] = expand_line(shortcut_start, shortcut_stop, shortcut_line, expand_by)\n",
    "    zone['novel'] = expand_line(novel_start, novel_stop, novel_line, expand_by)\n",
    "    zone['ushort'] = zone['u'].intersection(zone['shortcut'])\n",
    "    zone['unovel'] = zone['u'].intersection(zone['novel'])\n",
    "    zone['uped'] = zone['u'].intersection(pedestal)\n",
    "    zone['shortped'] = zone['shortcut'].intersection(pedestal)\n",
    "    zone['novelped'] = zone['novel'].intersection(pedestal)\n",
    "    zone['pedestal'] = pedestal\n",
    "    \n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trajectory_fields(tuning_curves, zone, xedges, yedges, field_thresh):\n",
    "    \n",
    "    xcenters = np.array((xedges[1:] + xedges[:-1]) / 2.)\n",
    "    ycenters = np.array((yedges[1:] + yedges[:-1]) / 2.)\n",
    "    \n",
    "    tuning_points = []\n",
    "    for i in itertools.product(ycenters, xcenters):\n",
    "        tuning_points.append(i)\n",
    "    tuning_points = np.array(tuning_points)\n",
    "\n",
    "    this_neuron = 0\n",
    "    fields_tc = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    fields_neuron = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    for neuron_tc in tuning_curves:\n",
    "        this_neuron += 1\n",
    "        field_idx = neuron_tc.flatten() > field_thresh\n",
    "        field = tuning_points[field_idx]\n",
    "        for pt in field:\n",
    "            point = Point([pt[0], pt[1]])\n",
    "            if zone['u'].contains(point) or zone['ushort'].contains(point) or zone['unovel'].contains(point):\n",
    "                if this_neuron not in fields_neuron['u']:\n",
    "                    fields_tc['u'].append(neuron_tc)\n",
    "                    fields_neuron['u'].append(this_neuron)\n",
    "            if zone['shortcut'].contains(point) or zone['shortped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['shortcut']:\n",
    "                    fields_tc['shortcut'].append(neuron_tc)\n",
    "                    fields_neuron['shortcut'].append(this_neuron)\n",
    "            if zone['novel'].contains(point) or zone['novelped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['novel']:\n",
    "                    fields_tc['novel'].append(neuron_tc)\n",
    "                    fields_neuron['novel'].append(this_neuron)\n",
    "            if zone['pedestal'].contains(point):\n",
    "                if this_neuron not in fields_neuron['pedestal']:\n",
    "                    fields_tc['pedestal'].append(neuron_tc)\n",
    "                    fields_neuron['pedestal'].append(this_neuron)\n",
    "                \n",
    "    return fields_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\info')\n",
    "sys.path.append('E:\\\\code\\\\emi_shortcut\\\\info')\n",
    "import info.R063d3_info as r063d3\n",
    "info = r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filepath = 'E:\\\\code\\\\emi_shortcut\\\\cache\\\\pickled'\n",
    "# pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "spikes = get_spikes(info.spike_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= info.run_threshold\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "t_start = info.task_times['phase3'].start\n",
    "t_stop = info.task_times['phase3'].stop\n",
    "\n",
    "sliced_pos = run_pos.time_slice(t_start, t_stop)\n",
    "\n",
    "sliced_spikes = [spiketrain.time_slice(t_start, t_stop) for spiketrain in spikes]\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(sliced_pos, sliced_spikes, xedges, yedges, gaussian_sigma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(zones['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields_tc = trajectory_fields(tuning_curves, zones, xedges, yedges, field_thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(fields_tc['novel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in fields_tc['novel']:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
