{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "import itertools\n",
    "\n",
    "from load_data import get_pos, get_spikes\n",
    "from maze_functions import find_zones, trajectory_fields\n",
    "from plotting_functions import plot_intersects, plot_zone\n",
    "from decode_functions import get_edges\n",
    "\n",
    "import vdmlab as vdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.array([[2, 7],\n",
    "               [4, 5],\n",
    "               [6, 3],\n",
    "               [8, 1],\n",
    "               [2, 4]])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(xy, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'b.', ms=10)\n",
    "plt.xlim(0.5, 8.5)\n",
    "plt.ylim(0.5, 7.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), vdm.SpikeTrain(np.array([2., 2.2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 2\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(position, spikes, xedges, yedges, sampling_rate=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in tuning_curves:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "\n",
    "edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, edges, apply_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc = []\n",
    "for tuning_curve in tuning_curves:\n",
    "    decoding_tc.append(np.ravel(tuning_curve))\n",
    "decoding_tc = np.array(decoding_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = tuning_curves[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoding_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood[7, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood[4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(likelihood[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_decoded_idx = []\n",
    "posbins = likelihood.shape[1]\n",
    "for posbin in range(posbins):\n",
    "    if np.sum(np.isnan(likelihood[:, posbin])) != (np.shape(likelihood)[1]-1):\n",
    "        max_decoded_idx.append(np.nanargmax(likelihood[:, posbin]))\n",
    "    else:\n",
    "        max_decoded_idx.append(np.nan)\n",
    "max_decoded_idx = np.array(max_decoded_idx)\n",
    "\n",
    "# max_decoded_idx = np.argmax(likelihood, axis=1)\n",
    "decoded = max_decoded_idx * (np.max(position.x)-np.min(position.x)) / (np.shape(likelihood)[1]-1)\n",
    "decoded += np.min(position.x)\n",
    "\n",
    "nan_idx = np.sum(np.isnan(likelihood), axis=1) == (np.shape(likelihood)[1]-1)\n",
    "decoded[nan_idx] = np.nan\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1.,2.,3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nul = np.array([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[~nul]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshaped = decoded.reshape(shape)\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the 1D decoding work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 3])\n",
    "time = np.array([0., 1., 2., 3., 4.])\n",
    "position = vdm.Position(x, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([3.6, 3.9])), vdm.SpikeTrain(np.array([2.2, 2.43]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves = vdm.tuning_curve(position, spikes, binsize=1, sampling_rate=1., gaussian_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tuning_curves[0], 'b')\n",
    "plt.plot(tuning_curves[1], 'm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_binsize = 0.5\n",
    "edges = get_edges(position, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(spikes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihood = vdm.bayesian_prob(counts, tuning_curves, counts_binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded_pos = vdm.decode_location(likelihood, position)\n",
    "decoded_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_decoded_idx = []\n",
    "posbins = likelihood.shape[1]\n",
    "for posbin in range(posbins):\n",
    "    if np.sum(np.isnan(likelihood[:, posbin])) != (np.shape(likelihood)[0]):\n",
    "        max_decoded_idx.append(np.nanargmax(likelihood[:, posbin]))\n",
    "    else:\n",
    "        max_decoded_idx.append(np.nan)\n",
    "max_decoded_idx = np.array(max_decoded_idx)\n",
    "\n",
    "decoded = max_decoded_idx * (np.max(position.x)-np.min(position.x)) / (np.shape(likelihood)[1]-1)\n",
    "decoded += np.min(position.x)\n",
    "\n",
    "nan_idx = np.sum(np.isnan(likelihood), axis=1) == (np.shape(likelihood)[1]-1)\n",
    "decoded[nan_idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.shape(likelihood)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.ones(6)\n",
    "index = (a == 1)\n",
    "index = np.hstack([index, 0, 0])\n",
    "a[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshaped = []\n",
    "for tc in decoding_tc:\n",
    "    reshaped.append(tc.reshape(shape))\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [vdm.SpikeTrain(np.array([0., 0., 1.])), vdm.SpikeTrain(np.array([3.6, 3.9]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_line = LineString([[2, 0], [2, 2], [2, 4], [2, 6], [2, 8], [2, 10]])\n",
    "\n",
    "one_start = Point([2, 2])\n",
    "one_stop = Point([2, 8])\n",
    "\n",
    "expand_by = 1\n",
    "\n",
    "one_zone = vdm.expand_line(one_start, one_stop, one_line, expand_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_idx = []\n",
    "for pos_idx in range(len(position.time)):\n",
    "    point = Point([position.x[pos_idx], position.y[pos_idx]])\n",
    "    if one_zone.contains(point):\n",
    "        this_idx.append(pos_idx)\n",
    "        \n",
    "this_pos = position[this_idx]\n",
    "linear = this_pos.linearize(one_line, one_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(position.x, position.y, 'g.', ms=10)\n",
    "# plt.plot([2, 4, 2], [7, 5, 4], 'm.', ms=20)\n",
    "plt.plot([2, 6], [4, 3], 'm.', ms=20)\n",
    "plt.plot(one_zone.exterior.xy[0], one_zone.exterior.xy[1], 'b', lw=1)\n",
    "plt.xlim(-1, 10)\n",
    "plt.ylim(-1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xcenters = np.array((xedges[1:] + xedges[:-1]) / 2.)\n",
    "ycenters = np.array((yedges[1:] + yedges[:-1]) / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_points = []\n",
    "for i in itertools.product(ycenters, xcenters):\n",
    "    tuning_points.append(i)\n",
    "tuning_points = np.array(tuning_points)\n",
    "tuning_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_thresh = 0\n",
    "fields_tc = []\n",
    "for neuron_tc in tuning_curves:\n",
    "    field_idx = neuron_tc.flatten() > field_thresh\n",
    "    field = tuning_points[field_idx]\n",
    "    for pt in field:\n",
    "        point = Point([pt[0], pt[1]])\n",
    "        if one_zone.contains(point):\n",
    "            fields_tc.append(neuron_tc)\n",
    "fields_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(spikes, edges, apply_filter=False, gaussian_std=0.02, gaussian_window=1.0):\n",
    "    dt = np.median(np.diff(edges))\n",
    "\n",
    "    gaussian_std /= dt\n",
    "    gaussian_window /= dt\n",
    "\n",
    "    if apply_filter and gaussian_std > dt:\n",
    "        gaussian_filter = signal.gaussian(gaussian_window, gaussian_std)\n",
    "        gaussian_filter /= np.sum(gaussian_filter)\n",
    "    elif apply_filter:\n",
    "        print('No gaussian filter applied. Check that gaussian_std > dt if filter desired.')\n",
    "\n",
    "    counts = np.zeros((int(len(spikes)), int(len(edges)-1)))\n",
    "    for idx, spiketrain in enumerate(spikes):\n",
    "        counts[idx] = np.histogram(spiketrain.time, bins=edges)[0]\n",
    "        if apply_filter and gaussian_std > dt:\n",
    "            counts[idx] = np.convolve(counts[idx], gaussian_filter, mode='same')\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([xedges, yedges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_counts_2d(spikes, position, xedges, yedges, apply_filter=False):\n",
    "    counts = []\n",
    "    for spiketrain in spikes:\n",
    "        spikes_x = []\n",
    "        spikes_y = []\n",
    "        for spike_time in spiketrain.time:\n",
    "            spike_idx = vdm.find_nearest_idx(position.time, spike_time)\n",
    "            spikes_x.append(position.x[spike_idx])\n",
    "            spikes_y.append(position.y[spike_idx])\n",
    "        spikes_2d, spikes_xedges, spikes_yedges = np.histogram2d(spikes_y, spikes_x, bins=[yedges, xedges])\n",
    "        counts.append(spikes_2d)\n",
    "        if apply_filter and gaussian_std > dt:\n",
    "                counts[idx] = np.convolve2d(counts[idx], gaussian_filter, mode='same')\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bayesian_prob(counts, tuning_curves, binsize, min_neurons=1, min_spikes=1):\n",
    "    n_time_bins = np.shape(counts)[1]\n",
    "    n_position_bins = np.shape(tuning_curves)[1]\n",
    "\n",
    "    likelihood = np.empty((n_time_bins, n_position_bins)) * np.nan\n",
    "\n",
    "    # Ignore warnings when inf created in this loop\n",
    "    error_settings = np.seterr(over='ignore')\n",
    "    for idx in range(n_position_bins):\n",
    "        valid_idx = tuning_curves[:, idx] > 1  # log of 1 or less is negative or invalid\n",
    "        if np.any(valid_idx):\n",
    "            # event_rate is the lambda in this poisson distribution\n",
    "            event_rate = tuning_curves[valid_idx, idx][..., np.newaxis] ** counts[valid_idx]\n",
    "            prior = np.exp(-binsize * np.sum(tuning_curves[valid_idx, idx]))\n",
    "\n",
    "            # Below is the same as\n",
    "            # likelihood[:, idx] = np.prod(event_rate, axis=0) * prior * (1/n_position_bins)\n",
    "            # only less likely to have floating point issues, though slower\n",
    "            likelihood[:, idx] = np.exp(np.sum(np.log(event_rate), axis=0)) * prior * (1/n_position_bins)\n",
    "    np.seterr(**error_settings)\n",
    "\n",
    "    # Set any inf value to be largest float\n",
    "    largest_float = np.finfo(float).max\n",
    "    likelihood[np.isinf(likelihood)] = largest_float\n",
    "    likelihood /= np.nansum(likelihood, axis=1)[..., np.newaxis]\n",
    "\n",
    "    # Remove bins with too few neurons that that are active\n",
    "    # a neuron is considered active by having at least min_spikes in a bin\n",
    "    n_active_neurons = np.sum(counts >= min_spikes, axis=0)\n",
    "    likelihood[n_active_neurons < min_neurons] = np.nan\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcenters = np.array((xedges[1:] + xedges[:-1]) / 2.)\n",
    "ycenters = np.array((yedges[1:] + yedges[:-1]) / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(xcenters, ycenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_line(start_pt, stop_pt, line, expand_by):\n",
    "    line_expanded = line.buffer(expand_by)\n",
    "    zone = start_pt.union(line_expanded).union(stop_pt)\n",
    "    \n",
    "    return zone\n",
    "\n",
    "def find_zones(info, expand_by=6):\n",
    "    u_line = LineString(info.u_trajectory)\n",
    "    shortcut_line = LineString(info.shortcut_trajectory)\n",
    "    novel_line = LineString(info.novel_trajectory)\n",
    "\n",
    "    u_start = Point(info.u_trajectory[0])\n",
    "    u_stop = Point(info.u_trajectory[-1])\n",
    "    shortcut_start = Point(info.shortcut_trajectory[0])\n",
    "    shortcut_stop = Point(info.shortcut_trajectory[-1])\n",
    "    novel_start = Point(info.novel_trajectory[0])\n",
    "    novel_stop = Point(info.novel_trajectory[-1])\n",
    "    pedestal_center = Point(info.path_pts['pedestal'][0], info.path_pts['pedestal'][1])\n",
    "    pedestal = pedestal_center.buffer(expand_by*2.2)\n",
    "\n",
    "    zone = dict()\n",
    "    zone['u'] = expand_line(u_start, u_stop, u_line, expand_by)\n",
    "    zone['shortcut'] = expand_line(shortcut_start, shortcut_stop, shortcut_line, expand_by)\n",
    "    zone['novel'] = expand_line(novel_start, novel_stop, novel_line, expand_by)\n",
    "    zone['ushort'] = zone['u'].intersection(zone['shortcut'])\n",
    "    zone['unovel'] = zone['u'].intersection(zone['novel'])\n",
    "    zone['uped'] = zone['u'].intersection(pedestal)\n",
    "    zone['shortped'] = zone['shortcut'].intersection(pedestal)\n",
    "    zone['novelped'] = zone['novel'].intersection(pedestal)\n",
    "    zone['pedestal'] = pedestal\n",
    "    \n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trajectory_fields(tuning_curves, zone, xedges, yedges, field_thresh):\n",
    "    \n",
    "    xcenters = np.array((xedges[1:] + xedges[:-1]) / 2.)\n",
    "    ycenters = np.array((yedges[1:] + yedges[:-1]) / 2.)\n",
    "    \n",
    "    tuning_points = []\n",
    "    for i in itertools.product(ycenters, xcenters):\n",
    "        tuning_points.append(i)\n",
    "    tuning_points = np.array(tuning_points)\n",
    "\n",
    "    this_neuron = 0\n",
    "    fields_tc = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    fields_neuron = dict(u=[], shortcut=[], novel=[], pedestal=[])\n",
    "    for neuron_tc in tuning_curves:\n",
    "        this_neuron += 1\n",
    "        field_idx = neuron_tc.flatten() > field_thresh\n",
    "        field = tuning_points[field_idx]\n",
    "        for pt in field:\n",
    "            point = Point([pt[0], pt[1]])\n",
    "            if zone['u'].contains(point) or zone['ushort'].contains(point) or zone['unovel'].contains(point):\n",
    "                if this_neuron not in fields_neuron['u']:\n",
    "                    fields_tc['u'].append(neuron_tc)\n",
    "                    fields_neuron['u'].append(this_neuron)\n",
    "            if zone['shortcut'].contains(point) or zone['shortped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['shortcut']:\n",
    "                    fields_tc['shortcut'].append(neuron_tc)\n",
    "                    fields_neuron['shortcut'].append(this_neuron)\n",
    "            if zone['novel'].contains(point) or zone['novelped'].contains(point):\n",
    "                if this_neuron not in fields_neuron['novel']:\n",
    "                    fields_tc['novel'].append(neuron_tc)\n",
    "                    fields_neuron['novel'].append(this_neuron)\n",
    "            if zone['pedestal'].contains(point):\n",
    "                if this_neuron not in fields_neuron['pedestal']:\n",
    "                    fields_tc['pedestal'].append(neuron_tc)\n",
    "                    fields_neuron['pedestal'].append(this_neuron)\n",
    "                \n",
    "    return fields_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\info')\n",
    "sys.path.append('E:\\\\code\\\\emi_shortcut\\\\info')\n",
    "import info.R063d3_info as r063d3\n",
    "info = r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filepath = 'E:\\\\code\\\\emi_shortcut\\\\cache\\\\pickled'\n",
    "# pickle_filepath = 'C:\\\\Users\\\\Emily\\\\Code\\\\emi_shortcut\\\\cache\\\\pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "spikes = get_spikes(info.spike_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binsize = 3\n",
    "xedges = np.arange(position.x.min(), position.x.max()+binsize, binsize)\n",
    "yedges = np.arange(position.y.min(), position.y.max()+binsize, binsize)\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= info.run_threshold\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "t_start = info.task_times['phase3'].start\n",
    "t_stop = info.task_times['phase3'].stop\n",
    "\n",
    "sliced_pos = run_pos.time_slice(t_start, t_stop)\n",
    "\n",
    "sliced_spikes = [spiketrain.time_slice(t_start, t_stop) for spiketrain in spikes]\n",
    "\n",
    "tuning_curves = vdm.tuning_curve_2d(sliced_pos, sliced_spikes, xedges, yedges, gaussian_sigma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(zones['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields_tc = trajectory_fields(tuning_curves, zones, xedges, yedges, field_thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(fields_tc['novel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_curves[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "for tuning_curve in fields_tc['novel']:\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap='YlGn')\n",
    "    plt.colorbar(pp)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
