{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib.inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import nept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(spikes, edges, gaussian_std=None, n_gaussian_std=5):\n",
    "    dt = np.median(np.diff(edges))\n",
    "\n",
    "    if gaussian_std is not None:\n",
    "        n_points = n_gaussian_std * gaussian_std * 2 / dt\n",
    "        n_points = max(n_points, 1.0)\n",
    "        if n_points % 2 == 0:\n",
    "            n_points += 1\n",
    "        if n_points > len(edges):\n",
    "            raise ValueError(\"gaussian_std is too large for these times\")\n",
    "        gaussian_filter = signal.gaussian(n_points, gaussian_std/dt)\n",
    "        gaussian_filter /= np.sum(gaussian_filter)\n",
    "\n",
    "    counts = np.zeros((len(spikes), len(edges)-1))\n",
    "    for idx, spiketrain in enumerate(spikes):\n",
    "        counts[idx] = np.histogram(spiketrain.time, bins=edges)[0]\n",
    "        if gaussian_std is not None and gaussian_std > dt:\n",
    "            counts[idx] = np.convolve(counts[idx], gaussian_filter, mode='same')\n",
    "\n",
    "    return nept.AnalogSignal(counts.T, edges[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikes = [nept.SpikeTrain([1., 1., 1., 5., 5., 7.])]\n",
    "\n",
    "edges = [0, 2.5, 4, 5, 6, 10]\n",
    "counts = get_counts(spikes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts.data, counts.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spikes = [nept.SpikeTrain([0.8, 1.1, 1.2, 1.2, 2.1, 3.1])]\n",
    "position = nept.Position(np.array([1., 6.]), np.array([0., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counts_sliding(spikes, position, n_dts, dt, gaussian_std=None, n_gaussian_std=5):   \n",
    "    dt_edges = np.arange(position.time[0], position.time[-1], dt)\n",
    "    square_filter = np.ones(n_dts)\n",
    "#     square_filter = np.ones(n_dts) * (1 / n_dts)\n",
    "    print(square_filter)\n",
    "    \n",
    "    if gaussian_std is not None:\n",
    "        n_points = n_gaussian_std * gaussian_std * 2 / dt\n",
    "        n_points = max(n_points, 1.0)\n",
    "        if n_points % 2 == 0:\n",
    "            n_points += 1\n",
    "        gaussian_filter = signal.gaussian(n_points, gaussian_std/dt)\n",
    "        gaussian_filter /= np.sum(gaussian_filter)\n",
    "        print(gaussian_filter)\n",
    "        \n",
    "        filtered_spikes = []\n",
    "        for spiketrain in spikes:\n",
    "            filtered_spikes.append(nept.SpikeTrain(np.convolve(spiketrain.time, gaussian_filter, mode='same'), spiketrain.label))\n",
    "            \n",
    "    else:\n",
    "        filtered_spikes = spikes\n",
    "    \n",
    "    counts = np.zeros((len(filtered_spikes), len(dt_edges)-1))\n",
    "    for idx, spiketrain in enumerate(filtered_spikes):\n",
    "        counts[idx] = np.convolve(np.histogram(spiketrain.time, bins=dt_edges)[0], square_filter, mode='same')\n",
    "    \n",
    "    return dt_edges, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, t = counts_sliding(spikes, position, n_dts=5, dt=0.5, gaussian_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = np.array([2., 2., 3., 1., 5., 2.])\n",
    "np.convolve(r, np.ones(4), mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
