{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:36:53.431305Z",
     "start_time": "2018-07-17T18:36:52.282860Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:36:53.436258Z",
     "start_time": "2018-07-17T18:36:53.433259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:36:53.449250Z",
     "start_time": "2018-07-17T18:36:53.438256Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from run import spike_sorted_infos\n",
    "import info.r063d5 as r063d5\n",
    "import info.r063d6 as r063d6\n",
    "infos = [r063d6]\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:36:53.985876Z",
     "start_time": "2018-07-17T18:36:53.968885Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decoded(info, position, spikes, xedges, yedges, shuffled_id, random_shuffle):\n",
    "    \n",
    "    min_n_spikes = 100\n",
    "    max_n_spikes = 5000\n",
    "    \n",
    "    phase = info.task_times[\"phase3\"]\n",
    "    trials = get_trials(events, phase)\n",
    "    \n",
    "    error_byactual_position = np.zeros((len(yedges), len(xedges)))\n",
    "    n_byactual_position = np.ones((len(yedges), len(xedges)))\n",
    "    \n",
    "    session_n_active = []\n",
    "    session_likelihoods = []\n",
    "    session_decoded = []\n",
    "    session_actual = []\n",
    "    session_errors = []\n",
    "    \n",
    "    for trial in trials:\n",
    "        epoch_of_interest = phase.excludes(trial)\n",
    "\n",
    "        tuning_curves = get_only_tuning_curves(position, \n",
    "                                               spikes, \n",
    "                                               xedges, \n",
    "                                               yedges, \n",
    "                                               epoch_of_interest,\n",
    "                                               min_n_spikes,\n",
    "                                               max_n_spikes)\n",
    "\n",
    "        if shuffled_id:\n",
    "            tuning_curves = np.random.permutation(tuning_curves)\n",
    "\n",
    "        sliced_position = position.time_slice(trial.start, trial.stop)\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(trial.start, \n",
    "                                               trial.stop) for spiketrain in spikes]\n",
    "\n",
    "        # limit position to only times when the subject is moving faster than a certain threshold\n",
    "        run_epoch = nept.run_threshold(sliced_position, thresh=10., t_smooth=0.8)\n",
    "        sliced_position = sliced_position[run_epoch]\n",
    "        sliced_spikes = [spiketrain.time_slice(run_epoch.start, \n",
    "                                               run_epoch.stop) for spiketrain in spikes]\n",
    "\n",
    "        epochs_interest = nept.Epoch(np.array([sliced_position.time[0], sliced_position.time[-1]]))\n",
    "\n",
    "        counts = nept.bin_spikes(sliced_spikes, sliced_position.time, dt=0.025, window=0.025,\n",
    "                                 gaussian_std=0.0075, normalized=False)\n",
    "        \n",
    "        min_neurons = 2\n",
    "        min_spikes = 2\n",
    "        \n",
    "        tc_shape = tuning_curves.shape\n",
    "        decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "        likelihood = nept.bayesian_prob(counts, decoding_tc, binsize=0.025, min_neurons=2, \n",
    "                                        min_spikes=min_spikes)\n",
    "\n",
    "        # Find decoded location based on max likelihood for each valid timestep\n",
    "        xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "        ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "        xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "        decoded = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "\n",
    "        if random_shuffle:\n",
    "            random_x = [np.random.choice(decoded.x) for val in decoded.x]\n",
    "            random_y = [np.random.choice(decoded.y) for val in decoded.y]\n",
    "\n",
    "            decoded = nept.Position(np.array([random_x, random_y]).T, decoded.time)\n",
    "\n",
    "        session_decoded.append(decoded)\n",
    "        \n",
    "        # Remove nans from likelihood and reshape for plotting\n",
    "        keep_idx = np.sum(np.isnan(likelihood), axis=1) < likelihood.shape[1]\n",
    "        likelihood = likelihood[keep_idx]\n",
    "        likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "\n",
    "        session_likelihoods.append(likelihood)\n",
    "        \n",
    "        n_active_neurons = np.asarray([n_active if n_active >= min_neurons else 0 \n",
    "                                       for n_active in np.sum(counts.data >= 1, axis=1)])\n",
    "        n_active_neurons = n_active_neurons[keep_idx]\n",
    "        session_n_active.append(n_active_neurons)\n",
    "\n",
    "        f_xy = scipy.interpolate.interp1d(sliced_position.time, sliced_position.data.T, kind=\"nearest\")\n",
    "        counts_xy = f_xy(decoded.time)\n",
    "        true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                                 counts_xy[1][..., np.newaxis])),\n",
    "                                      decoded.time)\n",
    "\n",
    "        session_actual.append(true_position)\n",
    "\n",
    "        trial_errors = true_position.distance(decoded)\n",
    "\n",
    "        for error, x, y in zip(trial_errors, true_position.x, true_position.y):\n",
    "            x_idx = nept.find_nearest_idx(xedges, x)\n",
    "            y_idx = nept.find_nearest_idx(yedges, y)\n",
    "            error_byactual_position[y_idx][x_idx] += error\n",
    "            n_byactual_position[y_idx][x_idx] += 1\n",
    "\n",
    "        session_errors.append(trial_errors)\n",
    "            \n",
    "#     error_byactual = error_byactual_position / n_byactual_position\n",
    "\n",
    "    return session_decoded, session_actual, session_likelihoods, session_errors, session_n_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:36:55.524609Z",
     "start_time": "2018-07-17T18:36:55.512616Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions):\n",
    "    \n",
    "    all_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "    all_errors_id_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_id_shuffled], axis=0)\n",
    "    all_errors_random_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_random_shuffled], axis=0)\n",
    "    \n",
    "    print('Actual:', np.median(all_errors))\n",
    "    print('ID shuffle:', np.median(all_errors_id_shuffled))\n",
    "    print('Random shuffle:', np.median(all_errors_random_shuffled)) \n",
    "\n",
    "    print('Actual:', np.mean(all_errors), stats.sem(all_errors))\n",
    "    print('ID shuffle:', np.mean(all_errors_id_shuffled), stats.sem(all_errors_id_shuffled))\n",
    "    print('Random shuffle:', np.mean(all_errors_random_shuffled), stats.sem(all_errors_random_shuffled)) \n",
    "    \n",
    "    fliersize = 1\n",
    "\n",
    "    decoded_dict = dict(error=all_errors, label='Decoded')\n",
    "    shuffled_id_dict = dict(error=all_errors_id_shuffled, label='ID shuffled')\n",
    "    shuffled_random_dict = dict(error=all_errors_random_shuffled, label='Random shuffled')\n",
    "    decoded_errors = pd.DataFrame(decoded_dict)\n",
    "    shuffled_id = pd.DataFrame(shuffled_id_dict)\n",
    "    shuffled_random = pd.DataFrame(shuffled_random_dict)\n",
    "    data = pd.concat([shuffled_id, shuffled_random, decoded_errors])\n",
    "    colours = ['#ffffff', '#ffffff', '#bdbdbd']\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    flierprops = dict(marker='o', markersize=fliersize, linestyle='none')\n",
    "    # ax = sns.boxplot(x='label', y='error', data=data, palette=colours, flierprops=flierprops)\n",
    "    ax = sns.boxplot(x='label', y='error', data=data, flierprops=flierprops)\n",
    "\n",
    "\n",
    "    edge_colour = '#252525'\n",
    "    for i, artist in enumerate(ax.artists):\n",
    "        artist.set_edgecolor(edge_colour)\n",
    "        artist.set_facecolor(colours[i])\n",
    "\n",
    "        for j in range(i*6, i*6+6):\n",
    "            line = ax.lines[j]\n",
    "            line.set_color(edge_colour)\n",
    "            line.set_mfc(edge_colour)\n",
    "            line.set_mec(edge_colour)\n",
    "\n",
    "    ax.text(1., 1., 'n_sessions = ' + str(n_sessions),\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            transform=ax.transAxes,\n",
    "            color='k', fontsize=10)\n",
    "\n",
    "    ax.set(xlabel=' ', ylabel=\"Error (cm)\")\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:41:05.461052Z",
     "start_time": "2018-07-17T18:36:56.345192Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_sessions = 0\n",
    "session_ids = []\n",
    "xedges = []\n",
    "yedges = []\n",
    "\n",
    "all_decoded = []\n",
    "all_actual = []\n",
    "all_likelihoods = []\n",
    "all_n_active = []\n",
    "\n",
    "all_errors = []\n",
    "all_errors_id_shuffled = []\n",
    "all_errors_random_shuffled = []\n",
    "\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    session_ids.append(info.session_id)\n",
    "    n_sessions += 1\n",
    "    events, position, spikes, _, _ = get_data(info)\n",
    "    binsize = 8\n",
    "    \n",
    "    xedge, yedge = nept.get_xyedges(position, binsize=binsize)\n",
    "    xedges.append(xedge)\n",
    "    yedges.append(yedge)\n",
    "    \n",
    "    xx, yy = np.meshgrid(xedge, yedge)\n",
    "    \n",
    "    \n",
    "    decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=False, \n",
    "                                             random_shuffle=False)\n",
    "    \n",
    "    _, _, _, errors_id_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=True, \n",
    "                                             random_shuffle=False)\n",
    "    \n",
    "    _, _, _, errors_random_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=False, \n",
    "                                             random_shuffle=True)\n",
    "    \n",
    "    all_decoded.append(decoded)\n",
    "    all_actual.append(actual)\n",
    "    all_likelihoods.append(likelihoods)\n",
    "    all_n_active.append(n_active)\n",
    "    \n",
    "    all_errors.append(errors)\n",
    "    all_errors_id_shuffled.append(errors_id_shuffled)\n",
    "    all_errors_random_shuffled.append(errors_random_shuffled)\n",
    "    \n",
    "plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions)\n",
    "\n",
    "combined_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:47:31.041966Z",
     "start_time": "2018-07-17T18:47:30.433737Z"
    }
   },
   "outputs": [],
   "source": [
    "for session_idx in range(n_sessions):\n",
    "    trial_idx = 1\n",
    "    decoded = all_decoded[session_idx][trial_idx]\n",
    "    true_position = all_actual[session_idx][trial_idx]\n",
    "    likelihoods = np.array(all_likelihoods[session_idx][trial_idx])\n",
    "    n_active = all_n_active[session_idx][trial_idx]\n",
    "    errors = all_errors[session_idx][trial_idx]\n",
    "    xedge = xedges[session_idx]\n",
    "    yedge = yedges[session_idx]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(5, 4)\n",
    "    \n",
    "    xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "    ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "    pad_amount = binsize*2\n",
    "    ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "    ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "    n_timebins = decoded.n_samples\n",
    "#     n_timebins = 10\n",
    "\n",
    "    n_colours = 20.\n",
    "    colours = [(1., 1., 1.)]\n",
    "    colours.extend(matplotlib.cm.copper_r(np.linspace(0, 1, n_colours-1)))\n",
    "    cmap = matplotlib.colors.ListedColormap(colours)\n",
    "    \n",
    "    likelihoods_withnan = np.array(likelihoods)\n",
    "    likelihoods[np.isnan(likelihoods)] = -0.01\n",
    "    \n",
    "    xcenters = xedge[:-1] + (xedge[1:] - xedge[:-1]) / 2\n",
    "    ycenters = yedge[:-1] + (yedge[1:] - yedge[:-1]) / 2\n",
    "\n",
    "    x_idx = [nept.find_nearest_idx(xcenters, true_position.x[timestep]) for timestep in range(true_position.n_samples)]\n",
    "    y_idx = [nept.find_nearest_idx(ycenters, true_position.y[timestep]) for timestep in range(true_position.n_samples)]\n",
    "    \n",
    "    x_dec_idx = [nept.find_nearest_idx(xcenters, decoded.x[timestep]) for timestep in range(decoded.n_samples)]\n",
    "    y_dec_idx = [nept.find_nearest_idx(ycenters, decoded.y[timestep]) for timestep in range(decoded.n_samples)]\n",
    "    \n",
    "#     cmap = plt.cm.get_cmap('bone_r')\n",
    "    posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihoods[0], vmax=0.2, cmap=cmap)\n",
    "    colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "    estimated_position, = ax1.plot([], [], \"o\", color=\"c\")\n",
    "    rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "\n",
    "    ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "\n",
    "    binwidth = 5.\n",
    "    error_bins = np.arange(-binwidth, np.max(errors)+binwidth, binwidth)\n",
    "\n",
    "    _, _, errors_bin = ax2.hist([np.clip(errors, error_bins[0], error_bins[-1])], bins=error_bins, rwidth=0.9, color=\"k\")\n",
    "    errors_idx = np.digitize(errors, error_bins)\n",
    "\n",
    "    likelihood_at_actual = ax2.text(0.6, 1, [],\n",
    "             horizontalalignment='left',\n",
    "             verticalalignment='top',\n",
    "             transform = ax2.transAxes,\n",
    "             fontsize=fontsize)\n",
    "    \n",
    "    # xlabels = [str(int(b)) for b in error_bins]\n",
    "    # xlabels[0] = \"nan\"\n",
    "    # ax2.set_xticklabels(xlabels)\n",
    "    fontsize = 14\n",
    "    ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "    ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    # xticks = binwidth * np.arange(0, len(xlabels)-1, 2) - binwidth\n",
    "    # xticks[0] = -binwidth/2.\n",
    "    xticks = binwidth * np.arange(0, len(error_bins), 4)\n",
    "    plt.xticks(xticks, fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "\n",
    "    ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "    \n",
    "    n_active_bins = np.arange(-0.5, np.max(n_active)+1)\n",
    "\n",
    "    _, _, n_neurons_bin = ax3.hist(n_active, bins=n_active_bins, rwidth=0.9, color=\"k\", align=\"mid\")\n",
    "\n",
    "    ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "    ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.yaxis.set_ticks_position('left')\n",
    "    ax3.xaxis.set_ticks_position('bottom')\n",
    "#     xticks = binwidth * np.arange(0, len(n_active_bins)+1)\n",
    "#     plt.xticks(xticks+binwidth/2)\n",
    "#     ax3.set_xticklabels(xticks, fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    def init():\n",
    "        posterior_position.set_array([])\n",
    "        estimated_position.set_data([], [])\n",
    "        rat_position.set_data([], [])\n",
    "        likelihood_at_actual.set_text([])\n",
    "        return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        posterior_position.set_array(likelihoods[i].ravel())\n",
    "        estimated_position.set_data(decoded.x[i], decoded.y[i])\n",
    "        rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "\n",
    "        for patch in errors_bin:\n",
    "            patch.set_fc('k')\n",
    "        errors_bin[errors_idx[i]-1].set_fc('r')\n",
    "\n",
    "        for patch in n_neurons_bin:\n",
    "            patch.set_fc('k')\n",
    "        n_neurons_bin[n_active[i]].set_fc('b')\n",
    "        \n",
    "        likelihood_at_actual.set_text(\"posterior at true position: %.3f \\nposterior at decoded position: %.3f \" % \n",
    "                                      (likelihoods_withnan[i][y_idx[i]][x_idx[i]], \n",
    "                                       likelihoods_withnan[i][y_dec_idx[i]][x_dec_idx[i]]))\n",
    "\n",
    "        return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=200, \n",
    "                                   blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#     writer = animation.writers['ffmpeg'](fps=18)\n",
    "#     dpi = 600\n",
    "#     filename = session_ids[session_idx]+'_decoded_trial'+str(trial_idx)+'.mp4'\n",
    "#     anim.save(os.path.join(output_filepath, filename), writer=writer, dpi=dpi)\n",
    "\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:47:37.208084Z",
     "start_time": "2018-07-17T18:47:31.721586Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Blue triangle is the true position; Cyan circle is the estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx = 1\n",
    "timestep = 0\n",
    "\n",
    "xcenters = xedges[:-1] + (xedges[1:] - xedges[:-1]) / 2\n",
    "ycenters = yedges[:-1] + (yedges[1:] - yedges[:-1]) / 2\n",
    "\n",
    "x_idx = [nept.find_nearest_idx(xcenters, actual[trial_idx].x[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "y_idx = [nept.find_nearest_idx(ycenters, actual[trial_idx].y[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "\n",
    "print(likelihoods[timestep][y_idx[timestep]][x_idx[timestep]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('bone_r')\n",
    "pp = plt.pcolormesh(xx[:-1], yy[:-1], likelihoods[timestep], cmap=cmap)\n",
    "colorbar = fig.colorbar(pp, ax=ax1)\n",
    "plt.plot(actual[trial_idx].x[timestep], actual[trial_idx].y[timestep], \"r.\", ms=10)\n",
    "colorbar = plt.colorbar(pp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T14:34:39.358762Z",
     "start_time": "2018-07-17T12:50:06.367Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined_errors = []\n",
    "# binsizes = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "# for binsize in binsizes:\n",
    "#     n_sessions = 0\n",
    "#     xxs = []\n",
    "#     yys = []\n",
    "\n",
    "#     all_decoded = []\n",
    "#     all_actual = []\n",
    "#     all_likelihoods = []\n",
    "#     all_n_active = []\n",
    "\n",
    "#     all_errors = []\n",
    "\n",
    "\n",
    "#     for info in infos:\n",
    "#         print(info.session_id)\n",
    "#         n_sessions += 1\n",
    "#         events, position, spikes, _, _ = get_data(info)\n",
    "#         xedges, yedges = nept.get_xyedges(position, binsize=binsize)\n",
    "\n",
    "#         xx, yy = np.meshgrid(xedges, yedges)\n",
    "#         xxs.append(xx)\n",
    "#         yys.append(yy)\n",
    "\n",
    "#         phase = \"phase3\"\n",
    "#         trial_epochs = get_trials(events, info.task_times[phase])\n",
    "\n",
    "#         decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "#                                                  position, \n",
    "#                                                  spikes, \n",
    "#                                                  xedges, \n",
    "#                                                  yedges, \n",
    "#                                                  shuffled_id=False, \n",
    "#                                                  random_shuffle=False)\n",
    "\n",
    "#         all_decoded.append(decoded)\n",
    "#         all_actual.append(actual)\n",
    "#         all_likelihoods.append(likelihoods)\n",
    "#         all_n_active.append(n_active)\n",
    "\n",
    "#         all_errors.append(errors)\n",
    "\n",
    "#     combined_errors.append(np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0))\n",
    "    \n",
    "# plt.plot(binsizes, np.mean(combined_errors, axis=1))\n",
    "# plt.xticks(binsizes)\n",
    "# plt.xlabel(\"Binsize (cm)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
