{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:38:03.219196Z",
     "start_time": "2018-07-23T13:37:55.479484Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:38:03.225193Z",
     "start_time": "2018-07-23T13:38:03.221195Z"
    }
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:38:03.238186Z",
     "start_time": "2018-07-23T13:38:03.228192Z"
    }
   },
   "outputs": [],
   "source": [
    "from run import spike_sorted_infos\n",
    "import info.r063d5 as r063d5\n",
    "import info.r063d6 as r063d6\n",
    "infos = [r063d5]\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:38:03.263172Z",
     "start_time": "2018-07-23T13:38:03.241184Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_decoded(info, position, spikes, xedges, yedges, shuffled_id):\n",
    "    \n",
    "    phase = info.task_times[\"phase3\"]\n",
    "    trials = get_trials(events, phase)\n",
    "    \n",
    "    error_byactual_position = np.zeros((len(yedges), len(xedges)))\n",
    "    n_byactual_position = np.ones((len(yedges), len(xedges)))\n",
    "    \n",
    "    session_n_active = []\n",
    "    session_likelihoods = []\n",
    "    session_decoded = []\n",
    "    session_actual = []\n",
    "    session_errors = []\n",
    "    \n",
    "    for trial in trials:\n",
    "        epoch_of_interest = phase.excludes(trial)\n",
    "\n",
    "        tuning_curves = get_only_tuning_curves(position, \n",
    "                                               spikes, \n",
    "                                               xedges, \n",
    "                                               yedges, \n",
    "                                               epoch_of_interest)\n",
    "\n",
    "        if shuffled_id:\n",
    "            tuning_curves = np.random.permutation(tuning_curves)\n",
    "\n",
    "        sliced_position = position.time_slice(trial.start, trial.stop)\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(trial.start, \n",
    "                                               trial.stop) for spiketrain in spikes]\n",
    "\n",
    "        # limit position to only times when the subject is moving faster than a certain threshold\n",
    "        run_epoch = nept.run_threshold(sliced_position, thresh=10., t_smooth=0.8)\n",
    "        sliced_position = sliced_position[run_epoch]\n",
    "        sliced_spikes = [spiketrain.time_slice(run_epoch.start, \n",
    "                                               run_epoch.stop) for spiketrain in spikes]\n",
    "\n",
    "        epochs_interest = nept.Epoch(np.array([sliced_position.time[0], sliced_position.time[-1]]))\n",
    "\n",
    "        counts = nept.bin_spikes(sliced_spikes, sliced_position.time, dt=0.025, window=0.025,\n",
    "                                 gaussian_std=0.0075, normalized=False)\n",
    "        \n",
    "        min_neurons = 2\n",
    "        min_spikes = 2\n",
    "        \n",
    "        tc_shape = tuning_curves.shape\n",
    "        decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "        likelihood = nept.bayesian_prob(counts, decoding_tc, binsize=0.025, min_neurons=2, \n",
    "                                        min_spikes=min_spikes)\n",
    "\n",
    "        # Find decoded location based on max likelihood for each valid timestep\n",
    "        xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "        ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "        xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "        decoded = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "\n",
    "        session_decoded.append(decoded)\n",
    "        \n",
    "        # Remove nans from likelihood and reshape for plotting\n",
    "        keep_idx = np.sum(np.isnan(likelihood), axis=1) < likelihood.shape[1]\n",
    "        likelihood = likelihood[keep_idx]\n",
    "        likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "\n",
    "        session_likelihoods.append(likelihood)\n",
    "        \n",
    "        n_active_neurons = np.asarray([n_active if n_active >= min_neurons else 0 \n",
    "                                       for n_active in np.sum(counts.data >= 1, axis=1)])\n",
    "        n_active_neurons = n_active_neurons[keep_idx]\n",
    "        session_n_active.append(n_active_neurons)\n",
    "\n",
    "        f_xy = scipy.interpolate.interp1d(sliced_position.time, sliced_position.data.T, kind=\"nearest\")\n",
    "        counts_xy = f_xy(decoded.time)\n",
    "        true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                                 counts_xy[1][..., np.newaxis])),\n",
    "                                      decoded.time)\n",
    "\n",
    "        session_actual.append(true_position)\n",
    "\n",
    "        trial_errors = true_position.distance(decoded)\n",
    "\n",
    "        for error, x, y in zip(trial_errors, true_position.x, true_position.y):\n",
    "            x_idx = nept.find_nearest_idx(xedges, x)\n",
    "            y_idx = nept.find_nearest_idx(yedges, y)\n",
    "            error_byactual_position[y_idx][x_idx] += error\n",
    "            n_byactual_position[y_idx][x_idx] += 1\n",
    "\n",
    "        session_errors.append(trial_errors)\n",
    "            \n",
    "#     error_byactual = error_byactual_position / n_byactual_position\n",
    "\n",
    "    return session_decoded, session_actual, session_likelihoods, session_errors, session_n_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:38:03.279163Z",
     "start_time": "2018-07-23T13:38:03.266170Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions, filename=None):\n",
    "    \n",
    "    all_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "    all_errors_id_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_id_shuffled], axis=0)\n",
    "\n",
    "#     print('Actual:', np.median(all_errors))\n",
    "#     print('ID shuffle:', np.median(all_errors_id_shuffled))\n",
    "\n",
    "#     print('Actual:', np.mean(all_errors), stats.sem(all_errors))\n",
    "#     print('ID shuffle:', np.mean(all_errors_id_shuffled), stats.sem(all_errors_id_shuffled))\n",
    "\n",
    "    fliersize = 1\n",
    "\n",
    "    decoded_dict = dict(error=all_errors, label='Decoded')\n",
    "    shuffled_id_dict = dict(error=all_errors_id_shuffled, label='ID shuffled')\n",
    "    decoded_errors = pd.DataFrame(decoded_dict)\n",
    "    shuffled_id = pd.DataFrame(shuffled_id_dict)\n",
    "    data = pd.concat([shuffled_id, decoded_errors])\n",
    "    colours = ['#ffffff', '#bdbdbd']\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    flierprops = dict(marker='o', markersize=fliersize, linestyle='none')\n",
    "    # ax = sns.boxplot(x='label', y='error', data=data, palette=colours, flierprops=flierprops)\n",
    "    ax = sns.boxplot(x='label', y='error', data=data, flierprops=flierprops)\n",
    "\n",
    "\n",
    "    edge_colour = '#252525'\n",
    "    for i, artist in enumerate(ax.artists):\n",
    "        artist.set_edgecolor(edge_colour)\n",
    "        artist.set_facecolor(colours[i])\n",
    "\n",
    "        for j in range(i*6, i*6+6):\n",
    "            line = ax.lines[j]\n",
    "            line.set_color(edge_colour)\n",
    "            line.set_mfc(edge_colour)\n",
    "            line.set_mec(edge_colour)\n",
    "    \n",
    "    ax.text(1., 1., \"N sessions: %d \\nmean-error: %.1f cm \\nmedian-error: %.1f cm\" % (n_sessions, \n",
    "                                                                                      np.mean(all_errors), \n",
    "                                                                                      np.median(all_errors)),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=10)\n",
    "\n",
    "    ax.set(xlabel=' ', ylabel=\"Error (cm)\")\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.126193Z",
     "start_time": "2018-07-23T13:45:35.274202Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binsize = 8\n",
    "n_sessions = 0\n",
    "session_ids = []\n",
    "xedges = []\n",
    "yedges = []\n",
    "\n",
    "all_decoded = []\n",
    "all_actual = []\n",
    "all_likelihoods = []\n",
    "all_n_active = []\n",
    "\n",
    "all_errors = []\n",
    "all_errors_id_shuffled = []\n",
    "all_errors_random_shuffled = []\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    session_ids.append(info.session_id)\n",
    "    n_sessions += 1\n",
    "    events, position, spikes, _, _ = get_data(info)\n",
    "\n",
    "    xedge, yedge = nept.get_xyedges(position, binsize=binsize)\n",
    "    xedges.append(xedge)\n",
    "    yedges.append(yedge)\n",
    "\n",
    "    xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "\n",
    "    decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=False)\n",
    "\n",
    "    _, _, _, errors_id_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=True)\n",
    "\n",
    "    all_decoded.append(decoded)\n",
    "    all_actual.append(actual)\n",
    "    all_likelihoods.append(likelihoods)\n",
    "    all_n_active.append(n_active)\n",
    "\n",
    "    all_errors.append(errors)\n",
    "    all_errors_id_shuffled.append(errors_id_shuffled)\n",
    "\n",
    "combined_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "\n",
    "filename = os.path.join(output_filepath, \"combined_errors-binsize\"+str(binsize)+\".png\")\n",
    "plot_errors(all_errors, all_errors_id_shuffled, n_sessions, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:55:54.294050Z",
     "start_time": "2018-07-23T13:55:54.138095Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(output_filepath, \"combined_errors-binsize\"+str(binsize)+\".png\")\n",
    "plot_errors(all_errors, all_errors_id_shuffled, n_sessions, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:58:34.020528Z",
     "start_time": "2018-07-23T13:58:34.008535Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.127193Z",
     "start_time": "2018-07-23T13:45:55.727Z"
    }
   },
   "outputs": [],
   "source": [
    "for trial_idx in range(2):\n",
    "    for session_idx in range(n_sessions):\n",
    "        decoded = all_decoded[session_idx][trial_idx]\n",
    "        true_position = all_actual[session_idx][trial_idx]\n",
    "        likelihoods = np.array(all_likelihoods[session_idx][trial_idx])\n",
    "        n_active = all_n_active[session_idx][trial_idx]\n",
    "        errors = all_errors[session_idx][trial_idx]\n",
    "        xedge = xedges[session_idx]\n",
    "        yedge = yedges[session_idx]\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        gs = gridspec.GridSpec(5, 4)\n",
    "\n",
    "        xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "        ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "        pad_amount = binsize*2\n",
    "        ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "        ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "        n_timebins = decoded.n_samples\n",
    "    #     n_timebins = 10\n",
    "\n",
    "        n_colours = 20.\n",
    "        colours = [(1., 1., 1.)]\n",
    "        colours.extend(matplotlib.cm.copper_r(np.linspace(0, 1, n_colours-1)))\n",
    "        cmap = matplotlib.colors.ListedColormap(colours)\n",
    "\n",
    "        likelihoods_withnan = np.array(likelihoods)\n",
    "        likelihoods[np.isnan(likelihoods)] = -0.01\n",
    "\n",
    "        xcenters = xedge[:-1] + (xedge[1:] - xedge[:-1]) / 2\n",
    "        ycenters = yedge[:-1] + (yedge[1:] - yedge[:-1]) / 2\n",
    "\n",
    "        x_idx = [nept.find_nearest_idx(xcenters, true_position.x[timestep]) for timestep in range(true_position.n_samples)]\n",
    "        y_idx = [nept.find_nearest_idx(ycenters, true_position.y[timestep]) for timestep in range(true_position.n_samples)]\n",
    "\n",
    "        x_dec_idx = [nept.find_nearest_idx(xcenters, decoded.x[timestep]) for timestep in range(decoded.n_samples)]\n",
    "        y_dec_idx = [nept.find_nearest_idx(ycenters, decoded.y[timestep]) for timestep in range(decoded.n_samples)]\n",
    "\n",
    "    #     cmap = plt.cm.get_cmap('bone_r')\n",
    "        posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihoods[0], vmax=0.2, cmap=cmap)\n",
    "        colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "        estimated_position, = ax1.plot([], [], \"o\", color=\"c\")\n",
    "        rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "\n",
    "        ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "\n",
    "        binwidth = 5.\n",
    "        error_bins = np.arange(-binwidth, np.max(errors)+binwidth, binwidth)\n",
    "\n",
    "        _, _, errors_bin = ax2.hist([np.clip(errors, error_bins[0], error_bins[-1])], bins=error_bins, rwidth=0.9, color=\"k\")\n",
    "        errors_idx = np.digitize(errors, error_bins)\n",
    "\n",
    "        fontsize = 14\n",
    "        likelihood_at_actual = ax2.text(0.6, 1, [],\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='top',\n",
    "                 transform = ax2.transAxes,\n",
    "                 fontsize=fontsize)\n",
    "\n",
    "        ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "        ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.yaxis.set_ticks_position('left')\n",
    "        ax2.xaxis.set_ticks_position('bottom')\n",
    "        # xticks = binwidth * np.arange(0, len(xlabels)-1, 2) - binwidth\n",
    "        # xticks[0] = -binwidth/2.\n",
    "        xticks = binwidth * np.arange(0, len(error_bins), 4)\n",
    "        plt.xticks(xticks, fontsize=fontsize)\n",
    "        plt.yticks(fontsize=fontsize)\n",
    "\n",
    "        ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "\n",
    "        n_active_bins = np.arange(-0.5, np.max(n_active)+1)\n",
    "\n",
    "        _, _, n_neurons_bin = ax3.hist(n_active, bins=n_active_bins, rwidth=0.9, color=\"k\", align=\"mid\")\n",
    "\n",
    "        ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "        ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.yaxis.set_ticks_position('left')\n",
    "        ax3.xaxis.set_ticks_position('bottom')\n",
    "    #     xticks = binwidth * np.arange(0, len(n_active_bins)+1)\n",
    "    #     plt.xticks(xticks+binwidth/2)\n",
    "    #     ax3.set_xticklabels(xticks, fontsize=fontsize)\n",
    "        plt.yticks(fontsize=fontsize)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "\n",
    "        def init():\n",
    "            posterior_position.set_array([])\n",
    "            estimated_position.set_data([], [])\n",
    "            rat_position.set_data([], [])\n",
    "            likelihood_at_actual.set_text([])\n",
    "            return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "\n",
    "        def animate(i):\n",
    "            posterior_position.set_array(likelihoods[i].ravel())\n",
    "            estimated_position.set_data(decoded.x[i], decoded.y[i])\n",
    "            rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "\n",
    "            for patch in errors_bin:\n",
    "                patch.set_fc('k')\n",
    "            errors_bin[errors_idx[i]-1].set_fc('r')\n",
    "\n",
    "            for patch in n_neurons_bin:\n",
    "                patch.set_fc('k')\n",
    "            n_neurons_bin[n_active[i]].set_fc('b')\n",
    "\n",
    "            likelihood_at_actual.set_text(\"posterior at true position: %.3f \\nposterior at decoded position: %.3f \" % \n",
    "                                          (likelihoods_withnan[i][y_idx[i]][x_idx[i]], \n",
    "                                           likelihoods_withnan[i][y_dec_idx[i]][x_dec_idx[i]]))\n",
    "\n",
    "            return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "        anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=200, \n",
    "                                       blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#         writer = animation.writers['ffmpeg'](fps=10)\n",
    "#         dpi = 600\n",
    "#         filename = session_ids[session_idx]+'_decoded_trial'+str(trial_idx)+'.mp4'\n",
    "#         anim.save(os.path.join(output_filepath, filename), writer=writer, dpi=dpi)\n",
    "\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.127193Z",
     "start_time": "2018-07-23T13:45:55.935Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Blue triangle is the true position; Cyan circle is the estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:59:53.404081Z",
     "start_time": "2018-07-23T13:59:53.401083Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T14:02:06.100097Z",
     "start_time": "2018-07-23T14:02:06.089104Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_line(start_pt, stop_pt, line, expand_by):\n",
    "    \"\"\"Expands shapely line into a zone.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_pt : shapely.Point\n",
    "    stop_pt : shapely.Point\n",
    "    line : shapely.LineString\n",
    "    expand_by : int or float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zone : shapely.Polygon\n",
    "\n",
    "    \"\"\"\n",
    "    line_expanded = line.buffer(expand_by)\n",
    "    zone = start_pt.union(line_expanded).union(stop_pt)\n",
    "\n",
    "    return zone\n",
    "\n",
    "\n",
    "def find_zones(info, remove_feeder, expand_by=6):\n",
    "    \"\"\"Finds zones from ideal trajectories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info : shortcut module\n",
    "    remove_feeder: boolean\n",
    "    expand_by : int or float\n",
    "        Amount to expand the line.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zone : dict\n",
    "        With shapely.Polygon as values.\n",
    "        Keys are u, shortcut, novel, ushort, unovel, uped, shortped,\n",
    "        novelped, pedestal.\n",
    "\n",
    "    \"\"\"\n",
    "    u_line = LineString(info.u_trajectory)\n",
    "    shortcut_line = LineString(info.shortcut_trajectory)\n",
    "    novel_line = LineString(info.novel_trajectory)\n",
    "\n",
    "    pedestal = Point(info.path_pts['pedestal'][0], info.path_pts['pedestal'][1]).buffer(expand_by*2.2)\n",
    "    feeder1 = Point(info.path_pts['feeder1'][0], info.path_pts['feeder1'][1]).buffer(expand_by*1.2)\n",
    "    feeder2 = Point(info.path_pts['feeder2'][0], info.path_pts['feeder2'][1]).buffer(expand_by*1.2)\n",
    "\n",
    "    u_zone = expand_line(Point(info.u_trajectory[0]), \n",
    "                         Point(info.u_trajectory[-1]), \n",
    "                         u_line, expand_by)\n",
    "    shortcut_zone = expand_line(Point(info.shortcut_trajectory[0]), \n",
    "                                Point(info.shortcut_trajectory[-1]), \n",
    "                                shortcut_line, expand_by)\n",
    "    novel_zone = expand_line(Point(info.novel_trajectory[0]), \n",
    "                             Point(info.novel_trajectory[-1]), \n",
    "                             novel_line, expand_by)\n",
    "\n",
    "    zone = dict()\n",
    "    zone['u'] = u_zone.difference(pedestal)\n",
    "    zone['shortcut'] = shortcut_zone.difference(u_zone)\n",
    "    zone['shortcut'] = zone['shortcut'].difference(novel_zone)\n",
    "    zone['shortcut'] = zone['shortcut'].difference(pedestal)\n",
    "    zone['novel'] = novel_zone.difference(u_zone)\n",
    "    zone['novel'] = zone['novel'].difference(pedestal)\n",
    "    zone['pedestal'] = pedestal\n",
    "\n",
    "    if remove_feeder:\n",
    "        for feeder in [feeder1, feeder2]:\n",
    "            zone['u'] = zone['u'].difference(feeder)\n",
    "            zone['shortcut'] = zone['shortcut'].difference(feeder)\n",
    "            zone['novel'] = zone['novel'].difference(feeder)\n",
    "            zone['pedestal'] = zone['pedestal'].difference(feeder)\n",
    "\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:18.158126Z",
     "start_time": "2018-07-23T16:37:18.147152Z"
    }
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, remove_feeder=True, expand_by=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:18.818453Z",
     "start_time": "2018-07-23T16:37:18.812457Z"
    }
   },
   "outputs": [],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:19.280480Z",
     "start_time": "2018-07-23T16:37:19.180539Z"
    }
   },
   "outputs": [],
   "source": [
    "zone = zones[\"u\"]\n",
    "plt.plot(zones[\"u\"].exterior.xy[0], zones[\"u\"].exterior.xy[1], 'b', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:20.658190Z",
     "start_time": "2018-07-23T16:37:20.652213Z"
    }
   },
   "outputs": [],
   "source": [
    "xcenters = xedge[:-1] + (xedge[1:] - xedge[:-1]) / 2\n",
    "ycenters = yedge[:-1] + (yedge[1:] - yedge[:-1]) / 2\n",
    "xcenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:21.474041Z",
     "start_time": "2018-07-23T16:37:21.468045Z"
    }
   },
   "outputs": [],
   "source": [
    "u_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "shortcut_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "novel_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "pedestal_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "\n",
    "u_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "shortcut_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "novel_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "pedestal_ybins = np.zeros(len(ycenters)).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:22.071376Z",
     "start_time": "2018-07-23T16:37:22.044386Z"
    }
   },
   "outputs": [],
   "source": [
    "for x_idx, xbin in enumerate(xcenters):\n",
    "    for y_idx, ybin in enumerate(ycenters):\n",
    "        point = Point([xbin, ybin])\n",
    "        if zones['u'].contains(point):\n",
    "            u_xbins[x_idx] = True\n",
    "            u_ybins[y_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:22.617099Z",
     "start_time": "2018-07-23T16:37:22.612121Z"
    }
   },
   "outputs": [],
   "source": [
    "u_xbins, u_ybins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:48:01.666306Z",
     "start_time": "2018-07-23T16:48:01.523500Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(phase1_position.x, phase1_position.y, \".\")\n",
    "plt.plot(zones[\"u\"].exterior.xy[0], zones[\"u\"].exterior.xy[1], 'b', lw=1)\n",
    "for intersect in zones[\"shortcut\"]:\n",
    "    plt.plot(intersect.exterior.xy[0], intersect.exterior.xy[1], 'g', lw=1)\n",
    "plt.plot(zones[\"novel\"].exterior.xy[0], zones[\"novel\"].exterior.xy[1], 'r', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T14:12:39.111121Z",
     "start_time": "2018-07-23T14:12:39.106123Z"
    }
   },
   "outputs": [],
   "source": [
    "shortcut_xbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:52:21.414318Z",
     "start_time": "2018-07-23T16:52:20.739506Z"
    }
   },
   "outputs": [],
   "source": [
    "events, position, spikes, _, _ = get_data(info)\n",
    "xedge, yedge = nept.get_xyedges(position, binsize=binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:52:33.572725Z",
     "start_time": "2018-07-23T16:52:33.563749Z"
    }
   },
   "outputs": [],
   "source": [
    "phase1_position = position.time_slice(info.task_times[\"phase1\"].start, info.task_times[\"phase1\"].stop)\n",
    "occupancy = nept.get_occupancy(phase1_position, yedge, xedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:54:03.061555Z",
     "start_time": "2018-07-23T16:54:03.051561Z"
    }
   },
   "outputs": [],
   "source": [
    "occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:53:26.838165Z",
     "start_time": "2018-07-23T16:53:26.834167Z"
    }
   },
   "outputs": [],
   "source": [
    "u_pos = np.zeros(occupancy.shape).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:54:11.503650Z",
     "start_time": "2018-07-23T16:54:11.499653Z"
    }
   },
   "outputs": [],
   "source": [
    "u_pos[occupancy > 0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:55:13.831497Z",
     "start_time": "2018-07-23T16:55:13.659596Z"
    }
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, occupancy, vmax=10., cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_zones(position, zones):\n",
    "    \"\"\"Assigns points to each trajectory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    position : nept.Position\n",
    "    zones : dict\n",
    "        With u, shortcut, novel, pedestal as keys\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_zones : dict\n",
    "        With u, shortcut, novel, other as keys, each a nept.Position object\n",
    "\n",
    "    \"\"\"\n",
    "    u_data = []\n",
    "    u_times = []\n",
    "    shortcut_data = []\n",
    "    shortcut_times = []\n",
    "    novel_data = []\n",
    "    novel_times = []\n",
    "    other_data = []\n",
    "    other_times = []\n",
    "\n",
    "    if not position.isempty:\n",
    "        for x, y, time in zip(position.x, position.y, position.time):\n",
    "            point = Point([x, y])\n",
    "            if zones['u'].contains(point):\n",
    "                u_data.append([x, y])\n",
    "                u_times.append(time)\n",
    "                continue\n",
    "            elif zones['shortcut'].contains(point):\n",
    "                shortcut_data.append([x, y])\n",
    "                shortcut_times.append(time)\n",
    "                continue\n",
    "            elif zones['novel'].contains(point):\n",
    "                novel_data.append([x, y])\n",
    "                novel_times.append(time)\n",
    "                continue\n",
    "            else:\n",
    "                other_data.append([x, y])\n",
    "                other_times.append(time)\n",
    "\n",
    "    sorted_zones = dict()\n",
    "    sorted_zones['u'] = nept.Position(u_data, u_times)\n",
    "    sorted_zones['shortcut'] = nept.Position(shortcut_data, shortcut_times)\n",
    "    sorted_zones['novel'] = nept.Position(novel_data, novel_times)\n",
    "    sorted_zones['other'] = nept.Position(other_data, other_times)\n",
    "\n",
    "    return sorted_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.317383Z",
     "start_time": "2018-07-23T13:37:55.533Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_idx = 1\n",
    "timestep = 0\n",
    "\n",
    "xcenters = xedges[:-1] + (xedges[1:] - xedges[:-1]) / 2\n",
    "ycenters = yedges[:-1] + (yedges[1:] - yedges[:-1]) / 2\n",
    "\n",
    "x_idx = [nept.find_nearest_idx(xcenters, actual[trial_idx].x[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "y_idx = [nept.find_nearest_idx(ycenters, actual[trial_idx].y[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "\n",
    "print(likelihoods[timestep][y_idx[timestep]][x_idx[timestep]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.318383Z",
     "start_time": "2018-07-23T13:37:55.539Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('bone_r')\n",
    "pp = plt.pcolormesh(xx[:-1], yy[:-1], likelihoods[timestep], cmap=cmap)\n",
    "colorbar = fig.colorbar(pp, ax=ax1)\n",
    "plt.plot(actual[trial_idx].x[timestep], actual[trial_idx].y[timestep], \"r.\", ms=10)\n",
    "colorbar = plt.colorbar(pp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.323380Z",
     "start_time": "2018-07-23T13:37:55.552Z"
    }
   },
   "outputs": [],
   "source": [
    "# combined_errors = []\n",
    "# binsizes = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "# for binsize in binsizes:\n",
    "#     n_sessions = 0\n",
    "#     xxs = []\n",
    "#     yys = []\n",
    "\n",
    "#     all_decoded = []\n",
    "#     all_actual = []\n",
    "#     all_likelihoods = []\n",
    "#     all_n_active = []\n",
    "\n",
    "#     all_errors = []\n",
    "\n",
    "\n",
    "#     for info in infos:\n",
    "#         print(info.session_id)\n",
    "#         n_sessions += 1\n",
    "#         events, position, spikes, _, _ = get_data(info)\n",
    "#         xedges, yedges = nept.get_xyedges(position, binsize=binsize)\n",
    "\n",
    "#         xx, yy = np.meshgrid(xedges, yedges)\n",
    "#         xxs.append(xx)\n",
    "#         yys.append(yy)\n",
    "\n",
    "#         phase = \"phase3\"\n",
    "#         trial_epochs = get_trials(events, info.task_times[phase])\n",
    "\n",
    "#         decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "#                                                  position, \n",
    "#                                                  spikes, \n",
    "#                                                  xedges, \n",
    "#                                                  yedges, \n",
    "#                                                  shuffled_id=False, \n",
    "#                                                  random_shuffle=False)\n",
    "\n",
    "#         all_decoded.append(decoded)\n",
    "#         all_actual.append(actual)\n",
    "#         all_likelihoods.append(likelihoods)\n",
    "#         all_n_active.append(n_active)\n",
    "\n",
    "#         all_errors.append(errors)\n",
    "\n",
    "#     combined_errors.append(np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0))\n",
    "    \n",
    "# plt.plot(binsizes, np.mean(combined_errors, axis=1))\n",
    "# plt.xticks(binsizes)\n",
    "# plt.xlabel(\"Binsize (cm)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
