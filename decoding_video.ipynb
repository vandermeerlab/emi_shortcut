{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T11:52:19.750090Z",
     "start_time": "2018-07-25T11:52:13.121033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials, get_zones, get_trial_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T11:52:19.756086Z",
     "start_time": "2018-07-25T11:52:19.752088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T11:52:19.766081Z",
     "start_time": "2018-07-25T11:52:19.757085Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r063d5 as r063d5\n",
    "import info.r063d6 as r063d6\n",
    "infos = [r063d5]\n",
    "\n",
    "from run import spike_sorted_infos\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T11:52:19.782071Z",
     "start_time": "2018-07-25T11:52:19.768080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decoded(info, position, spikes, xedges, yedges, shuffled_id):\n",
    "    \n",
    "    phase = info.task_times[\"phase3\"]\n",
    "    trials = get_trials(events, phase)\n",
    "    \n",
    "    error_byactual_position = np.zeros((len(yedges), len(xedges)))\n",
    "    n_byactual_position = np.ones((len(yedges), len(xedges)))\n",
    "    \n",
    "    session_n_active = []\n",
    "    session_likelihoods = []\n",
    "    session_decoded = []\n",
    "    session_actual = []\n",
    "    session_errors = []\n",
    "    session_n_running = 0\n",
    "    \n",
    "    for trial in trials:\n",
    "        epoch_of_interest = phase.excludes(trial)\n",
    "\n",
    "        tuning_curves = get_only_tuning_curves(position, \n",
    "                                               spikes, \n",
    "                                               xedges, \n",
    "                                               yedges, \n",
    "                                               epoch_of_interest)\n",
    "\n",
    "        if shuffled_id:\n",
    "            tuning_curves = np.random.permutation(tuning_curves)\n",
    "\n",
    "        sliced_position = position.time_slice(trial.start, trial.stop)\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(trial.start, \n",
    "                                               trial.stop) for spiketrain in spikes]\n",
    "\n",
    "        # limit position to only times when the subject is moving faster than a certain threshold\n",
    "        run_epoch = nept.run_threshold(sliced_position, thresh=10., t_smooth=0.8)\n",
    "        sliced_position = sliced_position[run_epoch]\n",
    "        \n",
    "        session_n_running += sliced_position.n_samples\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(run_epoch.start, \n",
    "                                               run_epoch.stop) for spiketrain in spikes]\n",
    "\n",
    "        epochs_interest = nept.Epoch(np.array([sliced_position.time[0], sliced_position.time[-1]]))\n",
    "\n",
    "        counts = nept.bin_spikes(sliced_spikes, sliced_position.time, dt=0.025, window=0.025,\n",
    "                                 gaussian_std=0.0075, normalized=False)\n",
    "        \n",
    "        min_neurons = 2\n",
    "        min_spikes = 2\n",
    "        \n",
    "        tc_shape = tuning_curves.shape\n",
    "        decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "        likelihood = nept.bayesian_prob(counts, decoding_tc, binsize=0.025, min_neurons=2, \n",
    "                                        min_spikes=min_spikes)\n",
    "\n",
    "        # Find decoded location based on max likelihood for each valid timestep\n",
    "        xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "        ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "        xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "        decoded = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "\n",
    "        session_decoded.append(decoded)\n",
    "        \n",
    "        # Remove nans from likelihood and reshape for plotting\n",
    "        keep_idx = np.sum(np.isnan(likelihood), axis=1) < likelihood.shape[1]\n",
    "        likelihood = likelihood[keep_idx]\n",
    "        likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "\n",
    "        session_likelihoods.append(likelihood)\n",
    "        \n",
    "        n_active_neurons = np.asarray([n_active if n_active >= min_neurons else 0 \n",
    "                                       for n_active in np.sum(counts.data >= 1, axis=1)])\n",
    "        n_active_neurons = n_active_neurons[keep_idx]\n",
    "        session_n_active.append(n_active_neurons)\n",
    "\n",
    "        f_xy = scipy.interpolate.interp1d(sliced_position.time, sliced_position.data.T, kind=\"nearest\")\n",
    "        counts_xy = f_xy(decoded.time)\n",
    "        true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                                 counts_xy[1][..., np.newaxis])),\n",
    "                                      decoded.time)\n",
    "\n",
    "        session_actual.append(true_position)\n",
    "\n",
    "        trial_errors = true_position.distance(decoded)\n",
    "\n",
    "        for error, x, y in zip(trial_errors, true_position.x, true_position.y):\n",
    "            x_idx = nept.find_nearest_idx(xedges, x)\n",
    "            y_idx = nept.find_nearest_idx(yedges, y)\n",
    "            error_byactual_position[y_idx][x_idx] += error\n",
    "            n_byactual_position[y_idx][x_idx] += 1\n",
    "\n",
    "        session_errors.append(trial_errors)\n",
    "            \n",
    "#     error_byactual = error_byactual_position / n_byactual_position\n",
    "\n",
    "    return session_decoded, session_actual, session_likelihoods, session_errors, session_n_active, session_n_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T11:52:19.793065Z",
     "start_time": "2018-07-25T11:52:19.783070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions, filename=None):\n",
    "    \n",
    "    all_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "    all_errors_id_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_id_shuffled], axis=0)\n",
    "\n",
    "#     print('Actual:', np.median(all_errors))\n",
    "#     print('ID shuffle:', np.median(all_errors_id_shuffled))\n",
    "\n",
    "#     print('Actual:', np.mean(all_errors), stats.sem(all_errors))\n",
    "#     print('ID shuffle:', np.mean(all_errors_id_shuffled), stats.sem(all_errors_id_shuffled))\n",
    "\n",
    "    fliersize = 1\n",
    "\n",
    "    decoded_dict = dict(error=all_errors, label='Decoded')\n",
    "    shuffled_id_dict = dict(error=all_errors_id_shuffled, label='ID shuffled')\n",
    "    decoded_errors = pd.DataFrame(decoded_dict)\n",
    "    shuffled_id = pd.DataFrame(shuffled_id_dict)\n",
    "    data = pd.concat([shuffled_id, decoded_errors])\n",
    "    colours = ['#ffffff', '#bdbdbd']\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    flierprops = dict(marker='o', markersize=fliersize, linestyle='none')\n",
    "    # ax = sns.boxplot(x='label', y='error', data=data, palette=colours, flierprops=flierprops)\n",
    "    ax = sns.boxplot(x='label', y='error', data=data, flierprops=flierprops)\n",
    "\n",
    "\n",
    "    edge_colour = '#252525'\n",
    "    for i, artist in enumerate(ax.artists):\n",
    "        artist.set_edgecolor(edge_colour)\n",
    "        artist.set_facecolor(colours[i])\n",
    "\n",
    "        for j in range(i*6, i*6+6):\n",
    "            line = ax.lines[j]\n",
    "            line.set_color(edge_colour)\n",
    "            line.set_mfc(edge_colour)\n",
    "            line.set_mec(edge_colour)\n",
    "    \n",
    "    ax.text(1., 1., \"N sessions: %d \\nmean-error: %.1f cm \\nmedian-error: %.1f cm\" % (n_sessions, \n",
    "                                                                                      np.mean(all_errors), \n",
    "                                                                                      np.median(all_errors)),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=10)\n",
    "\n",
    "    ax.set(xlabel=' ', ylabel=\"Error (cm)\")\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.126193Z",
     "start_time": "2018-07-23T13:45:35.274202Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binsize = 8\n",
    "n_sessions = 0\n",
    "session_ids = []\n",
    "xedges = []\n",
    "yedges = []\n",
    "\n",
    "all_decoded = []\n",
    "all_actual = []\n",
    "all_likelihoods = []\n",
    "all_n_active = []\n",
    "\n",
    "all_errors = []\n",
    "all_errors_id_shuffled = []\n",
    "all_errors_random_shuffled = []\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    session_ids.append(info.session_id)\n",
    "    n_sessions += 1\n",
    "    events, position, spikes, _, _ = get_data(info)\n",
    "\n",
    "    xedge, yedge = nept.get_xyedges(position, binsize=binsize)\n",
    "    xedges.append(xedge)\n",
    "    yedges.append(yedge)\n",
    "\n",
    "    xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "\n",
    "    decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=False)\n",
    "\n",
    "    _, _, _, errors_id_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=True)\n",
    "\n",
    "    all_decoded.append(decoded)\n",
    "    all_actual.append(actual)\n",
    "    all_likelihoods.append(likelihoods)\n",
    "    all_n_active.append(n_active)\n",
    "\n",
    "    all_errors.append(errors)\n",
    "    all_errors_id_shuffled.append(errors_id_shuffled)\n",
    "\n",
    "combined_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "\n",
    "filename = os.path.join(output_filepath, \"combined_errors-binsize\"+str(binsize)+\".png\")\n",
    "plot_errors(all_errors, all_errors_id_shuffled, n_sessions, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T13:12:13.224231Z",
     "start_time": "2018-07-25T12:44:00.958093Z"
    }
   },
   "outputs": [],
   "source": [
    "# proportion decoded\n",
    "binsize = 8\n",
    "    \n",
    "n_sessions = 0\n",
    "session_ids = []\n",
    "xedges = []\n",
    "yedges = []\n",
    "\n",
    "all_decoded = []\n",
    "all_actual = []\n",
    "all_likelihoods = []\n",
    "all_n_active = []\n",
    "\n",
    "all_errors = []\n",
    "all_errors_id_shuffled = []\n",
    "all_errors_random_shuffled = []\n",
    "\n",
    "proportion_decoded = []\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    session_ids.append(info.session_id)\n",
    "    n_sessions += 1\n",
    "    events, position, spikes, _, _ = get_data(info)\n",
    "\n",
    "    xedge, yedge = nept.get_xyedges(position, binsize=binsize)\n",
    "    xedges.append(xedge)\n",
    "    yedges.append(yedge)\n",
    "\n",
    "    xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "\n",
    "    decoded, actual, likelihoods, errors, n_active, session_n_running = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedge, \n",
    "                                             yedge, \n",
    "                                             shuffled_id=False)\n",
    "\n",
    "    n_decoded = 0\n",
    "    for trial in decoded:\n",
    "        n_decoded += trial.n_samples\n",
    "    proportion_decoded.append(n_decoded/session_n_running)\n",
    "\n",
    "print(proportion_decoded)\n",
    "y_pos = np.arange(n_sessions)\n",
    "plt.bar(y_pos, proportion_decoded, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, session_ids, rotation=90, fontsize=10)\n",
    "plt.ylabel('Proportion')\n",
    "plt.title(\"Samples decoded with %d cm bins\" % binsize)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_filepath, \"proportion-decoded_\"+str(binsize)+\"cm.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual session errors by binsize\n",
    "\n",
    "\n",
    "\n",
    "binsizes = [6, 8, 10, 12, 14]\n",
    "\n",
    "for info in infos:\n",
    "    \n",
    "    print(info.session_id)\n",
    "    combined_errors = []\n",
    "    mean_errors = []\n",
    "    median_errors = []\n",
    "    \n",
    "    for binsize in binsizes:\n",
    "    \n",
    "        session_ids.append(info.session_id)\n",
    "        n_sessions += 1\n",
    "        events, position, spikes, _, _ = get_data(info)\n",
    "\n",
    "        xedge, yedge = nept.get_xyedges(position, binsize=binsize)\n",
    "        xedges.append(xedge)\n",
    "        yedges.append(yedge)\n",
    "\n",
    "        xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "\n",
    "        decoded, actual, likelihoods, errors, n_active, session_n_running = get_decoded(info, \n",
    "                                                 position, \n",
    "                                                 spikes, \n",
    "                                                 xedge, \n",
    "                                                 yedge, \n",
    "                                                 shuffled_id=False)\n",
    "        for error in errors:\n",
    "            combined_errors.extend(error)\n",
    "        mean_errors.append(np.mean(combined_errors))\n",
    "        median_errors.append(np.median(combined_errors))\n",
    "        \n",
    "    plt.plot(binsizes, mean_errors)\n",
    "    plt.xlabel(\"Binsize (cm)\")\n",
    "    plt.ylabel(\"Mean error\")\n",
    "    plt.title(info.session_id+\" mean decode error (cm)\")\n",
    "    plt.savefig(os.path.join(output_filepath, info.session_id+\"_mean-error.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(binsizes, median_errors)\n",
    "    plt.xlabel(\"Binsize (cm)\")\n",
    "    plt.ylabel(\"Median error\")\n",
    "    plt.title(info.session_id+\" median decode error (cm)\")\n",
    "    plt.savefig(os.path.join(output_filepath, info.session_id+\"_median-error.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_over_space(values, positions, xedges, yedges):\n",
    "    xcenters = xedges[:-1] + (xedges[1:] - xedges[:-1]) / 2\n",
    "    ycenters = yedges[:-1] + (yedges[1:] - yedges[:-1]) / 2\n",
    "\n",
    "    count_position = np.zeros((len(yedges), len(xedges)))\n",
    "    n_position = np.ones((len(yedges), len(xedges)))\n",
    "\n",
    "    for trial_values, trial_positions in zip(values, positions):\n",
    "        for these_values, x, y in zip(trial_values, trial_positions.x, trial_positions.y):\n",
    "            x_idx = nept.find_nearest_idx(xcenters, x)\n",
    "            y_idx = nept.find_nearest_idx(ycenters, y)\n",
    "            if np.isscalar(these_values):\n",
    "                count_position[y_idx][x_idx] += these_values\n",
    "            else:\n",
    "                count_position[y_idx][x_idx] += these_values[y_idx][x_idx]\n",
    "            n_position[y_idx][x_idx] += 1\n",
    "\n",
    "    return count_position / n_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_byactual = plot_over_space(likelihoods, actual, xedge, yedge)\n",
    "\n",
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, likelihood_byactual, vmin=0., cmap='bone_r')\n",
    "plt.colorbar(pp)\n",
    "title = info.session_id+\" posterior\"\n",
    "plt.title(title)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_byactual = plot_over_space(errors, actual, xedge, yedge)\n",
    "\n",
    "pp = plt.pcolormesh(xx, yy, errors_byactual, vmin=0., cmap='bone_r')\n",
    "plt.colorbar(pp)\n",
    "title = info.session_id+\" decoding error (cm)\"\n",
    "plt.title(title)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.127193Z",
     "start_time": "2018-07-23T13:45:55.727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trial_idx in range(2):\n",
    "    for session_idx in range(n_sessions):\n",
    "        decoded = all_decoded[session_idx][trial_idx]\n",
    "        true_position = all_actual[session_idx][trial_idx]\n",
    "        likelihoods = np.array(all_likelihoods[session_idx][trial_idx])\n",
    "        n_active = all_n_active[session_idx][trial_idx]\n",
    "        errors = all_errors[session_idx][trial_idx]\n",
    "        xedge = xedges[session_idx]\n",
    "        yedge = yedges[session_idx]\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        gs = gridspec.GridSpec(5, 4)\n",
    "\n",
    "        xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "        ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "        pad_amount = binsize*2\n",
    "        ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "        ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "        n_timebins = decoded.n_samples\n",
    "    #     n_timebins = 10\n",
    "\n",
    "        n_colours = 20.\n",
    "        colours = [(1., 1., 1.)]\n",
    "        colours.extend(matplotlib.cm.copper_r(np.linspace(0, 1, n_colours-1)))\n",
    "        cmap = matplotlib.colors.ListedColormap(colours)\n",
    "\n",
    "        likelihoods_withnan = np.array(likelihoods)\n",
    "        likelihoods[np.isnan(likelihoods)] = -0.01\n",
    "\n",
    "        xcenters = xedge[:-1] + (xedge[1:] - xedge[:-1]) / 2\n",
    "        ycenters = yedge[:-1] + (yedge[1:] - yedge[:-1]) / 2\n",
    "\n",
    "        x_idx = [nept.find_nearest_idx(xcenters, true_position.x[timestep]) for timestep in range(true_position.n_samples)]\n",
    "        y_idx = [nept.find_nearest_idx(ycenters, true_position.y[timestep]) for timestep in range(true_position.n_samples)]\n",
    "\n",
    "        x_dec_idx = [nept.find_nearest_idx(xcenters, decoded.x[timestep]) for timestep in range(decoded.n_samples)]\n",
    "        y_dec_idx = [nept.find_nearest_idx(ycenters, decoded.y[timestep]) for timestep in range(decoded.n_samples)]\n",
    "\n",
    "    #     cmap = plt.cm.get_cmap('bone_r')\n",
    "        posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihoods[0], vmax=0.2, cmap=cmap)\n",
    "        colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "        estimated_position, = ax1.plot([], [], \"o\", color=\"c\")\n",
    "        rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "\n",
    "        ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "\n",
    "        binwidth = 5.\n",
    "        error_bins = np.arange(-binwidth, np.max(errors)+binwidth, binwidth)\n",
    "\n",
    "        _, _, errors_bin = ax2.hist([np.clip(errors, error_bins[0], error_bins[-1])], bins=error_bins, rwidth=0.9, color=\"k\")\n",
    "        errors_idx = np.digitize(errors, error_bins)\n",
    "\n",
    "        fontsize = 14\n",
    "        likelihood_at_actual = ax2.text(0.6, 1, [],\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='top',\n",
    "                 transform = ax2.transAxes,\n",
    "                 fontsize=fontsize)\n",
    "\n",
    "        ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "        ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.yaxis.set_ticks_position('left')\n",
    "        ax2.xaxis.set_ticks_position('bottom')\n",
    "        # xticks = binwidth * np.arange(0, len(xlabels)-1, 2) - binwidth\n",
    "        # xticks[0] = -binwidth/2.\n",
    "        xticks = binwidth * np.arange(0, len(error_bins), 4)\n",
    "        plt.xticks(xticks, fontsize=fontsize)\n",
    "        plt.yticks(fontsize=fontsize)\n",
    "\n",
    "        ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "\n",
    "        n_active_bins = np.arange(-0.5, np.max(n_active)+1)\n",
    "\n",
    "        _, _, n_neurons_bin = ax3.hist(n_active, bins=n_active_bins, rwidth=0.9, color=\"k\", align=\"mid\")\n",
    "\n",
    "        ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "        ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.yaxis.set_ticks_position('left')\n",
    "        ax3.xaxis.set_ticks_position('bottom')\n",
    "    #     xticks = binwidth * np.arange(0, len(n_active_bins)+1)\n",
    "    #     plt.xticks(xticks+binwidth/2)\n",
    "    #     ax3.set_xticklabels(xticks, fontsize=fontsize)\n",
    "        plt.yticks(fontsize=fontsize)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "\n",
    "        def init():\n",
    "            posterior_position.set_array([])\n",
    "            estimated_position.set_data([], [])\n",
    "            rat_position.set_data([], [])\n",
    "            likelihood_at_actual.set_text([])\n",
    "            return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "\n",
    "        def animate(i):\n",
    "            posterior_position.set_array(likelihoods[i].ravel())\n",
    "            estimated_position.set_data(decoded.x[i], decoded.y[i])\n",
    "            rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "\n",
    "            for patch in errors_bin:\n",
    "                patch.set_fc('k')\n",
    "            errors_bin[errors_idx[i]-1].set_fc('r')\n",
    "\n",
    "            for patch in n_neurons_bin:\n",
    "                patch.set_fc('k')\n",
    "            n_neurons_bin[n_active[i]].set_fc('b')\n",
    "\n",
    "            likelihood_at_actual.set_text(\"posterior at true position: %.3f \\nposterior at decoded position: %.3f \" % \n",
    "                                          (likelihoods_withnan[i][y_idx[i]][x_idx[i]], \n",
    "                                           likelihoods_withnan[i][y_dec_idx[i]][x_dec_idx[i]]))\n",
    "\n",
    "            return (posterior_position, estimated_position, rat_position, likelihood_at_actual)\n",
    "\n",
    "        anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=200, \n",
    "                                       blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#         writer = animation.writers['ffmpeg'](fps=10)\n",
    "#         dpi = 600\n",
    "#         filename = session_ids[session_idx]+'_decoded_trial'+str(trial_idx)+'.mp4'\n",
    "#         anim.save(os.path.join(output_filepath, filename), writer=writer, dpi=dpi)\n",
    "\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:49:17.127193Z",
     "start_time": "2018-07-23T13:45:55.935Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Blue triangle is the true position; Cyan circle is the estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:59:53.404081Z",
     "start_time": "2018-07-23T13:59:53.401083Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T14:02:06.100097Z",
     "start_time": "2018-07-23T14:02:06.089104Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_line(start_pt, stop_pt, line, expand_by):\n",
    "    \"\"\"Expands shapely line into a zone.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_pt : shapely.Point\n",
    "    stop_pt : shapely.Point\n",
    "    line : shapely.LineString\n",
    "    expand_by : int or float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zone : shapely.Polygon\n",
    "\n",
    "    \"\"\"\n",
    "    line_expanded = line.buffer(expand_by)\n",
    "    zone = start_pt.union(line_expanded).union(stop_pt)\n",
    "\n",
    "    return zone\n",
    "\n",
    "\n",
    "def find_zones(info, remove_feeder, expand_by=6):\n",
    "    \"\"\"Finds zones from ideal trajectories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info : shortcut module\n",
    "    remove_feeder: boolean\n",
    "    expand_by : int or float\n",
    "        Amount to expand the line.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zone : dict\n",
    "        With shapely.Polygon as values.\n",
    "        Keys are u, shortcut, novel, ushort, unovel, uped, shortped,\n",
    "        novelped, pedestal.\n",
    "\n",
    "    \"\"\"\n",
    "    u_line = LineString(info.u_trajectory)\n",
    "    shortcut_line = LineString(info.shortcut_trajectory)\n",
    "    novel_line = LineString(info.novel_trajectory)\n",
    "\n",
    "    pedestal = Point(info.path_pts['pedestal'][0], info.path_pts['pedestal'][1]).buffer(expand_by*2.2)\n",
    "    feeder1 = Point(info.path_pts['feeder1'][0], info.path_pts['feeder1'][1]).buffer(expand_by*1.2)\n",
    "    feeder2 = Point(info.path_pts['feeder2'][0], info.path_pts['feeder2'][1]).buffer(expand_by*1.2)\n",
    "\n",
    "    u_zone = expand_line(Point(info.u_trajectory[0]), \n",
    "                         Point(info.u_trajectory[-1]), \n",
    "                         u_line, expand_by)\n",
    "    shortcut_zone = expand_line(Point(info.shortcut_trajectory[0]), \n",
    "                                Point(info.shortcut_trajectory[-1]), \n",
    "                                shortcut_line, expand_by)\n",
    "    novel_zone = expand_line(Point(info.novel_trajectory[0]), \n",
    "                             Point(info.novel_trajectory[-1]), \n",
    "                             novel_line, expand_by)\n",
    "\n",
    "    zone = dict()\n",
    "    zone['u'] = u_zone.difference(pedestal)\n",
    "    zone['shortcut'] = shortcut_zone.difference(u_zone)\n",
    "    zone['shortcut'] = zone['shortcut'].difference(novel_zone)\n",
    "    zone['shortcut'] = zone['shortcut'].difference(pedestal)\n",
    "    zone['novel'] = novel_zone.difference(u_zone)\n",
    "    zone['novel'] = zone['novel'].difference(pedestal)\n",
    "    zone['pedestal'] = pedestal\n",
    "\n",
    "    if remove_feeder:\n",
    "        for feeder in [feeder1, feeder2]:\n",
    "            zone['u'] = zone['u'].difference(feeder)\n",
    "            zone['shortcut'] = zone['shortcut'].difference(feeder)\n",
    "            zone['novel'] = zone['novel'].difference(feeder)\n",
    "            zone['pedestal'] = zone['pedestal'].difference(feeder)\n",
    "\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:18.158126Z",
     "start_time": "2018-07-23T16:37:18.147152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, remove_feeder=True, expand_by=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:18.818453Z",
     "start_time": "2018-07-23T16:37:18.812457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:20.658190Z",
     "start_time": "2018-07-23T16:37:20.652213Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcenters = xedge[:-1] + (xedge[1:] - xedge[:-1]) / 2\n",
    "ycenters = yedge[:-1] + (yedge[1:] - yedge[:-1]) / 2\n",
    "xcenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:21.474041Z",
     "start_time": "2018-07-23T16:37:21.468045Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "shortcut_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "novel_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "pedestal_xbins = np.zeros(len(xcenters)).astype(bool)\n",
    "\n",
    "u_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "shortcut_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "novel_ybins = np.zeros(len(ycenters)).astype(bool)\n",
    "pedestal_ybins = np.zeros(len(ycenters)).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:22.071376Z",
     "start_time": "2018-07-23T16:37:22.044386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x_idx, xbin in enumerate(xcenters):\n",
    "    for y_idx, ybin in enumerate(ycenters):\n",
    "        point = Point([xbin, ybin])\n",
    "        if zones['u'].contains(point):\n",
    "            u_xbins[x_idx] = True\n",
    "            u_ybins[y_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:37:22.617099Z",
     "start_time": "2018-07-23T16:37:22.612121Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_xbins, u_ybins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:52:21.414318Z",
     "start_time": "2018-07-23T16:52:20.739506Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events, position, spikes, _, _ = get_data(info)\n",
    "xedge, yedge = nept.get_xyedges(position, binsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:52:33.572725Z",
     "start_time": "2018-07-23T16:52:33.563749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase1_position = position.time_slice(info.task_times[\"phase1\"].start, info.task_times[\"phase1\"].stop)\n",
    "phase1_occupancy = nept.get_occupancy(phase1_position, yedge, xedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase3_position = position.time_slice(info.task_times[\"phase3\"].start, info.task_times[\"phase3\"].stop)\n",
    "phase3_occupancy = nept.get_occupancy(phase3_position, yedge, xedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase3_occupancy.shape, phase1_occupancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = phase3_occupancy[phase3_occupancy>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:48:01.666306Z",
     "start_time": "2018-07-23T16:48:01.523500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(phase1_position.x, phase1_position.y, \".\")\n",
    "plt.plot(zones[\"u\"].exterior.xy[0], zones[\"u\"].exterior.xy[1], 'b', lw=1)\n",
    "# for intersect in zones[\"shortcut\"]:\n",
    "plt.plot(zones[\"shortcut\"].exterior.xy[0], zones[\"shortcut\"].exterior.xy[1], 'g', lw=1)\n",
    "plt.plot(zones[\"novel\"].exterior.xy[0], zones[\"novel\"].exterior.xy[1], 'r', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:53:26.838165Z",
     "start_time": "2018-07-23T16:53:26.834167Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binned_maze_shape = phase1_occupancy.shape\n",
    "u_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "novel_pos = np.zeros(binned_maze_shape).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:54:11.503650Z",
     "start_time": "2018-07-23T16:54:11.499653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_pos[phase1_occupancy > 0] = True\n",
    "novel_pos[(phase3_occupancy > 4.) & (~u_pos)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T16:55:13.831497Z",
     "start_time": "2018-07-23T16:55:13.659596Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, phase1_occupancy, vmax=10., cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, u_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, phase3_occupancy, vmax=10., cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase = \"phase3\"\n",
    "t_start = info.task_times[phase].start\n",
    "t_stop = info.task_times[phase].stop\n",
    "\n",
    "sliced_pos = position.time_slice(t_start, t_stop)\n",
    "\n",
    "feeder1_times = []\n",
    "for feeder1 in events['feeder1']:\n",
    "    if t_start < feeder1 < t_stop:\n",
    "        feeder1_times.append(feeder1)\n",
    "\n",
    "feeder2_times = []\n",
    "for feeder2 in events['feeder2']:\n",
    "    if t_start < feeder2 < t_stop:\n",
    "        feeder2_times.append(feeder2)\n",
    "\n",
    "path_pos = get_zones(info, sliced_pos)\n",
    "\n",
    "trials_idx, trial_epochs = get_trial_idx(path_pos['u'].time, \n",
    "                                         path_pos['shortcut'].time, \n",
    "                                         path_pos['novel'].time,\n",
    "                                         feeder1_times, \n",
    "                                         feeder2_times, \n",
    "                                         t_stop)\n",
    "\n",
    "shortcut_epochs = [trial_epochs[idx] for idx in trials_idx[\"shortcut\"]]\n",
    "u_epochs = [trial_epochs[idx] for idx in trials_idx[\"u\"]]\n",
    "novel_epochs = [trial_epochs[idx] for idx in trials_idx[\"novel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "\n",
    "u_position = position.time_slice(info.task_times[\"phase1\"].start, info.task_times[\"phase1\"].stop)\n",
    "u_occupancy = nept.get_occupancy(u_position, yedge, xedge)\n",
    "u_pos[u_occupancy > 0.] = True\n",
    "\n",
    "u_position = position.time_slice(info.task_times[\"phase2\"].start, info.task_times[\"phase2\"].stop)\n",
    "u_occupancy = nept.get_occupancy(u_position, yedge, xedge)\n",
    "u_pos[u_occupancy > 0.] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortcut_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "for epoch in shortcut_epochs:\n",
    "    shortcut_position = position.time_slice(epoch.start, epoch.stop)\n",
    "    shortcut_occupancy = nept.get_occupancy(shortcut_position, yedge, xedge)\n",
    "    shortcut_pos[(shortcut_occupancy > 0.) & (~u_pos)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novel_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "for epoch in novel_epochs:\n",
    "    novel_position = position.time_slice(epoch.start, epoch.stop)\n",
    "    novel_occupancy = nept.get_occupancy(novel_position, yedge, xedge)\n",
    "    novel_pos[(novel_occupancy > 1.) & (~u_pos) & (~shortcut_pos)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(novel_position.x, novel_position.y, \".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, u_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, shortcut_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letssee = u_pos + shortcut_pos + novel_pos\n",
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, letssee, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, novel_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = [[0,1,0],[1,1,1],[0,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novel_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "for epoch in novel_epochs:\n",
    "    novel_position = position.time_slice(epoch.start, epoch.stop)\n",
    "    novel_occupancy = nept.get_occupancy(novel_position, yedge, xedge)\n",
    "    novel_pos[(novel_occupancy > 1.) & (~u_pos) & (~shortcut_pos)] = True\n",
    "filtered = convolve2d(novel_pos, kernel, mode='same')\n",
    "novel_pos[filtered<=1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, novel_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortcut_pos = np.zeros(binned_maze_shape).astype(bool)\n",
    "for epoch in shortcut_epochs:\n",
    "    shortcut_position = position.time_slice(epoch.start, epoch.stop)\n",
    "    shortcut_occupancy = nept.get_occupancy(shortcut_position, yedge, xedge)\n",
    "    shortcut_pos[(shortcut_occupancy > 0.) & (~u_pos)] = True\n",
    "filtered = convolve2d(shortcut_pos, kernel, mode='same')\n",
    "shortcut_pos[filtered<=1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(xedge, yedge)\n",
    "\n",
    "plt.figure()\n",
    "pp = plt.pcolormesh(xx, yy, shortcut_pos, cmap=\"Greys\")\n",
    "colourbar = plt.colorbar(pp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def point_in_zones(position, zones):\n",
    "    \"\"\"Assigns points to each trajectory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    position : nept.Position\n",
    "    zones : dict\n",
    "        With u, shortcut, novel, pedestal as keys\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_zones : dict\n",
    "        With u, shortcut, novel, other as keys, each a nept.Position object\n",
    "\n",
    "    \"\"\"\n",
    "    u_data = []\n",
    "    u_times = []\n",
    "    shortcut_data = []\n",
    "    shortcut_times = []\n",
    "    novel_data = []\n",
    "    novel_times = []\n",
    "    other_data = []\n",
    "    other_times = []\n",
    "\n",
    "    if not position.isempty:\n",
    "        for x, y, time in zip(position.x, position.y, position.time):\n",
    "            point = Point([x, y])\n",
    "            if zones['u'].contains(point):\n",
    "                u_data.append([x, y])\n",
    "                u_times.append(time)\n",
    "                continue\n",
    "            elif zones['shortcut'].contains(point):\n",
    "                shortcut_data.append([x, y])\n",
    "                shortcut_times.append(time)\n",
    "                continue\n",
    "            elif zones['novel'].contains(point):\n",
    "                novel_data.append([x, y])\n",
    "                novel_times.append(time)\n",
    "                continue\n",
    "            else:\n",
    "                other_data.append([x, y])\n",
    "                other_times.append(time)\n",
    "\n",
    "    sorted_zones = dict()\n",
    "    sorted_zones['u'] = nept.Position(u_data, u_times)\n",
    "    sorted_zones['shortcut'] = nept.Position(shortcut_data, shortcut_times)\n",
    "    sorted_zones['novel'] = nept.Position(novel_data, novel_times)\n",
    "    sorted_zones['other'] = nept.Position(other_data, other_times)\n",
    "\n",
    "    return sorted_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.317383Z",
     "start_time": "2018-07-23T13:37:55.533Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_idx = 1\n",
    "timestep = 0\n",
    "\n",
    "xcenters = xedges[:-1] + (xedges[1:] - xedges[:-1]) / 2\n",
    "ycenters = yedges[:-1] + (yedges[1:] - yedges[:-1]) / 2\n",
    "\n",
    "x_idx = [nept.find_nearest_idx(xcenters, actual[trial_idx].x[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "y_idx = [nept.find_nearest_idx(ycenters, actual[trial_idx].y[timestep]) for timestep in range(actual[trial_idx].n_samples)]\n",
    "\n",
    "print(likelihoods[timestep][y_idx[timestep]][x_idx[timestep]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.318383Z",
     "start_time": "2018-07-23T13:37:55.539Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('bone_r')\n",
    "pp = plt.pcolormesh(xx[:-1], yy[:-1], likelihoods[timestep], cmap=cmap)\n",
    "colorbar = fig.colorbar(pp, ax=ax1)\n",
    "plt.plot(actual[trial_idx].x[timestep], actual[trial_idx].y[timestep], \"r.\", ms=10)\n",
    "colorbar = plt.colorbar(pp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T13:41:44.323380Z",
     "start_time": "2018-07-23T13:37:55.552Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined_errors = []\n",
    "# binsizes = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "# for binsize in binsizes:\n",
    "#     n_sessions = 0\n",
    "#     xxs = []\n",
    "#     yys = []\n",
    "\n",
    "#     all_decoded = []\n",
    "#     all_actual = []\n",
    "#     all_likelihoods = []\n",
    "#     all_n_active = []\n",
    "\n",
    "#     all_errors = []\n",
    "\n",
    "\n",
    "#     for info in infos:\n",
    "#         print(info.session_id)\n",
    "#         n_sessions += 1\n",
    "#         events, position, spikes, _, _ = get_data(info)\n",
    "#         xedges, yedges = nept.get_xyedges(position, binsize=binsize)\n",
    "\n",
    "#         xx, yy = np.meshgrid(xedges, yedges)\n",
    "#         xxs.append(xx)\n",
    "#         yys.append(yy)\n",
    "\n",
    "#         phase = \"phase3\"\n",
    "#         trial_epochs = get_trials(events, info.task_times[phase])\n",
    "\n",
    "#         decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "#                                                  position, \n",
    "#                                                  spikes, \n",
    "#                                                  xedges, \n",
    "#                                                  yedges, \n",
    "#                                                  shuffled_id=False, \n",
    "#                                                  random_shuffle=False)\n",
    "\n",
    "#         all_decoded.append(decoded)\n",
    "#         all_actual.append(actual)\n",
    "#         all_likelihoods.append(likelihoods)\n",
    "#         all_n_active.append(n_active)\n",
    "\n",
    "#         all_errors.append(errors)\n",
    "\n",
    "#     combined_errors.append(np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0))\n",
    "    \n",
    "# plt.plot(binsizes, np.mean(combined_errors, axis=1))\n",
    "# plt.xticks(binsizes)\n",
    "# plt.xlabel(\"Binsize (cm)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
