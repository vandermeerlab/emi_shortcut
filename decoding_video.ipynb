{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r068d6 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, _ = get_data(info)\n",
    "\n",
    "phase = \"phase3\"\n",
    "\n",
    "position_initial = position.time_slice(info.task_times[phase].start, info.task_times[phase].stop)\n",
    "spikes = [spiketrain.time_slice(info.task_times[phase].start, info.task_times[phase].stop) for spiketrain in spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xedges, yedges = nept.get_xyedges(position_initial, binsize=4)\n",
    "\n",
    "trial_epochs = get_trials(events, info.task_times[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for trial_idx in range(trial_epochs.n_epochs):\n",
    "for trial_idx in [18]:\n",
    "    trial_start = trial_epochs.starts[trial_idx]\n",
    "    trial_stop = trial_epochs.stops[trial_idx]\n",
    "\n",
    "    trial_times = nept.Epoch([trial_start, trial_stop])\n",
    "    sliced_spikes, tuning_curves = get_only_tuning_curves(info, position, spikes, xedges, yedges, phase=\"phase3\")\n",
    "\n",
    "    decoding_times = trial_times\n",
    "    shuffle_id = False\n",
    "    speed_limit = 0.167\n",
    "    t_smooth = 0.5\n",
    "    dt = 0.025\n",
    "    window = 0.025\n",
    "    gaussian_std = 0.0075\n",
    "    normalized = False\n",
    "    min_neurons = 2\n",
    "    min_spikes = 1\n",
    "\n",
    "    position = position_initial.time_slice(decoding_times.start, decoding_times.stop)\n",
    "    \n",
    "    # limit position to only times when the subject is moving faster than a certain threshold\n",
    "    run_epoch = nept.run_threshold(position, thresh=speed_limit, t_smooth=t_smooth)\n",
    "    position = position[run_epoch]\n",
    "\n",
    "    epochs_interest = nept.Epoch(np.array([position.time[0], position.time[-1]]))\n",
    "\n",
    "    counts = nept.bin_spikes(sliced_spikes, position.time, dt=dt, window=window,\n",
    "                             gaussian_std=gaussian_std, normalized=normalized)\n",
    "    \n",
    "    n_active_neurons = np.sum(counts.data >= 1, axis=1)\n",
    "\n",
    "    tc_shape = tuning_curves.shape\n",
    "    decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "    likelihood = nept.bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_epochs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for trial_idx in range(trial_epochs.n_epochs):\n",
    "for trial_idx in [18]:\n",
    "    trial_start = trial_epochs.starts[trial_idx]\n",
    "    trial_stop = trial_epochs.stops[trial_idx]\n",
    "\n",
    "    trial_times = nept.Epoch([trial_start, trial_stop])\n",
    "    sliced_spikes, tuning_curves = get_only_tuning_curves(info, position, spikes, xedges, yedges, phase=\"phase3\")\n",
    "\n",
    "    decoding_times = trial_times\n",
    "    shuffle_id = False\n",
    "    speed_limit = 4.\n",
    "    t_smooth = 0.5\n",
    "    dt = 0.025\n",
    "    window = 0.025\n",
    "    gaussian_std = 0.0075\n",
    "    normalized = False\n",
    "    min_neurons = 2\n",
    "    min_spikes = 1\n",
    "\n",
    "    position = position_initial.time_slice(decoding_times.start, decoding_times.stop)\n",
    "    \n",
    "    # limit position to only times when the subject is moving faster than a certain threshold\n",
    "    run_epoch = nept.run_threshold(position, thresh=speed_limit, t_smooth=t_smooth)\n",
    "    position = position[run_epoch]\n",
    "\n",
    "    epochs_interest = nept.Epoch(np.array([position.time[0], position.time[-1]]))\n",
    "\n",
    "    counts = nept.bin_spikes(sliced_spikes, position.time, dt=dt, window=window,\n",
    "                             gaussian_std=gaussian_std, normalized=normalized)\n",
    "    \n",
    "    n_active_neurons = np.sum(counts.data >= 1, axis=1)\n",
    "\n",
    "    tc_shape = tuning_curves.shape\n",
    "    decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "    likelihood = nept.bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)\n",
    "    \n",
    "    xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "    ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "    xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "    decoded_position = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "    \n",
    "    likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "#     likelihood[np.isnan(likelihood)] = 0.\n",
    "\n",
    "    f_xy = scipy.interpolate.interp1d(position.time, position.data.T, kind=\"nearest\")\n",
    "    counts_xy = f_xy(decoded_position.time)\n",
    "    true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                             counts_xy[1][..., np.newaxis])),\n",
    "                                  decoded_position.time)\n",
    "    \n",
    "    errors = true_position.distance(decoded_position)\n",
    "    print(np.nanmean(errors))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(5, 4) \n",
    "    \n",
    "    ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "    xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "    pad_amount = 5\n",
    "    ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "    ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "    n_timebins = len(likelihood)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('bone_r')\n",
    "    posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihood[0], vmin=0, vmax=0.1, cmap=cmap)\n",
    "    colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "    estimated_position, = ax1.plot([], [], \"<\", color=\"r\")\n",
    "    rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "    \n",
    "    ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "    \n",
    "    errors[np.isnan(errors)] = -1\n",
    "    binwidth = 5.\n",
    "    bins = np.arange(-binwidth, 50+binwidth, binwidth)\n",
    "    \n",
    "    _, _, errors_bin = ax2.hist([np.clip(errors, bins[0], bins[-1])], bins=bins, rwidth=0.9, color=\"k\")\n",
    "    \n",
    "    xlabels = [str(int(b)) for b in bins]\n",
    "    xlabels[0] = \"nan\"\n",
    "    ax2.set_xticklabels(xlabels)\n",
    "    fontsize = 14\n",
    "    ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "    ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    xticks = binwidth * np.arange(len(xlabels)-1) - binwidth\n",
    "    xticks[0] = -binwidth/2.\n",
    "    plt.xticks(xticks, fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "    \n",
    "    binwidth = 1\n",
    "    bins = np.arange(np.min(n_active_neurons), np.max(n_active_neurons) + binwidth, binwidth)\n",
    "\n",
    "    _, _, n_neurons_bin = ax3.hist(n_active_neurons, bins=bins, rwidth=0.9, color=\"k\")\n",
    "    \n",
    "    ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "    ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.yaxis.set_ticks_position('left')\n",
    "    ax3.xaxis.set_ticks_position('bottom')\n",
    "    xticks = binwidth * np.arange(len(bins))\n",
    "    plt.xticks(xticks, fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    def init():\n",
    "        posterior_position.set_array([])\n",
    "        estimated_position.set_data([], [])\n",
    "        rat_position.set_data([], [])\n",
    "        return (posterior_position, estimated_position, rat_position)\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        posterior_position.set_array(likelihood[i].ravel())\n",
    "        estimated_position.set_data(decoded_position.x[i], decoded_position.y[i])\n",
    "        rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "        \n",
    "        for patch in errors_bin:\n",
    "            patch.set_fc('k')\n",
    "        idx = np.digitize(np.array([errors[i]]), bin_array)[0]\n",
    "        errors_bin[idx-1].set_fc('r')\n",
    "        \n",
    "        for patch in n_neurons_bin:\n",
    "            patch.set_fc('k')\n",
    "        idx = np.digitize(np.array([n_active_neurons[i]]), bin_array)[0]\n",
    "        n_neurons_bin[idx-1].set_fc('r')\n",
    "    \n",
    "        return (posterior_position, estimated_position, rat_position, errors_bin, n_neurons_bin)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=80, \n",
    "                                   blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#     writer = animation.writers['ffmpeg'](fps=18)\n",
    "#     dpi = 600\n",
    "#     filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "#     anim.save(output_filepath+filename, writer=writer, dpi=dpi)\n",
    "    \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_position.n_samples, decoded_position.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = animation.writers['ffmpeg'](fps=18)\n",
    "# dpi = 600\n",
    "# filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "# anim.save(output_filepath+filename, writer=writer, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Blue is true position; Red is estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_idx = 18\n",
    "trial_start = trial_epochs.starts[trial_idx]\n",
    "trial_stop = trial_epochs.stops[trial_idx]\n",
    "\n",
    "trial_times = nept.Epoch([trial_start, trial_stop])\n",
    "sliced_spikes, tuning_curves = get_only_tuning_curves(info, position, spikes, xedges, yedges, phase=\"phase3\")\n",
    "\n",
    "decoding_times = trial_times\n",
    "shuffle_id = False\n",
    "speed_limit = 4.\n",
    "t_smooth = 0.5\n",
    "dt = 0.025\n",
    "window = 0.025\n",
    "gaussian_std = 0.0075\n",
    "normalized = False\n",
    "min_neurons = 2\n",
    "min_spikes = 1\n",
    "\n",
    "position = position_initial.time_slice(decoding_times.start, decoding_times.stop)\n",
    "\n",
    "# limit position to only times when the subject is moving faster than a certain threshold\n",
    "run_epoch = nept.run_threshold(position, thresh=speed_limit, t_smooth=t_smooth)\n",
    "position = position[run_epoch]\n",
    "\n",
    "epochs_interest = nept.Epoch(np.array([position.time[0], position.time[-1]]))\n",
    "\n",
    "counts = nept.bin_spikes(sliced_spikes, position.time, dt=dt, window=window,\n",
    "                         gaussian_std=gaussian_std, normalized=normalized)\n",
    "\n",
    "n_active_neurons = np.sum(counts.data >= 1, axis=1)\n",
    "\n",
    "tc_shape = tuning_curves.shape\n",
    "decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "likelihood = nept.bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "decoded_position = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "\n",
    "likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "#     likelihood[np.isnan(likelihood)] = 0.\n",
    "\n",
    "f_xy = scipy.interpolate.interp1d(position.time, position.data.T, kind=\"nearest\")\n",
    "counts_xy = f_xy(decoded_position.time)\n",
    "true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                         counts_xy[1][..., np.newaxis])),\n",
    "                              decoded_position.time)\n",
    "\n",
    "errors = true_position.distance(decoded_position)\n",
    "print(np.nanmean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_likelihood = np.nansum(likelihood, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "pad_amount = 5\n",
    "ax.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "ax.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "n_timebins = len(likelihood)\n",
    "\n",
    "cmap = plt.cm.get_cmap('bone_r')\n",
    "posterior_position = ax.pcolormesh(xx[:-1], yy[:-1], sum_likelihood, vmin=0, vmax=0.1, cmap=cmap)\n",
    "colorbar = plt.colorbar(posterior_position, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
