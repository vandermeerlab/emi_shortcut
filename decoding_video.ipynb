{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:19.755941Z",
     "start_time": "2018-06-25T14:42:18.258799Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:19.761939Z",
     "start_time": "2018-06-25T14:42:19.757941Z"
    }
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:19.771932Z",
     "start_time": "2018-06-25T14:42:19.763937Z"
    }
   },
   "outputs": [],
   "source": [
    "import info.r068d6 as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:56:44.033881Z",
     "start_time": "2018-06-25T14:56:43.391195Z"
    }
   },
   "outputs": [],
   "source": [
    "events, position, spikes, lfp, _ = get_data(info)\n",
    "\n",
    "phase = \"phase3\"\n",
    "\n",
    "position_initial = position.time_slice(info.task_times[phase].start, info.task_times[phase].stop)\n",
    "spikes = [spiketrain.time_slice(info.task_times[phase].start, info.task_times[phase].stop) for spiketrain in spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:56:44.371688Z",
     "start_time": "2018-06-25T14:56:44.366691Z"
    }
   },
   "outputs": [],
   "source": [
    "xedges, yedges = nept.get_xyedges(position_initial, binsize=4)\n",
    "\n",
    "trial_epochs = get_trials(events, info.task_times[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:56:45.099119Z",
     "start_time": "2018-06-25T14:56:45.095122Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_epochs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:56:48.581239Z",
     "start_time": "2018-06-25T14:56:45.943964Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for trial_idx in range(trial_epochs.n_epochs):\n",
    "for trial_idx in [18]:\n",
    "    trial_start = trial_epochs.starts[trial_idx]\n",
    "    trial_stop = trial_epochs.stops[trial_idx]\n",
    "\n",
    "    trial_times = nept.Epoch([trial_start, trial_stop])\n",
    "    sliced_spikes, tuning_curves = get_only_tuning_curves(info, position, spikes, xedges, yedges, phase=\"phase3\")\n",
    "\n",
    "    decoding_times = trial_times\n",
    "    shuffle_id = False\n",
    "    speed_limit = 0.167\n",
    "    t_smooth = 0.5\n",
    "    dt = 0.025\n",
    "    window = 0.025\n",
    "    gaussian_std = 0.0075\n",
    "    normalized = False\n",
    "    min_neurons = 2\n",
    "    min_spikes = 1\n",
    "\n",
    "    position = position_initial.time_slice(decoding_times.start, decoding_times.stop)\n",
    "    \n",
    "    # limit position to only times when the subject is moving faster than a certain threshold\n",
    "    run_epoch = nept.run_threshold(position, thresh=speed_limit, t_smooth=t_smooth)\n",
    "    position = position[run_epoch]\n",
    "\n",
    "    epochs_interest = nept.Epoch(np.array([position.time[0], position.time[-1]]))\n",
    "\n",
    "    counts = nept.bin_spikes(sliced_spikes, position.time, dt=dt, window=window,\n",
    "                             gaussian_std=gaussian_std, normalized=normalized)\n",
    "    \n",
    "    n_active_neurons = np.sum(counts.data >= 1, axis=1)\n",
    "\n",
    "    tc_shape = tuning_curves.shape\n",
    "    decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "    likelihood = nept.bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)\n",
    "    \n",
    "    xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "    ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "    xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "    decoded_position = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "    \n",
    "    likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "    likelihood[np.isnan(likelihood)] = 0.\n",
    "\n",
    "    f_xy = scipy.interpolate.interp1d(position.time, position.data.T, kind=\"nearest\")\n",
    "    counts_xy = f_xy(counts.time)\n",
    "    true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                             counts_xy[1][..., np.newaxis])),\n",
    "                                  counts.time)\n",
    "    \n",
    "    errors = true_position.distance(decoded_position)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(5, 4) \n",
    "    \n",
    "    ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "    xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "    pad_amount = 5\n",
    "    ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "    ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "    n_timebins = len(likelihood)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('bone_r')\n",
    "    posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihood[0], vmin=0, vmax=0.1, cmap=cmap)\n",
    "    colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "    estimated_position, = ax1.plot([], [], \"<\", color=\"r\")\n",
    "    rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "    \n",
    "    ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "    \n",
    "    binwidth = 5\n",
    "    bin_array = np.arange(np.min(errors), np.max(errors) + binwidth, binwidth)\n",
    "\n",
    "    _, _, errors_bin = ax2.hist(errors, bins=bin_array, rwidth=0.9, color=\"k\")\n",
    "    fontsize = 14\n",
    "    ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "    ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "    \n",
    "    binwidth = 1\n",
    "    bin_array = np.arange(np.min(n_active_neurons), np.max(n_active_neurons) + binwidth + 1, binwidth)\n",
    "\n",
    "    _, _, n_neurons_bin = ax3.hist(n_active_neurons, bins=bin_array, rwidth=0.9, color=\"k\")\n",
    "    ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "    ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.yaxis.set_ticks_position('left')\n",
    "    ax3.xaxis.set_ticks_position('bottom')\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    def init():\n",
    "        posterior_position.set_array([])\n",
    "        estimated_position.set_data([], [])\n",
    "        rat_position.set_data([], [])\n",
    "        return (posterior_position, estimated_position, rat_position)\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        posterior_position.set_array(likelihood[i].ravel())\n",
    "        estimated_position.set_data(decoded_position.x[i], decoded_position.y[i])\n",
    "        rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "        \n",
    "        for patch in errors_bin:\n",
    "            patch.set_fc('k')\n",
    "        idx = np.digitize(np.array([errors[i]]), bin_array)[0]\n",
    "        errors_bin[idx-1].set_fc('r')\n",
    "        \n",
    "        for patch in n_neurons_bin:\n",
    "            patch.set_fc('k')\n",
    "        idx = np.digitize(np.array([n_active_neurons[i]]), bin_array)[0]\n",
    "        n_neurons_bin[idx-1].set_fc('r')\n",
    "    \n",
    "        return (posterior_position, estimated_position, rat_position, errors_bin, n_neurons_bin)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=80, \n",
    "                                   blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#     writer = animation.writers['ffmpeg'](fps=18)\n",
    "#     dpi = 600\n",
    "#     filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "#     anim.save(output_filepath+filename, writer=writer, dpi=dpi)\n",
    "    \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.128013Z",
     "start_time": "2018-06-25T14:42:18.286Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood = likelihood_original.reshape(np.shape(likelihood_original)[0], tc_shape[1], tc_shape[2])\n",
    "\n",
    "nan_idx = np.isnan(likelihood)\n",
    "huh = likelihood[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.130012Z",
     "start_time": "2018-06-25T14:42:18.288Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.131012Z",
     "start_time": "2018-06-25T14:42:18.292Z"
    }
   },
   "outputs": [],
   "source": [
    "huh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.133011Z",
     "start_time": "2018-06-25T14:42:18.296Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.134011Z",
     "start_time": "2018-06-25T14:42:18.298Z"
    }
   },
   "outputs": [],
   "source": [
    "counts.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.135010Z",
     "start_time": "2018-06-25T14:42:18.302Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(likelihood_original[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.136009Z",
     "start_time": "2018-06-25T14:42:18.308Z"
    }
   },
   "outputs": [],
   "source": [
    "counts.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.136009Z",
     "start_time": "2018-06-25T14:42:18.314Z"
    }
   },
   "outputs": [],
   "source": [
    "def bayesian_prob(counts, tuning_curves, binsize, min_neurons, min_spikes):\n",
    "    \"\"\"Computes the bayesian probability of location based on spike counts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : nept.AnalogSignal\n",
    "        Where each inner array is the number of spikes (int) in each bin for an individual neuron.\n",
    "    tuning_curves : np.array\n",
    "        Where each inner array is the tuning curve (floats) for an individual neuron.\n",
    "    binsize : float\n",
    "        Size of the time bins.\n",
    "    min_neurons : int\n",
    "        Mininum number of neurons active in a given bin.\n",
    "    min_spikes : int\n",
    "        Mininum number of spikes in a given bin.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob : np.array\n",
    "        Where each inner array is the probability (floats) for an individual neuron by location bins.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If a bin does not meet the min_neuron/min_spikes requirement, that bin's probability\n",
    "    is set to nan. To convert it to 0s instead, use : prob[np.isnan(prob)] = 0 on the output.\n",
    "\n",
    "    \"\"\"\n",
    "    n_time_bins = np.shape(counts.time)[0]\n",
    "    n_position_bins = np.shape(tuning_curves)[1]\n",
    "\n",
    "    likelihood = np.empty((n_time_bins, n_position_bins)) * np.nan\n",
    "\n",
    "    # Ignore warnings when inf created in this loop\n",
    "    error_settings = np.seterr(over='ignore')\n",
    "    for idx in range(n_position_bins):\n",
    "        valid_idx = tuning_curves[:, idx] > 1  # log of 1 or less is negative or invalid\n",
    "        if np.any(valid_idx):\n",
    "            # event_rate is the lambda in this poisson distribution\n",
    "            event_rate = tuning_curves[valid_idx, idx, np.newaxis].T ** counts.data[:, valid_idx]\n",
    "            prior = np.exp(-binsize * np.sum(tuning_curves[valid_idx, idx]))\n",
    "\n",
    "            # Below is the same as\n",
    "            # likelihood[:, idx] = np.prod(event_rate, axis=0) * prior * (1/n_position_bins)\n",
    "            # only less likely to have floating point issues, though slower\n",
    "            likelihood[:, idx] = np.exp(np.sum(np.log(event_rate), axis=1)) * prior * (1/n_position_bins)\n",
    "    np.seterr(**error_settings)\n",
    "\n",
    "    # Set any inf value to be largest float\n",
    "    largest_float = np.finfo(float).max\n",
    "    likelihood[np.isinf(likelihood)] = largest_float\n",
    "    likelihood /= np.nansum(likelihood, axis=1)[..., np.newaxis]\n",
    "\n",
    "    # Remove bins with too few neurons that that are active\n",
    "    # a neuron is considered active by having at least min_spikes in a bin\n",
    "    n_active_neurons = np.sum(counts.data >= min_spikes, axis=1)\n",
    "    likelihood[n_active_neurons < min_neurons] = np.nan\n",
    "    \n",
    "    print(np.sum(np.isnan(likelihood)))\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.137008Z",
     "start_time": "2018-06-25T14:42:18.317Z"
    }
   },
   "outputs": [],
   "source": [
    "lo = bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.138008Z",
     "start_time": "2018-06-25T14:42:18.323Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood_original = nept.bayesian_prob(counts, decoding_tc, window, min_neurons=min_neurons, min_spikes=min_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.139007Z",
     "start_time": "2018-06-25T14:42:18.327Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.where(likelihood_original == 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.140006Z",
     "start_time": "2018-06-25T14:42:18.330Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.141006Z",
     "start_time": "2018-06-25T14:42:18.341Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# writer = animation.writers['ffmpeg'](fps=18)\n",
    "# dpi = 600\n",
    "# filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "# anim.save(output_filepath+filename, writer=writer, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.142006Z",
     "start_time": "2018-06-25T14:42:18.344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Blue is true position; Red is estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.143005Z",
     "start_time": "2018-06-25T14:42:18.348Z"
    }
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T14:42:23.144004Z",
     "start_time": "2018-06-25T14:42:18.354Z"
    }
   },
   "outputs": [],
   "source": [
    "errors_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
