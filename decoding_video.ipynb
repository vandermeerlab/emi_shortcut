{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:11.216918Z",
     "start_time": "2018-07-10T12:36:10.029200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import nept\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from loading_data import get_data\n",
    "from analyze_tuning_curves import get_only_tuning_curves\n",
    "from analyze_decode_bytrial import decode_trial\n",
    "from analyze_decode import get_decoded_zones\n",
    "from utils_maze import find_zones, get_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:11.222915Z",
     "start_time": "2018-07-10T12:36:11.218917Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisdir = os.getcwd()\n",
    "pickle_filepath = os.path.join(thisdir, \"cache\", \"pickled\")\n",
    "output_filepath = os.path.join(thisdir, \"plots\", \"decode-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:11.232909Z",
     "start_time": "2018-07-10T12:36:11.224914Z"
    }
   },
   "outputs": [],
   "source": [
    "from run import spike_sorted_infos\n",
    "import info.r063d5 as r063d5\n",
    "import info.r063d6 as r063d6\n",
    "infos = [r063d5, r063d6]\n",
    "# infos = spike_sorted_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:33:14.536701Z",
     "start_time": "2018-07-10T15:33:14.523708Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decoded(info, position, spikes, xedges, yedges, shuffled_id, random_shuffle):\n",
    "    \n",
    "    min_n_spikes = 100\n",
    "    max_n_spikes = 5000\n",
    "    \n",
    "    phase = info.task_times[\"phase3\"]\n",
    "    trials = get_trials(events, phase)\n",
    "    \n",
    "    error_byactual_position = np.zeros((len(yedges), len(xedges)))\n",
    "    n_byactual_position = np.ones((len(yedges), len(xedges)))\n",
    "    \n",
    "    session_n_active = []\n",
    "    session_likelihoods = []\n",
    "    session_decoded = []\n",
    "    session_actual = []\n",
    "    session_errors = []\n",
    "    \n",
    "    for trial in trials:\n",
    "        epoch_of_interest = phase.excludes(trial)\n",
    "\n",
    "        tuning_curves = get_only_tuning_curves(position, \n",
    "                                               spikes, \n",
    "                                               xedges, \n",
    "                                               yedges, \n",
    "                                               epoch_of_interest,\n",
    "                                               min_n_spikes,\n",
    "                                               max_n_spikes)\n",
    "\n",
    "        if shuffled_id:\n",
    "            tuning_curves = np.random.permutation(tuning_curves)\n",
    "\n",
    "        sliced_position = position.time_slice(trial.start, trial.stop)\n",
    "        \n",
    "        sliced_spikes = [spiketrain.time_slice(trial.start, \n",
    "                                               trial.stop) for spiketrain in spikes]\n",
    "\n",
    "        # limit position to only times when the subject is moving faster than a certain threshold\n",
    "        run_epoch = nept.run_threshold(sliced_position, thresh=15., t_smooth=1.)\n",
    "        sliced_position = sliced_position[run_epoch]\n",
    "        sliced_spikes = [spiketrain.time_slice(run_epoch.start, \n",
    "                                               run_epoch.stop) for spiketrain in spikes]\n",
    "\n",
    "        epochs_interest = nept.Epoch(np.array([sliced_position.time[0], sliced_position.time[-1]]))\n",
    "\n",
    "        counts = nept.bin_spikes(sliced_spikes, sliced_position.time, dt=0.025, window=0.025,\n",
    "                                 gaussian_std=0.0075, normalized=False)\n",
    "\n",
    "        session_n_active.append(np.sum(counts.data >= 1, axis=1))\n",
    "\n",
    "        tc_shape = tuning_curves.shape\n",
    "        decoding_tc = tuning_curves.reshape(tc_shape[0], tc_shape[1] * tc_shape[2])\n",
    "\n",
    "        likelihood = nept.bayesian_prob(counts, decoding_tc, binsize=0.025, min_neurons=2, min_spikes=1)\n",
    "\n",
    "        # Find decoded location based on max likelihood for each valid timestep\n",
    "        xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "        ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "        xy_centers = nept.cartesian(xcenters, ycenters)\n",
    "        decoded = nept.decode_location(likelihood, xy_centers, counts.time)\n",
    "\n",
    "        if random_shuffle:\n",
    "            random_x = [np.random.choice(decoded.x) for val in decoded.x]\n",
    "            random_y = [np.random.choice(decoded.y) for val in decoded.y]\n",
    "\n",
    "            decoded = nept.Position(np.array([random_x, random_y]).T, decoded.time)\n",
    "\n",
    "        session_decoded.append(decoded)\n",
    "        \n",
    "        # Remove nans from likelihood and reshape for plotting\n",
    "        keep_idx = np.sum(np.isnan(likelihood), axis=1) < likelihood.shape[1]\n",
    "        likelihood = likelihood[keep_idx]\n",
    "        likelihood = likelihood.reshape(np.shape(likelihood)[0], tc_shape[1], tc_shape[2])\n",
    "\n",
    "        session_likelihoods.append(likelihood)\n",
    "\n",
    "        f_xy = scipy.interpolate.interp1d(sliced_position.time, sliced_position.data.T, kind=\"nearest\")\n",
    "        counts_xy = f_xy(decoded.time)\n",
    "        true_position = nept.Position(np.hstack((counts_xy[0][..., np.newaxis],\n",
    "                                                 counts_xy[1][..., np.newaxis])),\n",
    "                                      decoded.time)\n",
    "\n",
    "        session_actual.append(true_position)\n",
    "\n",
    "        trial_errors = true_position.distance(decoded)\n",
    "\n",
    "        for error, x, y in zip(trial_errors, true_position.x, true_position.y):\n",
    "            x_idx = nept.find_nearest_idx(xedges, x)\n",
    "            y_idx = nept.find_nearest_idx(yedges, y)\n",
    "            error_byactual_position[y_idx][x_idx] += error\n",
    "            n_byactual_position[y_idx][x_idx] += 1\n",
    "\n",
    "        session_errors.append(trial_errors)\n",
    "            \n",
    "#     error_byactual = error_byactual_position / n_byactual_position\n",
    "\n",
    "    return session_decoded, session_actual, session_likelihoods, session_errors, session_n_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions):\n",
    "    \n",
    "    all_errors = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors], axis=0)\n",
    "    all_errors_id_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_id_shuffled], axis=0)\n",
    "    all_errors_random_shuffled = np.concatenate([np.concatenate(errors, axis=0) for errors in all_errors_random_shuffled], axis=0)\n",
    "    \n",
    "    print('Actual:', np.median(all_errors))\n",
    "    print('ID shuffle:', np.median(all_errors_id_shuffled))\n",
    "    print('Random shuffle:', np.median(all_errors_random_shuffled)) \n",
    "\n",
    "    print('Actual:', np.mean(all_errors), stats.sem(all_errors))\n",
    "    print('ID shuffle:', np.mean(all_errors_id_shuffled), stats.sem(all_errors_id_shuffled))\n",
    "    print('Random shuffle:', np.mean(all_errors_random_shuffled), stats.sem(all_errors_random_shuffled)) \n",
    "    \n",
    "    fliersize = 1\n",
    "\n",
    "    decoded_dict = dict(error=all_errors, label='Decoded')\n",
    "    shuffled_id_dict = dict(error=all_errors_id_shuffled, label='ID shuffled')\n",
    "    shuffled_random_dict = dict(error=all_errors_random_shuffled, label='Random shuffled')\n",
    "    decoded_errors = pd.DataFrame(decoded_dict)\n",
    "    shuffled_id = pd.DataFrame(shuffled_id_dict)\n",
    "    shuffled_random = pd.DataFrame(shuffled_random_dict)\n",
    "    data = pd.concat([shuffled_id, shuffled_random, decoded_errors])\n",
    "    colours = ['#ffffff', '#ffffff', '#bdbdbd']\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    flierprops = dict(marker='o', markersize=fliersize, linestyle='none')\n",
    "    # ax = sns.boxplot(x='label', y='error', data=data, palette=colours, flierprops=flierprops)\n",
    "    ax = sns.boxplot(x='label', y='error', data=data, flierprops=flierprops)\n",
    "\n",
    "\n",
    "    edge_colour = '#252525'\n",
    "    for i, artist in enumerate(ax.artists):\n",
    "        artist.set_edgecolor(edge_colour)\n",
    "        artist.set_facecolor(colours[i])\n",
    "\n",
    "        for j in range(i*6, i*6+6):\n",
    "            line = ax.lines[j]\n",
    "            line.set_color(edge_colour)\n",
    "            line.set_mfc(edge_colour)\n",
    "            line.set_mec(edge_colour)\n",
    "\n",
    "    ax.text(1., 1., 'n_sessions = ' + str(n_sessions),\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            transform=ax.transAxes,\n",
    "            color='k', fontsize=10)\n",
    "\n",
    "    ax.set(xlabel=' ', ylabel=\"Error (cm)\")\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_sessions = 0\n",
    "xxs = []\n",
    "yys = []\n",
    "\n",
    "all_decoded = []\n",
    "all_actual = []\n",
    "all_likelihoods = []\n",
    "all_n_active = []\n",
    "\n",
    "all_errors = []\n",
    "all_errors_id_shuffled = []\n",
    "all_errors_random_shuffled = []\n",
    "\n",
    "\n",
    "for info in infos:\n",
    "    print(info.session_id)\n",
    "    n_sessions += 1\n",
    "    events, position, spikes, _, _ = get_data(info)\n",
    "    xedges, yedges = nept.get_xyedges(position, binsize=8)\n",
    "    \n",
    "    xx, yy = np.meshgrid(xedges, yedges)\n",
    "    xxs.append(xx)\n",
    "    yys.append(yy)\n",
    "\n",
    "    phase = \"phase3\"\n",
    "    trial_epochs = get_trials(events, info.task_times[phase])\n",
    "    \n",
    "    decoded, actual, likelihoods, errors, n_active = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedges, \n",
    "                                             yedges, \n",
    "                                             shuffled_id=False, \n",
    "                                             random_shuffle=False)\n",
    "    \n",
    "    _, _, _, errors_id_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedges, \n",
    "                                             yedges, \n",
    "                                             shuffled_id=True, \n",
    "                                             random_shuffle=False)\n",
    "    \n",
    "    _, _, _, errors_random_shuffled, _ = get_decoded(info, \n",
    "                                             position, \n",
    "                                             spikes, \n",
    "                                             xedges, \n",
    "                                             yedges, \n",
    "                                             shuffled_id=False, \n",
    "                                             random_shuffle=True)\n",
    "    \n",
    "    all_decoded.append(decoded)\n",
    "    all_actual.append(actual)\n",
    "    all_likelihoods.append(likelihoods)\n",
    "    all_n_active.append(n_active)\n",
    "    \n",
    "    all_errors.append(errors)\n",
    "    all_errors_id_shuffled.append(errors_id_shuffled)\n",
    "    all_errors_random_shuffled.append(errors_random_shuffled)\n",
    "    \n",
    "plot_errors(all_errors, all_errors_id_shuffled, all_errors_random_shuffled, n_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:25.028935Z",
     "start_time": "2018-07-10T12:36:10.075Z"
    }
   },
   "outputs": [],
   "source": [
    "session_idx = 0\n",
    "trial_idx = 1\n",
    "decoded = all_decoded[session_idx][trial_idx]\n",
    "true_position = all_actual[session_idx][trial_idx]\n",
    "likelihoods = all_likelihoods[session_idx][trial_idx]\n",
    "n_active = all_n_active[session_idx][trial_idx]\n",
    "errors = all_errors[session_idx][trial_idx]\n",
    "xx = xxs[session_idx]\n",
    "yy = yys[session_idx]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "gs = gridspec.GridSpec(5, 4) \n",
    "\n",
    "ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=3, rowspan=3)\n",
    "\n",
    "pad_amount = 5\n",
    "ax1.set_xlim((np.floor(np.min(true_position.x))-pad_amount, np.ceil(np.max(true_position.x))+pad_amount))\n",
    "ax1.set_ylim((np.floor(np.min(true_position.y))-pad_amount, np.ceil(np.max(true_position.y))+pad_amount))\n",
    "\n",
    "# n_timebins = decoded.n_samples\n",
    "n_timebins = 10\n",
    "\n",
    "cmap = plt.cm.get_cmap('bone_r')\n",
    "posterior_position = ax1.pcolormesh(xx[:-1], yy[:-1], likelihoods[0], vmin=0, vmax=0.1, cmap=cmap)\n",
    "colorbar = fig.colorbar(posterior_position, ax=ax1)\n",
    "\n",
    "estimated_position, = ax1.plot([], [], \"<\", color=\"r\")\n",
    "rat_position, = ax1.plot([], [], \"<\", color=\"b\")\n",
    "\n",
    "ax2 = plt.subplot2grid((5, 4), (3, 0), colspan=3)\n",
    "\n",
    "binwidth = 5.\n",
    "error_bins = np.arange(-binwidth, np.max(errors)+binwidth, binwidth)\n",
    "\n",
    "_, _, errors_bin = ax2.hist([np.clip(errors, error_bins[0], error_bins[-1])], bins=error_bins, rwidth=0.9, color=\"k\")\n",
    "errors_idx = np.digitize(errors, error_bins)\n",
    "\n",
    "\n",
    "# xlabels = [str(int(b)) for b in error_bins]\n",
    "# xlabels[0] = \"nan\"\n",
    "# ax2.set_xticklabels(xlabels)\n",
    "fontsize = 14\n",
    "ax2.set_xlabel(\"Error (cm)\", fontsize=fontsize)\n",
    "ax2.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.yaxis.set_ticks_position('left')\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "# xticks = binwidth * np.arange(0, len(xlabels)-1, 2) - binwidth\n",
    "# xticks[0] = -binwidth/2.\n",
    "xticks = binwidth * np.arange(0, len(error_bins), 4)\n",
    "plt.xticks(xticks, fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "ax3 = plt.subplot2grid((5, 4), (4, 0), colspan=3)\n",
    "\n",
    "binwidth = 1\n",
    "n_active_bins = np.arange(-binwidth, np.max(n_active)+binwidth, binwidth)\n",
    "\n",
    "_, _, n_neurons_bin = ax3.hist(n_active, bins=n_active_bins, rwidth=0.9, color=\"k\")\n",
    "#     n_active_idx = np.digitize(n_active, n_active_bins)\n",
    "\n",
    "ax3.set_xlabel(\"Number of active neurons\", fontsize=fontsize)\n",
    "ax3.set_ylabel(\"# bins\", fontsize=fontsize)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.yaxis.set_ticks_position('left')\n",
    "ax3.xaxis.set_ticks_position('bottom')\n",
    "xticks = binwidth * np.arange(len(n_active_bins))\n",
    "plt.xticks(xticks-binwidth/2)\n",
    "ax3.set_xticklabels(xticks, fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "def init():\n",
    "    posterior_position.set_array([])\n",
    "    estimated_position.set_data([], [])\n",
    "    rat_position.set_data([], [])\n",
    "    return (posterior_position, estimated_position, rat_position)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    posterior_position.set_array(likelihoods[i].ravel())\n",
    "    estimated_position.set_data(decoded.x[i], decoded.y[i])\n",
    "    rat_position.set_data(true_position.x[i], true_position.y[i])\n",
    "\n",
    "    for patch in errors_bin:\n",
    "        patch.set_fc('k')\n",
    "    errors_bin[errors_idx[i]-1].set_fc('r')\n",
    "\n",
    "    for patch in n_neurons_bin:\n",
    "        patch.set_fc('k')\n",
    "    n_neurons_bin[n_active[i]].set_fc('r')\n",
    "\n",
    "    return (posterior_position, estimated_position, rat_position)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=n_timebins, interval=100, \n",
    "                               blit=False, repeat=False)\n",
    "\n",
    "\n",
    "#     writer = animation.writers['ffmpeg'](fps=18)\n",
    "#     dpi = 600\n",
    "#     filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "#     anim.save(output_filepath+filename, writer=writer, dpi=dpi)\n",
    "\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:25.030934Z",
     "start_time": "2018-07-10T12:36:10.079Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Blue is true position; Red is estimated location.\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:25.033932Z",
     "start_time": "2018-07-10T12:36:10.097Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning_curves = tc\n",
    "\n",
    "xx, yy = np.meshgrid(xedges, yedges)\n",
    "\n",
    "n_colours = 9.\n",
    "colours = [(1., 1., 1.)]\n",
    "colours.extend(matplotlib.cm.copper_r(np.linspace(0, 1, n_colours-1)))\n",
    "cmap = matplotlib.colors.ListedColormap(colours)\n",
    "\n",
    "# Plot individual tuning curves\n",
    "# for i, tuning_curve in enumerate(tuning_curves):    \n",
    "for i, tuning_curve in enumerate(tuning_curves[:3]): \n",
    "    tuning_curve = np.array(tuning_curve)\n",
    "    tuning_curve[np.isnan(tuning_curve)] = -np.nanmax(tuning_curve) / n_colours\n",
    "\n",
    "    plt.figure()\n",
    "    pp = plt.pcolormesh(xx, yy, tuning_curve, cmap=cmap)\n",
    "\n",
    "    colourbar = plt.colorbar(pp)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T12:36:25.035931Z",
     "start_time": "2018-07-10T12:36:10.105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = animation.writers['ffmpeg'](fps=18)\n",
    "# dpi = 600\n",
    "# filename = '/errors_'+info.session_id+'_trial'+str(trial_idx)+'.mp4'\n",
    "# anim.save(output_filepath+filename, writer=writer, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
