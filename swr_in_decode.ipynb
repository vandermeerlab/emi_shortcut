{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "import vdmlab as vdm\n",
    "\n",
    "from load_data import get_pos, get_spikes, get_lfp\n",
    "from analyze_maze import find_zones\n",
    "from analyze_decode import get_edges, point_in_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_filepath = 'E:/code/emi_shortcut/cache/pickled'\n",
    "output_filepath = 'E:/code/emi_shortcut/plots/decode/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import info.r063d3 as r063d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = r063d3\n",
    "\n",
    "shuffle_id = False\n",
    "experiment_time = 'tracks'\n",
    "\n",
    "tuning_curve_filename = info.session_id + '_tuning-curve.pkl'\n",
    "pickled_tuning_curve = os.path.join(pickle_filepath, tuning_curve_filename)\n",
    "with open(pickled_tuning_curve, 'rb') as fileobj:\n",
    "    tuning_curve = pickle.load(fileobj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding: R063d3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('decoding:', info.session_id)\n",
    "position = get_pos(info.pos_mat, info.pxl_to_cm)\n",
    "spikes = get_spikes(info.spike_mat)\n",
    "lfp = get_lfp(info.good_swr[0])\n",
    "\n",
    "speed = position.speed(t_smooth=0.5)\n",
    "run_idx = np.squeeze(speed.data) >= 0.1\n",
    "run_pos = position[run_idx]\n",
    "\n",
    "# track_starts = [info.task_times['phase1'].start,\n",
    "#                 info.task_times['phase2'].start,\n",
    "#                 info.task_times['phase3'].start]\n",
    "# track_stops = [info.task_times['phase1'].stop,\n",
    "#                info.task_times['phase2'].stop,\n",
    "#                info.task_times['phase3'].stop]\n",
    "\n",
    "track_starts = [info.task_times['phase3'].start]\n",
    "track_stops = [info.task_times['phase3'].stop]\n",
    "\n",
    "track_pos = run_pos.time_slices(track_starts, track_stops)\n",
    "\n",
    "if shuffle_id:\n",
    "    random.shuffle(tuning_curve)\n",
    "\n",
    "if experiment_time == 'tracks':\n",
    "    decode_spikes = [spiketrain.time_slices(track_starts, track_stops) for spiketrain in spikes]\n",
    "    epochs_interest = vdm.Epoch(np.hstack([np.array(track_starts), np.array(track_stops)]))\n",
    "    \n",
    "else:\n",
    "    decode_spikes = [spiketrain.time_slice(info.task_times[experiment_time].start,\n",
    "                                           info.task_times[experiment_time].stop) for spiketrain in spikes]\n",
    "    sliced_lfp = lfp.time_slice(info.task_times[experiment_time].start, info.task_times[experiment_time].stop)\n",
    "    z_thresh = 3.0\n",
    "    power_thresh = 5.0\n",
    "    merge_thresh = 0.02\n",
    "    min_length = 0.01\n",
    "    swrs = vdm.detect_swr_hilbert(sliced_lfp, fs=info.fs, thresh=(140.0, 250.0), z_thresh=z_thresh,\n",
    "                                  power_thresh=power_thresh, merge_thresh=merge_thresh, min_length=min_length)\n",
    "\n",
    "    epochs_interest = vdm.find_multi_in_epochs(decode_spikes, swrs, min_involved=3)\n",
    "\n",
    "counts_binsize = 0.025\n",
    "time_edges = get_edges(run_pos, counts_binsize, lastbin=True)\n",
    "counts = vdm.get_counts(decode_spikes, time_edges, gaussian_std=0.025)\n",
    "\n",
    "decoding_tc = []\n",
    "for tuning in tuning_curve:\n",
    "    decoding_tc.append(np.ravel(tuning))\n",
    "decoding_tc = np.array(decoding_tc)\n",
    "\n",
    "likelihood = vdm.bayesian_prob(counts, decoding_tc, counts_binsize)\n",
    "\n",
    "binsize = 3\n",
    "xedges = np.arange(track_pos.x.min(), track_pos.x.max() + binsize, binsize)\n",
    "yedges = np.arange(track_pos.y.min(), track_pos.y.max() + binsize, binsize)\n",
    "\n",
    "xcenters = (xedges[1:] + xedges[:-1]) / 2.\n",
    "ycenters = (yedges[1:] + yedges[:-1]) / 2.\n",
    "xy_centers = vdm.cartesian(xcenters, ycenters)\n",
    "\n",
    "time_centers = (time_edges[1:] + time_edges[:-1]) / 2.\n",
    "\n",
    "decoded = vdm.decode_location(likelihood, xy_centers, time_centers)\n",
    "nan_idx = np.logical_and(np.isnan(decoded.x), np.isnan(decoded.y))\n",
    "decoded = decoded[~nan_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not decoded.isempty:\n",
    "    sequences = vdm.remove_teleports(decoded, speed_thresh=10, min_length=3)\n",
    "\n",
    "decoded_epochs = sequences.contains(epochs_interest)\n",
    "\n",
    "sequence_decoded = vdm.epoch_position(decoded, decoded_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6503"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54630"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_decoded.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6503"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_epochs.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = find_zones(info, expand_by=7)\n",
    "decoded_zones = point_in_zones(decoded, zones)\n",
    "\n",
    "keys = ['u', 'shortcut', 'novel']\n",
    "errors = dict()\n",
    "actual_position = dict()\n",
    "if experiment_time == 'tracks':\n",
    "    for trajectory in keys:\n",
    "        actual_x = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.x)\n",
    "        actual_y = np.interp(decoded_zones[trajectory].time, track_pos.time, track_pos.y)\n",
    "        actual_position[trajectory] = vdm.Position(np.hstack((actual_x[..., np.newaxis],\n",
    "                                                              actual_y[..., np.newaxis])),\n",
    "                                                   decoded_zones[trajectory].time)\n",
    "        errors[trajectory] = actual_position[trajectory].distance(decoded_zones[trajectory])\n",
    "else:\n",
    "    for trajectory in decoded_zones:\n",
    "        errors[trajectory] = []\n",
    "        actual_position[trajectory] = []\n",
    "\n",
    "output = dict()\n",
    "output['zones'] = decoded_zones\n",
    "output['errors'] = errors\n",
    "output['times'] = len(time_centers)\n",
    "output['actual'] = actual_position\n",
    "output['decoded'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(output['errors']['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(decoded.time, decoded.y)\n",
    "plt.plot(actual_position['u'].time, actual_position['u'].y, lw=4)\n",
    "plt.xlim(6530, 6730)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
